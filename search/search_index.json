{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\ude80 ENME480 \u2014 Introduction to Robotics","text":"Fall 2025 \u2022 University of Maryland \u2022 3 credits"},{"location":"#course-overview","title":"\ud83c\udfaf Course overview","text":"<p>ENME480 blends core theory with practical labs:</p> <ul> <li>\ud83e\udd16 Kinematics &amp; dynamics \u2014 rigid motions, forward/inverse kinematics, planning &amp; control  </li> <li>\ud83e\uddd1\u200d\ud83d\udcbb ROS 2 &amp; Python \u2014 modern robotics tooling and best practices  </li> <li>\ud83e\uddea Studios &amp; labs \u2014 translate math into code on UR3e industrial arms  </li> <li>\ud83d\udc41\ufe0f Vision pipeline \u2014 perception + pick &amp; place for the final project</li> </ul>"},{"location":"#key-facts","title":"\ud83d\udd11 Key facts","text":"<ul> <li>Instructor: Dr. Nikhil Chopra \u2014 Office Hours: Wed 10\u201311:30, 2149 Martin Hall (Zoom link in syllabus)  </li> <li>TAs: Alex Beyer, Kaustubh Joshi \u2014 TA Office Hours: TBD </li> <li>Course dates: Sep 2 \u2013 Dec 12, 2025 </li> <li>Lectures: MW 2:00\u20132:50pm (TWS1100)  </li> <li>Studios (sections): 0101 Thu 12\u20132, 0102 Fri 8\u201310, 0103 Tue 12\u20132 (KEB 2111 / EAF 3119)  </li> <li>Channels: Piazza, Canvas, GitHub</li> </ul> <p>\ud83d\udccb View Syllabus \ud83d\uddd3\ufe0f Schedule \ud83e\uddea Start Labs \u2753 Help</p>"},{"location":"#quick-start-new-students","title":"\ud83d\ude80 Quick start (new students)","text":"<ol> <li>\ud83d\udccb Complete Safety Training (required before robot lab) </li> <li>\ud83d\udcbb Set up Ubuntu, Python, and ROS 2 \u2014 see Week 1 </li> <li>\ud83d\udc27 Practice Linux/Python basics \u2014 Week 2 </li> <li>\ud83e\udd16 Get started with ROS \u2014 Week 3</li> </ol>"},{"location":"#key-dates","title":"\ud83d\udcc5 Key dates","text":"<p>Final dates live on Canvas; midterm weeks appear on the Schedule page.</p> <ul> <li>Course runs: Sep 2 \u2192 Dec 12, 2025  </li> <li>Midterm 1: TBD (see Schedule) </li> <li>Midterm 2: TBD (see Schedule) </li> <li>Final project demos: TBD (last 1\u20132 weeks)</li> </ul>"},{"location":"#this-week","title":"\ud83d\uddd3\ufe0f This week","text":"<ul> <li>Safety training due by end of Week 1</li> <li>Environment setup (Ubuntu, Python, ROS 2)</li> <li>Account verification for lab access</li> </ul>"},{"location":"#whats-new","title":"\u26a1 What\u2019s new","text":"<ul> <li>Course website launched \ud83c\udf89</li> <li>Lab materials synced from GitHub</li> </ul>"},{"location":"#at-a-glance","title":"\ud83e\udded At a glance","text":"<ul> <li> <p> Meetings     ---     Lectures: MW 2:00\u20132:50 (TWS1100) Studios: 0101 Thu 12\u20132 \u2022 0102 Fri 8\u201310 \u2022 0103 Tue 12\u20132 (KEB 2111 / EAF 3119)      Schedule</p> </li> <li> <p> Grading     ---     Homework 20% \u00b7 Studios/Labs 20% \u00b7 Midterm 1 20% \u00b7 Midterm 2 20% \u00b7 Final Project 20% \u00b7 Extra credit up to 5%  Policies</p> </li> <li> <p> Text &amp; tools     ---     Spong/Hutchinson/Vidyasagar, Robot Modeling and Control (2e, 2020).     ROS 2 (Humble) + Python; laptop capable of running ROS 2.      Resources</p> </li> </ul>"},{"location":"#locations","title":"\ud83c\udfe2 Locations","text":"Activity Location Room \ud83d\udcbb Programming Studios Kim Engineering (KEB) KEB 2111 \ud83e\udd16 Robot Lab (RAL) Engineering Annex Facility (EAF) EAF 3119 (watch Piazza for any changes) \ud83d\udcda Office Hours (Instructor) Martin Hall 2149 (Wed 10\u201311:30)"},{"location":"#learning-path","title":"\ud83c\udf93 Learning path","text":"<pre><code>graph LR\n    A[Week 1\u20132: Setup] --&gt; B[Week 3: ROS Basics]\n    B --&gt; C[Week 4\u20135: Gazebo &amp; Demos]\n    C --&gt; D[Week 5\u20138: Kinematics]\n    D --&gt; E[Week 9\u201311: Dynamics &amp; Control]\n    E --&gt; F[Final Project]\n</code></pre>"},{"location":"dev-environment/","title":"\ud83d\udcbb Development Environment Setup","text":"<p>This page will walk you through how to set up VSCode to connect to the Docker image and run ROS code. You are free to use any IDE you wish, but VSCode is (in our experience) the easiest way to achieve what we need for this class.</p>"},{"location":"dev-environment/#prerequisites","title":"\ud83d\udcbb Prerequisites","text":"<p>Before starting, ensure you have:     - \u2705 Ubuntu 22.04 LTS installed     - \u2705 Python 3.8+ installed     - \u2705 ROS 2 Humble installed via the provided docker image</p>"},{"location":"dev-environment/#vs-code-recommended","title":"\ud83d\ude80 VS Code (Recommended)","text":"<ol> <li>Visit code.visualstudio.com/download and download the installer.</li> <li>Go to the extensions screen on the left side of your screen (Or hit Ctrl+Shift+X) and install the Remote Development package, the Container Tools package, the Docker package, the Python package, the ROS package and the Python Debugger package. We also recommend installing a python linter (i.e. Pylance, RUFF) to help with debugging.</li> <li>(WSL only) With WSL open, click the blue button in the bottom left of VSCode and select \"Connect to WSL\". VSCode should look like it is closing and reopening.</li> <li>Open a new terminal in VSCode using the Terminal menu on the top on your screen (or Ctrl+Shfit+`). You can check to make sure the connection worked by making sure the username displayed in the terminal matches what's displayed in WSL.</li> <li>Run the docker compose command from the last seciton to verify that VSCode can properly connect to the Docker.</li> </ol>"},{"location":"dev-environment/#pycharm-alternative","title":"\ud83d\udc0d PyCharm (Alternative)","text":""},{"location":"dev-environment/#install-pycharm","title":"Install PyCharm","text":"<pre><code># Install PyCharm Community Edition\nsudo snap install pycharm-community --classic\n\n# Or download from JetBrains website\n# https://www.jetbrains.com/pycharm/download/\n</code></pre>"},{"location":"dev-environment/#troubleshooting-common-issues","title":"\ud83d\udd0d Troubleshooting Common Issues","text":""},{"location":"dev-environment/#vs-code-issues","title":"VS Code Issues","text":"Problem Solution Python not found Check interpreter path in settings Extensions not working Restart VS Code, check installation ROS commands not found Source ROS environment in terminal"},{"location":"dev-environment/#environment-issues","title":"Environment Issues","text":"Problem Solution Virtual env not activated Run <code>source ~/robotics_env/bin/activate</code> Packages not found Check pip installation, verify environment ROS topics not visible Check ROS_DOMAIN_ID, source setup.bash"},{"location":"dev-environment/#getting-help","title":"\ud83c\udd98 Getting Help","text":""},{"location":"dev-environment/#development-resources","title":"Development Resources","text":"<ul> <li>VS Code Docs: code.visualstudio.com/docs</li> <li>PyCharm Docs: jetbrains.com/help/pycharm</li> <li>Python Docs: docs.python.org</li> </ul>"},{"location":"dev-environment/#course-support","title":"Course Support","text":"<ul> <li>Piazza: Ask questions on course forum</li> <li>Office Hours: Get help from TA or instructor</li> <li>Lab Sessions: Hands-on help during labs</li> </ul> <p>Last updated: Fall 2025 \u2022 Back to Resources</p>"},{"location":"enae450_readme/","title":"General overview","text":"<p>The goal of this lab is to install ROS2 Humble. The final test of the installation will be running terminal commands such as <pre><code>glxgears\n</code></pre> or <pre><code>ign gazebo empty.sdf\n</code></pre> and making sure the proper graphical output is displayed.</p> <p>Note: Just to be clear this is not the only way to install ROS2 Humble. The experienced or adventerous students can install ROS without any virtualization software by following insructions available online (e.g. link). In this case students are responsible for making sure ROS and the required packages operate properly.</p>"},{"location":"enae450_readme/#pc-with-ubuntu-2004-and-later-installation-steps-with-docker","title":"PC with Ubuntu 20.04 and later, installation steps with Docker","text":"<p>This is a simplified visualization of what we are trying to achive:\\ OS =&gt; Docker (virtualization software) =&gt; Ubuntu 22.04 + ROS2 Humble (container)\\ It doesn't matter if you launching Ubuntu using dual booting, or single booting, or using VM software. </p> <ol> <li>Installing Docker using apt repository (full guide)<ul> <li>Uninstall old Docker versions</li> <li>Set up Docker's apt repository <pre><code># Add Docker's official GPG key:\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add the repository to Apt sources:\necho \\\n    \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n    $(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\") stable\" | \\\n    sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\nsudo apt-get update\n</code></pre></li> <li>Install the Docker packages <pre><code>sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre></li> <li>Verify installation success <pre><code>sudo docker run hello-world\n</code></pre></li> <li>Change permissions to run docker without sudo <pre><code>sudo usermod -aG docker $USER\n</code></pre></li> <li>Restart PC</li> <li>Run the following and make sure there is no error <pre><code>docker ps -a\n</code></pre></li> </ul> </li> <li>Installing Nvidia drivers and Docker support (only if you have Nvidia GPU)<ul> <li>Test if you have Nvidia drivers installed already <pre><code>nvidia-smi\n</code></pre></li> <li>If you get error consider installing the drivers yourself (see link) or talk to your insructor</li> <li>If <code>nvidia-smi</code> returned proper output, then install Nvidia container toolkit (see full guide here) <pre><code># one large command\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n&amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\nsed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\nsudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n# command ended\n\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\nsudo nvidia-ctk runtime configure --runtime=docker\nsudo systemctl restart docker\n</code></pre></li> </ul> </li> <li>Downloading and building Docker image<ul> <li>Download Dockerfils and navigate terminal to the folder it is stored</li> <li>Run the following command (make sure to include \".\" in the last line) <pre><code>DOCKER_BUILDKIT=1 docker build --build-arg USER=$USER \\\n    --build-arg UID=$(id -u) \\\n    --build-arg GID=$(id -g) \\\n    --build-arg PW=docker \\\n    -t tb3_image \\\n    -f humble_dockerfile.Dockerfile\\\n    .\n</code></pre></li> <li>For the class purposes I used the abridged version of the docker image (see first line of the Docker file). Outside of the class please delete the first line and uncomment the second line (FROM osrf/ros:humble-desktop-full)</li> </ul> </li> <li>Running Docker container<ul> <li>If you have Nvidia GPU, run the following command <pre><code>docker run -it --rm --name TB3Container --net=host --ipc=host --pid=host --gpus=all --runtime=nvidia --privileged \\\n--env=\"DISPLAY=$DISPLAY\" \\\n--volume=\"/tmp/.X11-unix:/tmp/.X11-unix:rw\" \\\ntb3_image:latest\n</code></pre></li> <li>If you don't have Nvidia GPU, run the following command <pre><code>docker run -it --rm --name TB3Container --net=host --ipc=host --pid=host --privileged \\\n--env=\"DISPLAY=$DISPLAY\" \\\n--volume=\"/tmp/.X11-unix:/tmp/.X11-unix:rw\" \\\ntb3_image:latest\n</code></pre></li> </ul> </li> </ol>"},{"location":"enae450_readme/#pc-with-ubuntu-2204-installation-steps-without-docker","title":"PC with Ubuntu 22.04, installation steps without Docker","text":"<ol> <li> <p>Make sure your system is up to date     <pre><code>sudo apt-get update\nsudo apt-get dist-upgrade\n</code></pre></p> </li> <li> <p>Install supplementary packages     <pre><code>sudo apt-get update\nsudo apt-get install -y build-essential curl git make cmake iproute2 iputils-ping mc mesa-utils nano tmux \n</code></pre></p> </li> <li> <p>Install ROS2 Humble </p> <p>Follow official instructions from here</p> </li> <li> <p>Install supplementary ROS packages     <pre><code>sudo apt-get install -y ros-dev-tools python-is-python3 python3-pip\n</code></pre></p> </li> <li> <p>Fix python <code>setuptools</code> package     <pre><code>pip3 install setuptools==58.2.0\n</code></pre></p> </li> <li> <p>Install TB3 ROS packages     <pre><code>sudo apt-get install -y ros-humble-gazebo-* ros-humble-cartographer ros-humble-cartographer-ros ros-humble-navigation2  ros-humble-nav2-bringup ros-humble-dynamixel-sdk ros-humble-turtlebot3-msgs ros-humble-turtlebot3\n</code></pre></p> </li> <li> <p>Set up TB3 workspace     <pre><code>source /opt/ros/humble/setup.bash\nmkdir -p $HOME/tb3_ws/src\ncd $HOME/tb3_ws/src\ngit clone -b humble-devel https://github.com/ROBOTIS-GIT/turtlebot3_simulations.git\ncd $HOME/tb3_ws\ncolcon build --symlink-install\n</code></pre></p> </li> <li> <p>Source your ROS2 installation and <code>colcon</code> autocomplete     <pre><code>echo 'source /opt/ros/humble/setup.bash' &gt;&gt; $HOME/.bashrc\necho 'source /usr/share/colcon_cd/function/colcon_cd.sh' &gt;&gt; $HOME/.bashrc\necho 'source /usr/share/colcon_argcomplete/hook/colcon-argcomplete.bash' &gt;&gt; $HOME/.bashrc\necho 'export ROS_DOMAIN_ID=1' &gt;&gt; ~/.bashrc\necho 'export ROS_LOCALHOST_ONLY=1' &gt;&gt; ~/.bashrc\necho 'export TURTLEBOT3_MODEL=waffle_pi' &gt;&gt; $HOME/.bashrc\necho '#source $HOME/tb3_ws/install/setup.bash' &gt;&gt; $HOME/.bashrc\necho '#source /usr/share/gazebo/setup.bash' &gt;&gt; $HOME/.bashrc\n</code></pre></p> </li> <li> <p>(Optionally but recommended) Download tmux config file     <pre><code>wget https://raw.githubusercontent.com/kanishkaganguly/dotfiles/master/tmux/.tmux.bash.conf -O $HOME/.tmux.conf\n</code></pre></p> </li> </ol>"},{"location":"enae450_readme/#pc-with-windows-10-and-later-installation-steps-with-docker","title":"PC with Windows 10 and later, installation steps with Docker","text":"<p>On Windows machines our setup will have another virtualization layer but the rest will repeat Ubuntu setup Windows 10 =&gt; WSL2 with Ubuntu 20.04 (virtualization software) =&gt; Docker (virtualization software) =&gt; Ubuntu 22.04 + ROS2 Humble (container) 1. Installing WSL2 (see full guides 1, 2)     * Run Powershell as Administrator     * Verify compatibility of your system     <pre><code>systeminfo | findstr /B /C:\"OS Name\" /C:\"OS Version\"\n</code></pre>     * Enable Windows Machine Platform     <pre><code>dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n</code></pre>     Set WSL2 as the default version for future WSL installations     <pre><code>* wsl --set-default-version 2\n</code></pre>     * Install Ubuntu 20.04 in WSL 2     <pre><code>wsl --install -d Ubuntu-20.04\n</code></pre>     * To launch WSL2, start Powershell in a regular mode and run     <pre><code>wsl\n</code></pre> 2. Follow instructions from \"PC with Ubuntu 20.04 and later ...\". All commands should be executed from WSL2 environment</p>"},{"location":"enae450_readme/#mac-laptops","title":"Mac laptops","text":"<p>There are some issues with GPU acceleration support for Docker applications running on Mac. Mac users should use VMware Fusion virtualization software instead. This is a simplified visualization of what we are trying to achive:\\ Mac OS =&gt; VMware Fusion (virtualization software) =&gt; Ubuntu 22.04 + ROS2 Humble (container)\\ Since VMware Fusion can be taxing on resources of Mac laptops, we won't use Docker as a middle virtualization layer. Instead </p> <ol> <li>Download VMware Fusion 13. Use one of these options:<ul> <li>Follow UMD Terpware instructions</li> <li>Download VMware Fusion Tech Preview 2023 as described here</li> </ul> </li> <li>Install VMware Fusion 13 (Tech Preview) on your Mac laptop</li> <li>Download Ubuntu 22.04 desktop image<ul> <li>For older Macs download amd64 image from here</li> <li>For Macs with M1/M2 chips download arm64 image from here</li> </ul> </li> <li>Use the downloaded Ubuntu image to create a new Virtuale Machine</li> <li>Start the Virtuale Machine and follow instructions from \"PC with Ubuntu 22.04 ...\"</li> </ol>"},{"location":"enae450_readme/#installation-test","title":"Installation test","text":"<ol> <li>Start Docker container using image that you built (<code>tb3_image</code>).</li> <li>Verify that ROS2 environmental variables are set <pre><code>    env | grep ROS\n</code></pre></li> <li>Verify that graphics output is working (you should see a popup window with rotating gears) <pre><code>    glxgears\n</code></pre></li> <li>Verify that Gazebo is installed (you should see empty Gazebo environment) <pre><code>    ign gazebo empty.sdf\n</code></pre></li> </ol>"},{"location":"enae450_readme/#ide-installation-optional","title":"IDE installation (optional)","text":"<p>Install your IDE of choice, e.g. VS Code</p>"},{"location":"enae450_readme/#troubleshooting","title":"Troubleshooting","text":""},{"location":"enae450_readme/#general","title":"General","text":"<ol> <li> <p>Tmux shortcuts don't work (e.g. when trying to create new panes)</p> <ul> <li>If you are using setup with Docker, make sure that you copied the tmux config file into your home folder <pre><code>wget https://raw.githubusercontent.com/kanishkaganguly/dotfiles/master/tmux/.tmux.bash.conf -O $HOME/.tmux.conf\n</code></pre></li> <li>If you are using setup with Docker, talk to your instructor. Perhaps you are entering the shortcuts incorrectly</li> </ul> </li> <li> <p>Problems with listing ROS2 nodes</p> <ul> <li>Restart your ROS2 daemon <pre><code>ros2 daemon stop\nros2 daemon start\n</code></pre></li> </ul> </li> </ol>"},{"location":"enae450_readme/#windows-pc","title":"Windows PC","text":"<ol> <li> <p>Issues with connecting to Docker daemon but <code>docker version</code> works properly. Try starting docker service manually, in the WSL2 terminal run     <pre><code>sudo service docker start\n</code></pre>     If it works, you'll have to run this command every time you launch WSL2 terminal. There is a workaround that we can discuss deparately.</p> </li> <li> <p>When launching GUI apps in docker, it throws an error because it cannot access DISPLAY variable.</p> <ul> <li>If running Windows 10 make sure the OS build version is above 19044. If not, run the system update.</li> <li>In the Powershell run <pre><code>wsl --update\n</code></pre></li> <li>If the issue persists, check if you have the GPU drivers installed, see here</li> </ul> </li> </ol>"},{"location":"enae450_readme/#suggestion-windows-pc","title":"Suggestion (Windows PC)","text":"<ol> <li>Remove path to windows binaries in WSL2<ul> <li>Edit /etc/wsl.conf, e.g. <pre><code>    sudo nano /etc/wsl.conf\n</code></pre></li> <li>Add the following to the file <pre><code>    [interop]\n    appendWindowsPath = false\n</code></pre></li> <li>Restart WSL</li> </ul> </li> </ol>"},{"location":"gazebo-setup/","title":"\ud83c\udfae Gazebo Setup Guide","text":"**Set up and configure Gazebo for robot simulation**  *Learn to use Gazebo for simulating robots, testing algorithms, and visualizing robot behavior*"},{"location":"gazebo-setup/#overview","title":"\ud83c\udfaf Overview","text":"<p>Gazebo is a powerful 3D robot simulator that we'll use throughout ENME480 for testing robot control algorithms, visualizing robot movements, and simulating real-world scenarios. This guide covers installation, basic usage, and integration with ROS 2.</p>"},{"location":"gazebo-setup/#prerequisites","title":"\ud83d\udcbb Prerequisites","text":"<p>Before starting, ensure you have: - \u2705 Ubuntu 22.04 LTS installed (ROS 2 Humble Tier-1 platform) - \u2705 ROS 2 Humble installed and configured - \u2705 Graphics drivers installed and working - \u2705 At least 4GB RAM (8GB recommended)</p> <p>WSL/VM graphics</p> <p>In WSLg and VMs (UTM), Gazebo's GUI can be slower. Install the proper vGPU driver on Windows (WSLg) or drop graphics quality / use headless sim as needed.</p>"},{"location":"gazebo-setup/#install-gazebo-for-ros-2-humble-ubuntu-2204","title":"\ud83d\ude80 Install Gazebo for ROS 2 Humble (Ubuntu 22.04)","text":""},{"location":"gazebo-setup/#option-a-gazebo-classic-gazebo11-ros-interface-simple-stable","title":"Option A \u2014 Gazebo Classic (gazebo11) + ROS interface (simple &amp; stable)","text":"<pre><code>sudo apt update\nsudo apt install -y gazebo    # installs Gazebo Classic (gazebo11) on Ubuntu 22.04\nsudo apt install -y ros-humble-gazebo-ros-pkgs\n</code></pre>"},{"location":"gazebo-setup/#option-b-gazebo-gz-ignition-via-ros_gz-newer-stack","title":"Option B \u2014 Gazebo (GZ / Ignition) via ros_gz (newer stack)","text":"<ul> <li>For advanced users who want modern GZ features, see the official guide and <code>ros_gz</code> packages.</li> <li>Start here: https://gazebosim.org/docs/latest/ros_installation/ (migration notes: https://gazebosim.org/docs/latest/migrating_gazebo_classic_ros2_packages/)</li> </ul>"},{"location":"gazebo-setup/#verify-installation","title":"Verify Installation","text":"<pre><code># Check Gazebo version\ngazebo --version\n\n# Launch Gazebo\ngazebo\n</code></pre>"},{"location":"gazebo-setup/#basic-gazebo-concepts","title":"\ud83d\udd27 Basic Gazebo Concepts","text":""},{"location":"gazebo-setup/#world-files","title":"World Files","text":"<ul> <li>World files (<code>.world</code>) define the simulation environment</li> <li>Models represent robots, objects, and environments</li> <li>Physics engine handles collisions and dynamics</li> <li>Sensors provide simulated sensor data</li> </ul>"},{"location":"gazebo-setup/#key-components","title":"Key Components","text":"<ul> <li>World: 3D environment with physics</li> <li>Models: Robots, objects, buildings</li> <li>Links: Rigid bodies connected by joints</li> <li>Joints: Connections between links</li> <li>Sensors: Cameras, lasers, IMUs</li> </ul>"},{"location":"gazebo-setup/#launching-gazebo","title":"\ud83c\udfae Launching Gazebo","text":""},{"location":"gazebo-setup/#launch-from-terminal","title":"Launch from Terminal","text":"<pre><code># Launch empty world\ngazebo\n\n# Launch specific world file\ngazebo /usr/share/gazebo-11/worlds/empty.world\n\n# Launch with specific physics settings\ngazebo --physics-engine ode\n</code></pre>"},{"location":"gazebo-setup/#launch-from-ros-2","title":"Launch from ROS 2","text":"<pre><code># Launch Gazebo with ROS 2 integration\nros2 launch gazebo_ros gazebo.launch.py\n\n# Launch with specific world\nros2 launch gazebo_ros gazebo.launch.py world:=/path/to/world.world\n</code></pre>"},{"location":"gazebo-setup/#creating-a-simple-world","title":"\ud83c\udfd7\ufe0f Creating a Simple World","text":""},{"location":"gazebo-setup/#basic-world-file","title":"Basic World File","text":"<pre><code>&lt;?xml version=\"1.0\" ?&gt;\n&lt;sdf version=\"1.6\"&gt;\n  &lt;world name=\"default\"&gt;\n    &lt;!-- A global light source --&gt;\n    &lt;include&gt;\n      &lt;uri&gt;model://sun&lt;/uri&gt;\n    &lt;/include&gt;\n\n    &lt;!-- A ground plane --&gt;\n    &lt;include&gt;\n      &lt;uri&gt;model://ground_plane&lt;/uri&gt;\n    &lt;/include&gt;\n\n    &lt;!-- A simple box --&gt;\n    &lt;model name=\"box\"&gt;\n      &lt;static&gt;true&lt;/static&gt;\n      &lt;link name=\"link\"&gt;\n        &lt;collision name=\"collision\"&gt;\n          &lt;geometry&gt;\n            &lt;box&gt;\n              &lt;size&gt;1 1 1&lt;/size&gt;\n            &lt;/box&gt;\n          &lt;/geometry&gt;\n        &lt;/collision&gt;\n        &lt;visual name=\"visual\"&gt;\n          &lt;geometry&gt;\n            &lt;box&gt;\n              &lt;size&gt;1 1 1&lt;/size&gt;\n            &lt;/box&gt;\n          &lt;/geometry&gt;\n          &lt;material&gt;\n            &lt;ambient&gt;1 0 0 1&lt;/ambient&gt;\n            &lt;diffuse&gt;1 0 0 1&lt;/diffuse&gt;\n          &lt;/material&gt;\n        &lt;/visual&gt;\n      &lt;/link&gt;\n      &lt;pose&gt;0 0 0.5 0 0 0&lt;/pose&gt;\n    &lt;/model&gt;\n  &lt;/world&gt;\n&lt;/sdf&gt;\n</code></pre>"},{"location":"gazebo-setup/#save-and-load-world","title":"Save and Load World","text":"<pre><code># Save world file\n# Copy the XML above to ~/gazebo_worlds/simple.world\n\n# Launch custom world\ngazebo ~/gazebo_worlds/simple.world\n</code></pre>"},{"location":"gazebo-setup/#adding-robot-models","title":"\ud83e\udd16 Adding Robot Models","text":""},{"location":"gazebo-setup/#install-ur3e-model","title":"Install UR3e Model","text":"<pre><code># Clone UR3e model repository\ncd ~/ros2_ws/src\ngit clone https://github.com/UniversalRobots/Universal_Robots_ROS2_Description.git\n\n# Build workspace\ncd ~/ros2_ws\ncolcon build\n\n# Source workspace\nsource install/setup.bash\n</code></pre>"},{"location":"gazebo-setup/#launch-ur3e-in-gazebo","title":"Launch UR3e in Gazebo","text":"<pre><code># Launch UR3e in Gazebo\nros2 launch ur_gazebo ur3e_bringup.launch.py\n\n# Or launch with custom world\nros2 launch ur_gazebo ur3e_bringup.launch.py world:=~/gazebo_worlds/simple.world\n</code></pre>"},{"location":"gazebo-setup/#basic-gazebo-operations","title":"\ud83c\udfaf Basic Gazebo Operations","text":""},{"location":"gazebo-setup/#camera-controls","title":"Camera Controls","text":"<ul> <li>Mouse: Rotate view</li> <li>Scroll wheel: Zoom in/out</li> <li>Right-click + drag: Pan view</li> <li>Middle-click + drag: Rotate around point</li> </ul>"},{"location":"gazebo-setup/#model-manipulation","title":"Model Manipulation","text":"<ul> <li>Select model: Click on it</li> <li>Move model: Drag with left mouse button</li> <li>Rotate model: Drag with right mouse button</li> <li>Scale model: Use the scale handles</li> </ul>"},{"location":"gazebo-setup/#time-controls","title":"Time Controls","text":"<ul> <li>Play/Pause: Spacebar</li> <li>Step: Step button in toolbar</li> <li>Reset: Reset button in toolbar</li> <li>Real-time factor: Adjust in toolbar</li> </ul>"},{"location":"gazebo-setup/#using-gazebo-gui","title":"\ud83d\udd0d Using Gazebo GUI","text":""},{"location":"gazebo-setup/#main-toolbar","title":"Main Toolbar","text":"<ul> <li>Play/Pause: Start/stop simulation</li> <li>Step: Advance simulation one step</li> <li>Reset: Reset simulation to initial state</li> <li>Real-time factor: Speed up/slow down simulation</li> </ul>"},{"location":"gazebo-setup/#left-panel","title":"Left Panel","text":"<ul> <li>World: View world hierarchy</li> <li>Models: List all models in world</li> <li>Joints: View joint properties</li> <li>Sensors: Configure sensors</li> </ul>"},{"location":"gazebo-setup/#right-panel","title":"Right Panel","text":"<ul> <li>Properties: Edit selected object properties</li> <li>Material: Change object appearance</li> <li>Physics: Adjust physics properties</li> </ul>"},{"location":"gazebo-setup/#ros-2-integration","title":"\ud83d\udce1 ROS 2 Integration","text":""},{"location":"gazebo-setup/#gazebo-ros-2-plugins","title":"Gazebo ROS 2 Plugins","text":"<pre><code># Install Gazebo ROS 2 plugins\nsudo apt install ros-humble-gazebo-ros-pkgs\n\n# Check available plugins\ngazebo --help\n</code></pre>"},{"location":"gazebo-setup/#launch-file-example","title":"Launch File Example","text":"<pre><code>#!/usr/bin/env python3\nimport os\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration\nfrom launch_ros.actions import Node\nfrom ament_index_python.packages import get_package_share_directory\n\ndef generate_launch_description():\n    # Get the path to the package\n    pkg_gazebo_ros = get_package_share_directory('gazebo_ros')\n\n    # Declare launch arguments\n    world_file = LaunchConfiguration('world')\n\n    # Launch Gazebo\n    gazebo = Node(\n        package='gazebo_ros',\n        executable='gazebo',\n        name='gazebo',\n        output='screen',\n        arguments=[world_file]\n    )\n\n    return LaunchDescription([\n        DeclareLaunchArgument(\n            'world',\n            default_value=os.path.join(pkg_gazebo_ros, 'worlds', 'empty.world'),\n            description='Path to world file'\n        ),\n        gazebo\n    ])\n</code></pre>"},{"location":"gazebo-setup/#basic-simulation-examples","title":"\ud83e\uddea Basic Simulation Examples","text":""},{"location":"gazebo-setup/#example-1-simple-robot-movement","title":"Example 1: Simple Robot Movement","text":"<pre><code>#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Float64MultiArray\nfrom sensor_msgs.msg import JointState\n\nclass UR3eController(Node):\n    def __init__(self):\n        super().__init__('ur3e_controller')\n\n        # Publisher for joint commands\n        self.joint_pub = self.create_publisher(\n            Float64MultiArray,\n            '/joint_group_position_controller/commands',\n            10\n        )\n\n        # Subscriber for joint states\n        self.joint_sub = self.create_subscription(\n            JointState,\n            '/joint_states',\n            self.joint_callback,\n            10\n        )\n\n        # Timer for periodic commands\n        self.timer = self.create_timer(2.0, self.timer_callback)\n\n        self.get_logger().info('UR3e controller started')\n\n    def joint_callback(self, msg):\n        \"\"\"Callback for joint state updates.\"\"\"\n        if len(msg.position) &gt;= 6:\n            self.get_logger().info(f'Joint angles: {[f\"{x:.2f}\" for x in msg.position[:6]]}')\n\n    def timer_callback(self):\n        \"\"\"Send periodic joint commands.\"\"\"\n        # Simple sinusoidal movement\n        import math\n        import time\n\n        t = time.time()\n        joint_angles = [\n            0.0,  # Base\n            math.sin(t) * 0.5,  # Shoulder\n            math.cos(t) * 0.5,  # Elbow\n            0.0,  # Wrist 1\n            0.0,  # Wrist 2\n            0.0   # Wrist 3\n        ]\n\n        joint_msg = Float64MultiArray()\n        joint_msg.data = joint_angles\n        self.joint_pub.publish(joint_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = UR3eController()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"gazebo-setup/#example-2-camera-visualization","title":"Example 2: Camera Visualization","text":"<pre><code>#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\nimport cv2\n\nclass CameraViewer(Node):\n    def __init__(self):\n        super().__init__('camera_viewer')\n\n        # Subscribe to camera topic\n        self.camera_sub = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.camera_callback,\n            10\n        )\n\n        self.bridge = CvBridge()\n        self.get_logger().info('Camera viewer started')\n\n    def camera_callback(self, msg):\n        \"\"\"Display camera image.\"\"\"\n        try:\n            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\n            cv2.imshow(\"Camera Feed\", cv_image)\n            cv2.waitKey(1)\n        except Exception as e:\n            self.get_logger().error(f'Error processing image: {e}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = CameraViewer()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"gazebo-setup/#troubleshooting-common-issues","title":"\ud83d\udd27 Troubleshooting Common Issues","text":""},{"location":"gazebo-setup/#performance-issues","title":"Performance Issues","text":"Problem Solution Slow simulation Reduce physics update rate, use simpler models High CPU usage Close other applications, reduce model complexity Memory issues Use fewer models, restart Gazebo"},{"location":"gazebo-setup/#graphics-issues","title":"Graphics Issues","text":"Problem Solution Black screen Check graphics drivers, try software rendering Low FPS Reduce graphics quality, use simpler models Model not visible Check model URDF, verify file paths"},{"location":"gazebo-setup/#ros-2-integration-issues","title":"ROS 2 Integration Issues","text":"Problem Solution Topics not appearing Check launch file, verify package installation Models not loading Check URDF files, verify package paths Physics not working Check physics engine, verify model collision"},{"location":"gazebo-setup/#advanced-features","title":"\ud83d\udcda Advanced Features","text":""},{"location":"gazebo-setup/#custom-models","title":"Custom Models","text":"<pre><code># Create model directory\nmkdir -p ~/.gazebo/models/my_robot\n\n# Create model.config file\ncat &gt; ~/.gazebo/models/my_robot/model.config &lt;&lt; EOF\n&lt;?xml version=\"1.0\"?&gt;\n&lt;model&gt;\n  &lt;name&gt;My Robot&lt;/name&gt;\n  &lt;version&gt;1.0&lt;/version&gt;\n  &lt;sdf version=\"1.6\"&gt;model.sdf&lt;/sdf&gt;\n  &lt;description&gt;My custom robot model&lt;/description&gt;\n&lt;/model&gt;\nEOF\n\n# Create model.sdf file (similar to world file)\n# ... create SDF file ...\n</code></pre>"},{"location":"gazebo-setup/#physics-parameters","title":"Physics Parameters","text":"<pre><code>&lt;!-- In world file --&gt;\n&lt;physics type=\"ode\"&gt;\n  &lt;max_step_size&gt;0.001&lt;/max_step_size&gt;\n  &lt;real_time_factor&gt;1.0&lt;/real_time_factor&gt;\n  &lt;real_time_update_rate&gt;1000&lt;/real_time_update_rate&gt;\n  &lt;gravity&gt;0 0 -9.81&lt;/gravity&gt;\n&lt;/physics&gt;\n</code></pre>"},{"location":"gazebo-setup/#verification-checklist","title":"\u2705 Verification Checklist","text":"<ul> <li>[ ] Gazebo launches successfully</li> <li>[ ] ROS 2 integration working</li> <li>[ ] UR3e model loads correctly</li> <li>[ ] Basic simulation runs</li> <li>[ ] Camera visualization working</li> <li>[ ] Joint control functional</li> <li>[ ] Physics simulation realistic</li> </ul>"},{"location":"gazebo-setup/#getting-help","title":"\ud83c\udd98 Getting Help","text":""},{"location":"gazebo-setup/#gazebo-resources","title":"Gazebo Resources","text":"<ul> <li>Official Docs: gazebosim.org</li> <li>ROS 2 Integration: docs.ros.org</li> <li>Community Forum: answers.gazebosim.org</li> </ul>"},{"location":"gazebo-setup/#course-support","title":"Course Support","text":"<ul> <li>Piazza: Ask questions on course forum</li> <li>Office Hours: Get help from TA or instructor</li> <li>Lab Sessions: Hands-on help during labs</li> </ul>"},{"location":"gazebo-setup/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<p>After setting up Gazebo:</p> <ol> <li>Practice basic operations in empty world</li> <li>Load and control UR3e robot</li> <li>Start Week 4 lab: See Week 4 Lab</li> <li>Experiment with different worlds and models</li> </ol>   **Ready to simulate robots? Let's start the Week 4 lab! \ud83c\udfae**  [\ud83d\udc0d Python Basics](python-basics.md){ .md-button } [\ud83e\udd16 ROS Setup](ros-setup.md){ .md-button } [\ud83d\udcda Back to Resources](resources.md){ .md-button }   <p>Last updated: Fall 2025 \u2022 Back to Resources</p>"},{"location":"git-basics/","title":"\ud83d\udd27 Git &amp; GitHub Basics","text":"**Essential version control for robotics development**  *Learn Git to manage your lab code, collaborate with teammates, and track your progress*"},{"location":"git-basics/#overview","title":"\ud83c\udfaf Overview","text":"<p>Git is a version control system that helps you track changes in your code, collaborate with others, and maintain a history of your work. This guide covers the essential Git commands you'll need for ENME480 labs and projects.</p>"},{"location":"git-basics/#prerequisites","title":"\ud83d\udcbb Prerequisites","text":"<p>Before starting, ensure you have: - \u2705 Git installed on your system - \u2705 GitHub account created - \u2705 Basic terminal knowledge</p>"},{"location":"git-basics/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"git-basics/#install-git","title":"Install Git","text":"<pre><code># Ubuntu/Debian\nsudo apt install git\n\n# Check installation\ngit --version\n</code></pre>"},{"location":"git-basics/#configure-git","title":"Configure Git","text":"<pre><code># Set your name and email\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@umd.edu\"\n\n# Check configuration\ngit config --list\n</code></pre>"},{"location":"git-basics/#core-git-concepts","title":"\ud83d\udcda Core Git Concepts","text":""},{"location":"git-basics/#repository-repo","title":"Repository (Repo)","text":"<ul> <li>Local repository: Git repository on your computer</li> <li>Remote repository: Git repository on GitHub/GitLab</li> <li>Clone: Copy remote repository to local machine</li> </ul>"},{"location":"git-basics/#working-directory","title":"Working Directory","text":"<ul> <li>Working directory: Where you edit files</li> <li>Staging area: Area where changes are prepared for commit</li> <li>Repository: Where committed changes are stored</li> </ul>"},{"location":"git-basics/#basic-workflow","title":"Basic Workflow","text":"<ol> <li>Edit files in working directory</li> <li>Stage changes to staging area</li> <li>Commit changes to repository</li> <li>Push changes to remote repository</li> </ol>"},{"location":"git-basics/#essential-git-commands","title":"\ud83d\udd27 Essential Git Commands","text":""},{"location":"git-basics/#initializing-a-repository","title":"Initializing a Repository","text":"<pre><code># Create new repository\ngit init\n\n# Clone existing repository\ngit clone https://github.com/username/repository.git\n\n# Check repository status\ngit status\n</code></pre>"},{"location":"git-basics/#making-changes","title":"Making Changes","text":"<pre><code># Stage all changes\ngit add .\n\n# Stage specific files\ngit add filename.py\ngit add *.py\n\n# Check what's staged\ngit diff --cached\n\n# Commit changes\ngit commit -m \"Add robot control functions\"\n\n# Check commit history\ngit log\ngit log --oneline\n</code></pre>"},{"location":"git-basics/#managing-branches","title":"Managing Branches","text":"<pre><code># List branches\ngit branch\n\n# Create new branch\ngit branch feature-name\n\n# Switch to branch\ngit checkout feature-name\n\n# Create and switch to new branch\ngit checkout -b feature-name\n\n# Merge branch\ngit checkout main\ngit merge feature-name\n\n# Delete branch\ngit branch -d feature-name\n</code></pre>"},{"location":"git-basics/#working-with-github","title":"\ud83c\udf10 Working with GitHub","text":""},{"location":"git-basics/#setting-up-ssh-keys","title":"Setting up SSH Keys","text":"<pre><code># Generate SSH key\nssh-keygen -t ed25519 -C \"your.email@umd.edu\"\n\n# Start SSH agent\neval \"$(ssh-agent -s)\"\n\n# Add SSH key\nssh-add ~/.ssh/id_ed25519\n\n# Copy public key to GitHub\ncat ~/.ssh/id_ed25519.pub\n</code></pre>"},{"location":"git-basics/#remote-operations","title":"Remote Operations","text":"<pre><code># Add remote repository\ngit remote add origin https://github.com/username/repository.git\n\n# Check remotes\ngit remote -v\n\n# Push changes\ngit push origin main\n\n# Pull changes\ngit pull origin main\n\n# Fetch changes (without merging)\ngit fetch origin\n</code></pre>"},{"location":"git-basics/#common-workflows","title":"\ud83d\udcdd Common Workflows","text":""},{"location":"git-basics/#daily-workflow","title":"Daily Workflow","text":"<pre><code># Start of day - get latest changes\ngit pull origin main\n\n# Make changes to files\n# ... edit files ...\n\n# Check what changed\ngit status\ngit diff\n\n# Stage and commit changes\ngit add .\ngit commit -m \"Implement joint limit checking\"\n\n# Push changes\ngit push origin main\n</code></pre>"},{"location":"git-basics/#feature-development","title":"Feature Development","text":"<pre><code># Create feature branch\ngit checkout -b feature/joint-control\n\n# Make changes\n# ... implement feature ...\n\n# Commit changes\ngit add .\ngit commit -m \"Add joint control system\"\n\n# Push feature branch\ngit push origin feature/joint-control\n\n# Create pull request on GitHub\n# ... merge on GitHub ...\n\n# Switch back to main\ngit checkout main\ngit pull origin main\n\n# Delete feature branch\ngit branch -d feature/joint-control\n</code></pre>"},{"location":"git-basics/#useful-git-commands","title":"\ud83d\udd0d Useful Git Commands","text":""},{"location":"git-basics/#viewing-history","title":"Viewing History","text":"<pre><code># View commit history\ngit log --oneline --graph\n\n# View changes in specific commit\ngit show commit_hash\n\n# View changes in working directory\ngit diff\n\n# View staged changes\ngit diff --cached\n</code></pre>"},{"location":"git-basics/#managing-files","title":"Managing Files","text":"<pre><code># Remove file from Git\ngit rm filename.py\n\n# Rename file\ngit mv oldname.py newname.py\n\n# Ignore files\necho \"*.log\" &gt;&gt; .gitignore\necho \"build/\" &gt;&gt; .gitignore\n</code></pre>"},{"location":"git-basics/#undoing-changes","title":"Undoing Changes","text":"<pre><code># Undo last commit (keep changes)\ngit reset --soft HEAD~1\n\n# Undo last commit (discard changes)\ngit reset --hard HEAD~1\n\n# Undo changes in working directory\ngit checkout -- filename.py\n\n# Revert specific commit\ngit revert commit_hash\n</code></pre>"},{"location":"git-basics/#github-desktop-optional","title":"\ud83d\udcf1 GitHub Desktop (Optional)","text":""},{"location":"git-basics/#why-use-github-desktop","title":"Why Use GitHub Desktop?","text":"<ul> <li>Visual interface for Git operations</li> <li>Easier for beginners than command line</li> <li>Built-in merge conflict resolution</li> <li>Good for simple workflows</li> </ul>"},{"location":"git-basics/#installation","title":"Installation","text":"<pre><code># Download from GitHub\n# https://desktop.github.com/\n\n# Install and authenticate with your GitHub account\n</code></pre>"},{"location":"git-basics/#practice-exercises","title":"\ud83e\uddea Practice Exercises","text":""},{"location":"git-basics/#exercise-1-create-a-lab-repository","title":"Exercise 1: Create a Lab Repository","text":"<pre><code># Create directory for lab work\nmkdir enme480-labs\ncd enme480-labs\n\n# Initialize Git repository\ngit init\n\n# Create README file\necho \"# ENME480 Lab Work\" &gt; README.md\n\n# Make first commit\ngit add README.md\ngit commit -m \"Initial commit: Add README\"\n\n# Create GitHub repository and push\ngit remote add origin https://github.com/username/enme480-labs.git\ngit push -u origin main\n</code></pre>"},{"location":"git-basics/#exercise-2-work-with-branches","title":"Exercise 2: Work with Branches","text":"<pre><code># Create feature branch\ngit checkout -b lab/week1\n\n# Create lab file\necho \"# Week 1 Lab\" &gt; week1.md\n\n# Commit changes\ngit add week1.md\ngit commit -m \"Add Week 1 lab notes\"\n\n# Push feature branch\ngit push origin lab/week1\n\n# Switch back to main\ngit checkout main\n\n# Merge feature branch\ngit merge lab/week1\n\n# Push merged changes\ngit push origin main\n</code></pre>"},{"location":"git-basics/#troubleshooting-common-issues","title":"\ud83d\udd27 Troubleshooting Common Issues","text":""},{"location":"git-basics/#merge-conflicts","title":"Merge Conflicts","text":"<pre><code># When you get a merge conflict\ngit status  # See conflicted files\n\n# Edit conflicted files to resolve conflicts\n# Look for &lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt; markers\n\n# After resolving conflicts\ngit add .\ngit commit -m \"Resolve merge conflicts\"\n</code></pre>"},{"location":"git-basics/#authentication-issues","title":"Authentication Issues","text":"<pre><code># If you get authentication errors\ngit config --global credential.helper store\n\n# Or use personal access token\n# Generate token on GitHub: Settings \u2192 Developer settings \u2192 Personal access tokens\n</code></pre>"},{"location":"git-basics/#large-files","title":"Large Files","text":"<pre><code># If you accidentally commit large files\ngit filter-branch --tree-filter 'rm -f large_file.dat' HEAD\n\n# Or use Git LFS for large files\ngit lfs install\ngit lfs track \"*.dat\"\n</code></pre>"},{"location":"git-basics/#git-best-practices","title":"\ud83d\udcda Git Best Practices","text":""},{"location":"git-basics/#commit-messages","title":"Commit Messages","text":"<ul> <li>Use present tense: \"Add feature\" not \"Added feature\"</li> <li>Be descriptive: \"Implement joint limit checking\" not \"Fix bug\"</li> <li>Keep it short: First line under 50 characters</li> <li>Use imperative mood: \"Add\", \"Fix\", \"Update\", \"Remove\"</li> </ul>"},{"location":"git-basics/#branch-naming","title":"Branch Naming","text":"<ul> <li>Feature branches: <code>feature/description</code></li> <li>Bug fixes: <code>fix/description</code></li> <li>Lab work: <code>lab/week1</code>, <code>lab/week2</code></li> <li>Project work: <code>project/final-project</code></li> </ul>"},{"location":"git-basics/#when-to-commit","title":"When to Commit","text":"<ul> <li>After completing a logical unit of work</li> <li>Before making major changes to working code</li> <li>After fixing a bug or implementing a feature</li> <li>At the end of each lab session</li> </ul>"},{"location":"git-basics/#getting-help","title":"\ud83c\udd98 Getting Help","text":""},{"location":"git-basics/#git-resources","title":"Git Resources","text":"<ul> <li>Git Documentation: git-scm.com</li> <li>GitHub Guides: guides.github.com</li> <li>Git Cheat Sheet: git-scm.com</li> </ul>"},{"location":"git-basics/#course-support","title":"Course Support","text":"<ul> <li>Piazza: Ask questions on course forum</li> <li>Office Hours: Get help from TA or instructor</li> <li>Lab Sessions: Hands-on help during labs</li> </ul>"},{"location":"git-basics/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<p>After mastering Git basics:</p> <ol> <li>Set up your lab repository on GitHub</li> <li>Practice with daily commits during lab work</li> <li>Collaborate with teammates on group projects</li> <li>Learn advanced Git features as needed</li> </ol>   **Ready to manage your code? Let's set up your lab repository! \ud83d\udcda**  [\ud83d\udc27 Ubuntu Setup](ubuntu-setup.md){ .md-button } [\ud83e\udd16 ROS Setup](ros-setup.md){ .md-button } [\ud83d\udcda Back to Resources](resources.md){ .md-button }   <p>Last updated: Fall 2025 \u2022 Back to Resources</p>"},{"location":"help/","title":"\ud83c\udd98 Help &amp; Support","text":"**Need assistance? You're in the right place!**   *Everything you need to succeed in ENME480.*"},{"location":"help/#contact","title":"\ud83d\udcde Contact","text":"Who Details Best for \ud83c\udf93 Instructor \u2013 Dr. Nikhil Chopra Office Hours: Wed 10\u201311:30, 2149 Martin Hall \u2022 Email: nchopra@umd.edu \u2022 Zoom (syllabus link) Course content, grades, personal issues \ud83d\udc68\u200d\ud83d\udcbb TAs \u2013 Alex Beyer, Kaustubh Joshi Emails: abeyer@umd.edu, kjoshi@umd.edu \u2022 Office Hours: TBD Labs &amp; technical questions \ud83d\udcac Piazza piazza.com/umd/fall2025/enme480 Official Q&amp;A and announcements \ud83d\udce7 Canvas (ELMS) elms.umd.edu Materials, submissions, grades \ud83e\uddd1\u200d\ud83d\udcbb GitHub github.com/ENME480 Lab code &amp; updates"},{"location":"help/#emergency-safety","title":"\ud83d\udea8 Emergency &amp; Safety","text":"<ul> <li>Complete required safety training before entering RAL and using robots.  </li> <li>Never bypass safety systems; stay clear of the robot workspace; hit E-Stop when in doubt.  </li> <li>For medical or fire emergencies, call 911 / campus police; follow posted lab procedures.</li> </ul>"},{"location":"help/#lab-support","title":"\ud83e\uddea Lab Support","text":"<p>Before lab: finish pre-lab reading, set up ROS 2, review safety. During lab: ask TAs early; report equipment issues immediately. Attendance: Studios are mandatory; late/missed attendance may affect grades; coordinate via Piazza if conflicts arise. Homework cadence: posted Fridays 11:59pm, due a week later via Canvas.</p>"},{"location":"help/#quick-troubleshooting","title":"\ud83d\udcbb Quick Troubleshooting","text":""},{"location":"help/#ubuntu","title":"Ubuntu","text":"<pre><code>lsb_release -a\nsudo apt update &amp;&amp; sudo apt upgrade\ndf -h\n</code></pre>"},{"location":"help/#python","title":"Python","text":"<pre><code>python3 --version\npython3 -m pip install --upgrade pip\n</code></pre>"},{"location":"help/#ros-2","title":"ROS 2","text":"<pre><code>ros2 --help\nsource /opt/ros/humble/setup.bash\nros2 topic list\n</code></pre>"},{"location":"help/#learning-resources","title":"\ud83d\udcda Learning Resources","text":"<ul> <li>ROS 2 Docs (Humble)</li> <li>Python Docs \u2022 Ubuntu Help</li> <li>Gazebo Tutorials (or Ignition Gazebo)</li> <li>Stack Overflow \u2022 ROS Answers</li> </ul>"},{"location":"help/#asking-great-questions","title":"\ud83c\udfaf Asking Great Questions","text":"<ol> <li>Search Piazza/Canvas first \u2192 2) Try a fix \u2192 3) Share error + steps tried \u2192 4) Minimal code reproducer.    Example: \"<code>ros2 run my_pkg node</code> fails with <code>ImportError: \u2026</code>. I re-sourced <code>setup.bash</code>, verified <code>PYTHONPATH</code>, and rebuilt. Full stack trace: \u2026\"</li> </ol> <p>Last updated: Fall 2025 \u2022 Back to Home</p>"},{"location":"kinematics-reference/","title":"\ud83d\udcd0 Kinematics Reference","text":"**Essential kinematics formulas and reference materials**  *DH parameters, transformation matrices, forward/inverse kinematics for robotics*"},{"location":"kinematics-reference/#overview","title":"\ud83c\udfaf Overview","text":"<p>This reference guide contains essential kinematics formulas, DH parameters, and mathematical tools you'll need for ENME480. Keep this handy during labs and homework assignments.</p>"},{"location":"kinematics-reference/#mathematical-fundamentals","title":"\ud83d\udd22 Mathematical Fundamentals","text":""},{"location":"kinematics-reference/#rotation-matrices","title":"Rotation Matrices","text":"<pre><code>import numpy as np\n\n# Rotation around X-axis (roll)\ndef Rx(theta):\n    return np.array([\n        [1, 0, 0],\n        [0, np.cos(theta), -np.sin(theta)],\n        [0, np.sin(theta), np.cos(theta)]\n    ])\n\n# Rotation around Y-axis (pitch)\ndef Ry(theta):\n    return np.array([\n        [np.cos(theta), 0, np.sin(theta)],\n        [0, 1, 0],\n        [-np.sin(theta), 0, np.cos(theta)]\n    ])\n\n# Rotation around Z-axis (yaw)\ndef Rz(theta):\n    return np.array([\n        [np.cos(theta), -np.sin(theta), 0],\n        [np.sin(theta), np.cos(theta), 0],\n        [0, 0, 1]\n    ])\n\n# Combined rotation (ZYX Euler angles)\ndef Rzyx(roll, pitch, yaw):\n    return Rz(yaw) @ Ry(pitch) @ Rx(roll)\n</code></pre>"},{"location":"kinematics-reference/#homogeneous-transformations","title":"Homogeneous Transformations","text":"<pre><code>def homogeneous_transform(R, p):\n    \"\"\"Create 4x4 homogeneous transformation matrix.\"\"\"\n    T = np.eye(4)\n    T[:3, :3] = R\n    T[:3, 3] = p\n    return T\n\ndef translation_matrix(x, y, z):\n    \"\"\"Create translation matrix.\"\"\"\n    return np.array([\n        [1, 0, 0, x],\n        [0, 1, 0, y],\n        [0, 0, 1, z],\n        [0, 0, 0, 1]\n    ])\n\ndef rotation_matrix(R):\n    \"\"\"Create rotation matrix.\"\"\"\n    T = np.eye(4)\n    T[:3, :3] = R\n    return T\n</code></pre>"},{"location":"kinematics-reference/#dh-parameters","title":"\ud83e\udd16 DH Parameters","text":""},{"location":"kinematics-reference/#dh-parameter-table","title":"DH Parameter Table","text":"Joint \u03b8 d a \u03b1 Base \u03b8\u2081 d\u2081 a\u2081 \u03b1\u2081 Shoulder \u03b8\u2082 d\u2082 a\u2082 \u03b1\u2082 Elbow \u03b8\u2083 d\u2083 a\u2083 \u03b1\u2083 Wrist 1 \u03b8\u2084 d\u2084 a\u2084 \u03b1\u2084 Wrist 2 \u03b8\u2085 d\u2085 a\u2085 \u03b1\u2085 Wrist 3 \u03b8\u2086 d\u2086 a\u2086 \u03b1\u2086"},{"location":"kinematics-reference/#dh-transformation-matrix","title":"DH Transformation Matrix","text":"<pre><code>def dh_transform(theta, d, a, alpha):\n    \"\"\"Compute DH transformation matrix.\"\"\"\n    ct = np.cos(theta)\n    st = np.sin(theta)\n    ca = np.cos(alpha)\n    sa = np.sin(alpha)\n\n    T = np.array([\n        [ct, -st*ca, st*sa, a*ct],\n        [st, ct*ca, -ct*sa, a*st],\n        [0, sa, ca, d],\n        [0, 0, 0, 1]\n    ])\n\n    return T\n</code></pre>"},{"location":"kinematics-reference/#ur3e-dh-parameters","title":"\ud83e\uddbe UR3e DH Parameters","text":""},{"location":"kinematics-reference/#standard-dh-parameters","title":"Standard DH Parameters","text":"<pre><code># UR3e DH parameters (in meters and radians)\nur3e_dh = [\n    # [theta, d, a, alpha]\n    [0, 0.1519, 0, -np.pi/2],      # Base\n    [0, 0, -0.24365, 0],           # Shoulder\n    [0, 0, -0.21325, 0],           # Elbow\n    [0, 0.11235, 0, -np.pi/2],     # Wrist 1\n    [0, 0.08535, 0, np.pi/2],      # Wrist 2\n    [0, 0.0819, 0, 0]              # Wrist 3\n]\n\n# Joint limits (in radians)\nur3e_limits = [\n    [-2*np.pi, 2*np.pi],    # Base\n    [-2*np.pi, 2*np.pi],    # Shoulder\n    [-np.pi, 0],             # Elbow\n    [-2*np.pi, 2*np.pi],    # Wrist 1\n    [-2*np.pi, 2*np.pi],    # Wrist 2\n    [-2*np.pi, 2*np.pi]     # Wrist 3\n]\n</code></pre>"},{"location":"kinematics-reference/#modified-dh-parameters","title":"Modified DH Parameters","text":"<pre><code># Modified DH parameters (alternative convention)\nur3e_mdh = [\n    # [theta, d, a, alpha]\n    [0, 0.1519, 0, 0],             # Base\n    [0, 0, 0.24365, -np.pi/2],     # Shoulder\n    [0, 0, 0.21325, 0],            # Elbow\n    [0, 0.11235, 0, -np.pi/2],     # Wrist 1\n    [0, 0.08535, 0, np.pi/2],      # Wrist 2\n    [0, 0.0819, 0, 0]              # Wrist 3\n]\n</code></pre>"},{"location":"kinematics-reference/#forward-kinematics","title":"\u27a1\ufe0f Forward Kinematics","text":""},{"location":"kinematics-reference/#basic-forward-kinematics","title":"Basic Forward Kinematics","text":"<pre><code>def forward_kinematics(joint_angles, dh_params):\n    \"\"\"Compute forward kinematics using DH parameters.\"\"\"\n    T = np.eye(4)\n\n    for i, (theta, d, a, alpha) in enumerate(dh_params):\n        # Add joint angle to theta\n        current_theta = theta + joint_angles[i]\n\n        # Compute transformation for this joint\n        Ti = dh_transform(current_theta, d, a, alpha)\n\n        # Multiply transformations\n        T = T @ Ti\n\n    return T\n\n# Example usage\njoint_angles = [0, -np.pi/2, 0, 0, 0, 0]  # Home position\nT_end_effector = forward_kinematics(joint_angles, ur3e_dh)\n\n# Extract position and orientation\nposition = T_end_effector[:3, 3]\norientation = T_end_effector[:3, :3]\n</code></pre>"},{"location":"kinematics-reference/#position-and-orientation-extraction","title":"Position and Orientation Extraction","text":"<pre><code>def extract_pose(T):\n    \"\"\"Extract position and orientation from transformation matrix.\"\"\"\n    position = T[:3, 3]\n    orientation = T[:3, :3]\n\n    # Convert to Euler angles (ZYX convention)\n    yaw = np.arctan2(orientation[1, 0], orientation[0, 0])\n    pitch = np.arctan2(-orientation[2, 0], \n                       np.sqrt(orientation[2, 1]**2 + orientation[2, 2]**2))\n    roll = np.arctan2(orientation[2, 1], orientation[2, 2])\n\n    return position, np.array([roll, pitch, yaw])\n\ndef extract_quaternion(T):\n    \"\"\"Extract quaternion from transformation matrix.\"\"\"\n    from scipy.spatial.transform import Rotation as R\n\n    orientation = T[:3, :3]\n    r = R.from_matrix(orientation)\n    return r.as_quat()  # [x, y, z, w]\n</code></pre>"},{"location":"kinematics-reference/#inverse-kinematics","title":"\u2b05\ufe0f Inverse Kinematics","text":""},{"location":"kinematics-reference/#analytical-ik-for-ur3e","title":"Analytical IK for UR3e","text":"<pre><code>def ur3e_inverse_kinematics(T_desired, elbow_config=1):\n    \"\"\"\n    Analytical inverse kinematics for UR3e.\n\n    Args:\n        T_desired: Desired end-effector pose (4x4 matrix)\n        elbow_config: 1 for elbow up, -1 for elbow down\n\n    Returns:\n        List of joint angles (6x1)\n    \"\"\"\n    # Extract position and orientation\n    p_desired = T_desired[:3, 3]\n    R_desired = T_desired[:3, :3]\n\n    # DH parameters\n    d1, d4, d5, d6 = 0.1519, 0.11235, 0.08535, 0.0819\n    a2, a3 = 0.24365, 0.21325\n\n    # Wrist center position\n    p_wrist = p_desired - d6 * R_desired[:, 2]\n\n    # Joint 1 (base rotation)\n    theta1 = np.arctan2(p_wrist[1], p_wrist[0])\n\n    # Joint 2 and 3 (shoulder and elbow)\n    r = np.sqrt(p_wrist[0]**2 + p_wrist[1]**2)\n    s = p_wrist[2] - d1\n\n    # Cosine law\n    D = (r**2 + s**2 - a2**2 - a3**2) / (2 * a2 * a3)\n\n    if abs(D) &gt; 1:\n        raise ValueError(\"Target position not reachable\")\n\n    theta3 = elbow_config * np.arccos(D)\n    theta2 = np.arctan2(s, r) - np.arctan2(a3 * np.sin(theta3), \n                                           a2 + a3 * np.cos(theta3))\n\n    # Joints 4, 5, 6 (wrist)\n    R03 = forward_kinematics([theta1, theta2, theta3, 0, 0, 0], ur3e_dh)[:3, :3]\n    R36 = R03.T @ R_desired\n\n    # Extract Euler angles from R36\n    theta4 = np.arctan2(R36[1, 2], R36[0, 2])\n    theta5 = np.arctan2(np.sqrt(R36[0, 2]**2 + R36[1, 2]**2), R36[2, 2])\n    theta6 = np.arctan2(-R36[2, 1], R36[2, 0])\n\n    return [theta1, theta2, theta3, theta4, theta5, theta6]\n\n# Example usage\nT_desired = np.eye(4)\nT_desired[:3, 3] = [0.3, 0.0, 0.5]  # Desired position\n\ntry:\n    joint_angles = ur3e_inverse_kinematics(T_desired, elbow_config=1)\n    print(f\"Joint angles: {[f'{x:.3f}' for x in joint_angles]}\")\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"kinematics-reference/#numerical-ik-jacobian-method","title":"Numerical IK (Jacobian Method)","text":"<pre><code>def numerical_inverse_kinematics(T_desired, initial_guess, max_iter=100, tol=1e-6):\n    \"\"\"Numerical inverse kinematics using Jacobian method.\"\"\"\n    from scipy.optimize import minimize\n\n    def objective_function(joint_angles):\n        T_current = forward_kinematics(joint_angles, ur3e_dh)\n\n        # Position error\n        pos_error = np.linalg.norm(T_current[:3, 3] - T_desired[:3, 3])\n\n        # Orientation error (simplified)\n        ori_error = np.linalg.norm(T_current[:3, :3] - T_desired[:3, :3])\n\n        return pos_error + 0.1 * ori_error\n\n    # Minimize objective function\n    result = minimize(objective_function, initial_guess, \n                     method='L-BFGS-B', \n                     bounds=ur3e_limits,\n                     options={'maxiter': max_iter})\n\n    if result.success:\n        return result.x\n    else:\n        raise ValueError(\"IK optimization failed\")\n\n# Example usage\ninitial_guess = [0, -np.pi/2, 0, 0, 0, 0]\ntry:\n    joint_angles = numerical_inverse_kinematics(T_desired, initial_guess)\n    print(f\"Numerical IK result: {[f'{x:.3f}' for x in joint_angles]}\")\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"kinematics-reference/#jacobian-matrix","title":"\ud83d\udd04 Jacobian Matrix","text":""},{"location":"kinematics-reference/#analytical-jacobian","title":"Analytical Jacobian","text":"<pre><code>def compute_jacobian(joint_angles, dh_params):\n    \"\"\"Compute analytical Jacobian matrix.\"\"\"\n    n_joints = len(dh_params)\n    J = np.zeros((6, n_joints))\n\n    # Current end-effector pose\n    T_current = forward_kinematics(joint_angles, dh_params)\n    p_current = T_current[:3, 3]\n\n    # Compute Jacobian columns\n    for i in range(n_joints):\n        # Perturb joint i\n        joint_angles_perturbed = joint_angles.copy()\n        joint_angles_perturbed[i] += 1e-6\n\n        # Compute perturbed pose\n        T_perturbed = forward_kinematics(joint_angles_perturbed, dh_params)\n        p_perturbed = T_perturbed[:3, 3]\n\n        # Linear velocity component\n        J[:3, i] = (p_perturbed - p_current) / 1e-6\n\n        # Angular velocity component (simplified)\n        # For full implementation, compute orientation differences\n\n    return J\n\n# Example usage\njoint_angles = [0, -np.pi/2, 0, 0, 0, 0]\nJ = compute_jacobian(joint_angles, ur3e_dh)\nprint(f\"Jacobian shape: {J.shape}\")\n</code></pre>"},{"location":"kinematics-reference/#jacobian-based-control","title":"Jacobian-Based Control","text":"<pre><code>def jacobian_control(joint_angles, desired_velocity, dh_params, dt=0.01):\n    \"\"\"Simple Jacobian-based velocity control.\"\"\"\n    J = compute_jacobian(joint_angles, dh_params)\n\n    # Pseudo-inverse of Jacobian\n    J_inv = np.linalg.pinv(J)\n\n    # Joint velocities\n    joint_velocities = J_inv @ desired_velocity\n\n    # Update joint angles\n    new_joint_angles = joint_angles + joint_velocities * dt\n\n    return new_joint_angles\n\n# Example usage\ndesired_velocity = np.array([0.1, 0, 0, 0, 0, 0])  # Move in X direction\nnew_angles = jacobian_control(joint_angles, desired_velocity, ur3e_dh)\n</code></pre>"},{"location":"kinematics-reference/#trajectory-generation","title":"\ud83d\udcca Trajectory Generation","text":""},{"location":"kinematics-reference/#linear-trajectory","title":"Linear Trajectory","text":"<pre><code>def linear_trajectory(start_pos, end_pos, num_points):\n    \"\"\"Generate linear trajectory between two points.\"\"\"\n    t = np.linspace(0, 1, num_points)\n\n    trajectory = []\n    for ti in t:\n        pos = start_pos + ti * (end_pos - start_pos)\n        trajectory.append(pos)\n\n    return np.array(trajectory)\n\n# Example usage\nstart_pos = np.array([0.3, 0.0, 0.5])\nend_pos = np.array([0.5, 0.2, 0.3])\ntrajectory = linear_trajectory(start_pos, end_pos, 50)\n</code></pre>"},{"location":"kinematics-reference/#joint-space-trajectory","title":"Joint Space Trajectory","text":"<pre><code>def joint_trajectory(start_angles, end_angles, num_points):\n    \"\"\"Generate trajectory in joint space.\"\"\"\n    t = np.linspace(0, 1, num_points)\n\n    trajectory = []\n    for ti in t:\n        angles = start_angles + ti * (np.array(end_angles) - np.array(start_angles))\n        trajectory.append(angles)\n\n    return np.array(trajectory)\n\n# Example usage\nstart_angles = [0, -np.pi/2, 0, 0, 0, 0]\nend_angles = [np.pi/4, -np.pi/3, -np.pi/6, 0, 0, 0]\njoint_traj = joint_trajectory(start_angles, end_angles, 100)\n</code></pre>"},{"location":"kinematics-reference/#utility-functions","title":"\ud83d\udd27 Utility Functions","text":""},{"location":"kinematics-reference/#distance-and-angle-calculations","title":"Distance and Angle Calculations","text":"<pre><code>def euclidean_distance(p1, p2):\n    \"\"\"Calculate Euclidean distance between two points.\"\"\"\n    return np.linalg.norm(np.array(p1) - np.array(p2))\n\ndef angle_between_vectors(v1, v2):\n    \"\"\"Calculate angle between two vectors.\"\"\"\n    cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n    cos_angle = np.clip(cos_angle, -1, 1)  # Avoid numerical errors\n    return np.arccos(cos_angle)\n\ndef normalize_angle(angle):\n    \"\"\"Normalize angle to [-\u03c0, \u03c0].\"\"\"\n    return np.arctan2(np.sin(angle), np.cos(angle))\n</code></pre>"},{"location":"kinematics-reference/#matrix-operations","title":"Matrix Operations","text":"<pre><code>def skew_symmetric(v):\n    \"\"\"Create skew-symmetric matrix from vector.\"\"\"\n    return np.array([\n        [0, -v[2], v[1]],\n        [v[2], 0, -v[0]],\n        [-v[1], v[0], 0]\n    ])\n\ndef rotation_matrix_to_axis_angle(R):\n    \"\"\"Convert rotation matrix to axis-angle representation.\"\"\"\n    theta = np.arccos((np.trace(R) - 1) / 2)\n\n    if abs(theta) &lt; 1e-6:\n        return np.array([0, 0, 1]), 0\n\n    axis = np.array([\n        R[2, 1] - R[1, 2],\n        R[0, 2] - R[2, 0],\n        R[1, 0] - R[0, 1]\n    ])\n    axis = axis / (2 * np.sin(theta))\n\n    return axis, theta\n</code></pre>"},{"location":"kinematics-reference/#common-formulas","title":"\ud83d\udcda Common Formulas","text":""},{"location":"kinematics-reference/#trigonometric-identities","title":"Trigonometric Identities","text":"<pre><code># Sum and difference formulas\ndef sin_sum(a, b):\n    return np.sin(a) * np.cos(b) + np.cos(a) * np.sin(b)\n\ndef cos_sum(a, b):\n    return np.cos(a) * np.cos(b) - np.sin(a) * np.sin(b)\n\n# Double angle formulas\ndef sin_double(a):\n    return 2 * np.sin(a) * np.cos(a)\n\ndef cos_double(a):\n    return np.cos(a)**2 - np.sin(a)**2\n</code></pre>"},{"location":"kinematics-reference/#vector-operations","title":"Vector Operations","text":"<pre><code>def cross_product(v1, v2):\n    \"\"\"Cross product of two 3D vectors.\"\"\"\n    return np.array([\n        v1[1] * v2[2] - v1[2] * v2[1],\n        v1[2] * v2[0] - v1[0] * v2[2],\n        v1[0] * v2[1] - v1[1] * v2[0]\n    ])\n\ndef dot_product(v1, v2):\n    \"\"\"Dot product of two vectors.\"\"\"\n    return np.sum(v1 * v2)\n</code></pre>"},{"location":"kinematics-reference/#verification-examples","title":"\u2705 Verification Examples","text":""},{"location":"kinematics-reference/#test-forward-kinematics","title":"Test Forward Kinematics","text":"<pre><code>def test_forward_kinematics():\n    \"\"\"Test forward kinematics with known values.\"\"\"\n    # Test home position\n    home_angles = [0, -np.pi/2, 0, 0, 0, 0]\n    T_home = forward_kinematics(home_angles, ur3e_dh)\n\n    print(\"Home position:\")\n    print(f\"Position: {T_home[:3, 3]}\")\n    print(f\"Orientation:\\n{T_home[:3, :3]}\")\n\n    # Test with different angles\n    test_angles = [np.pi/4, -np.pi/3, -np.pi/6, 0, 0, 0]\n    T_test = forward_kinematics(test_angles, ur3e_dh)\n\n    print(\"\\nTest position:\")\n    print(f\"Position: {T_test[:3, 3]}\")\n    print(f\"Orientation:\\n{T_test[:3, :3]}\")\n\n# Run test\ntest_forward_kinematics()\n</code></pre>"},{"location":"kinematics-reference/#getting-help","title":"\ud83c\udd98 Getting Help","text":""},{"location":"kinematics-reference/#mathematical-resources","title":"Mathematical Resources","text":"<ul> <li>Linear Algebra: Khan Academy</li> <li>Robotics Math: Modern Robotics</li> <li>Python Math: SciPy Documentation</li> </ul>"},{"location":"kinematics-reference/#course-support","title":"Course Support","text":"<ul> <li>Piazza: Ask questions on course forum</li> <li>Office Hours: Get help from TA or instructor</li> <li>Lab Sessions: Hands-on help during labs</li> </ul>"},{"location":"kinematics-reference/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<p>After mastering kinematics:</p> <ol> <li>Practice with Python examples above</li> <li>Implement FK/IK for different robot configurations</li> <li>Start Week 6 lab: See Week 6 Lab</li> <li>Work on homework problems using these formulas</li> </ol>   **Ready to solve kinematics problems? Let's start the Week 6 lab! \ud83d\udcd0**  [\ud83d\udc0d Python Basics](python-basics.md){ .md-button } [\ud83e\udd16 ROS Setup](ros-setup.md){ .md-button } [\ud83d\udcda Back to Resources](resources.md){ .md-button }   <p>Last updated: Fall 2025 \u2022 Back to Resources</p>"},{"location":"policies/","title":"Policies &amp; Campus Resources","text":"<p>This course follows University policies (integrity, conduct, accessibility, attendance, grades, IP). See campus policy pages and the syllabus for full details.</p>"},{"location":"policies/#academic-integrity-course-specific","title":"Academic Integrity (Course-specific)","text":"<ul> <li>Unauthorized collaboration or AI-generated solutions are not permitted unless explicitly allowed.</li> <li>Pledge on each assessment: \u201cI pledge on my honor that I have not given or received any unauthorized assistance on this exam/assignment.\u201d</li> <li>When in doubt about collaboration boundaries, ask the course staff.</li> </ul>"},{"location":"policies/#ai-usage-course-specific","title":"AI Usage (Course-specific)","text":"<ul> <li>You may use AI tools for brainstorming/review; your final submissions must be your own.</li> <li>Never run AI-generated code on physical robots.</li> </ul>"},{"location":"policies/#accessibility-accommodations","title":"Accessibility &amp; Accommodations","text":"<p>UMD ADS provides accommodations; contact the instructor promptly to arrange.</p>"},{"location":"policies/#title-ix-mandatory-reporting","title":"Title IX &amp; Mandatory Reporting","text":"<p>The instructor is a Responsible University Employee. Confidential resources include CARE to Stop Violence and the Counseling Center.</p>"},{"location":"policies/#participation-attendance","title":"Participation &amp; Attendance","text":"<p>Attendance and on-time arrival are essential, especially for group studios/labs. If you must miss your assigned lab time, message TAs via Piazza in advance and coordinate with your team.</p>"},{"location":"policies/#safety-guidelines","title":"Safety Guidelines","text":""},{"location":"policies/#robot-lab-safety","title":"Robot Lab Safety","text":"<ul> <li>Safety training is mandatory before entering the robot lab</li> <li>Never bypass safety systems or remove safety guards</li> <li>Keep clear of robot workspace during operation</li> <li>Use emergency stop buttons if needed</li> <li>Report safety concerns immediately to course staff</li> </ul>"},{"location":"policies/#general-lab-safety","title":"General Lab Safety","text":"<ul> <li>Follow all posted safety procedures</li> <li>Wear appropriate safety gear when required</li> <li>Keep work areas clean and organized</li> <li>Report equipment malfunctions immediately</li> <li>No food or drink in lab areas</li> </ul>"},{"location":"policies/#emergency-procedures","title":"Emergency Procedures","text":"<ul> <li>Medical emergency: Call 911 or campus police</li> <li>Fire/equipment emergency: Use emergency stops, evacuate if needed</li> <li>Robot malfunction: Stop all operations, contact TA immediately</li> </ul>"},{"location":"policies/#course-evaluation","title":"Course Evaluation","text":"<p>Please complete Student Feedback on Course Experiences at semester end.</p>"},{"location":"python-basics/","title":"\ud83d\udc0d Python Basics for Robotics","text":"**Essential Python programming for robotics development**  *Learn the Python fundamentals you'll need for ROS 2, robot control, and simulation*"},{"location":"python-basics/#overview","title":"\ud83c\udfaf Overview","text":"<p>This guide covers essential Python concepts for robotics programming. You'll learn the basics needed to write ROS 2 nodes, control robots, process sensor data, and work with mathematical operations.</p>"},{"location":"python-basics/#prerequisites","title":"\ud83d\udcbb Prerequisites","text":"<p>Before starting, ensure you have: - \u2705 Ubuntu with Python 3.8+ installed - \u2705 Basic terminal knowledge - \u2705 Text editor (VS Code, gedit, or nano)</p>"},{"location":"python-basics/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"python-basics/#check-python-installation","title":"Check Python Installation","text":"<pre><code># Check Python version\npython3 --version\n\n# Check pip version\npip3 --version\n\n# Start Python interpreter\npython3\n</code></pre>"},{"location":"python-basics/#install-essential-packages","title":"Install Essential Packages","text":"<pre><code># Install common robotics packages\npip3 install numpy matplotlib scipy\n\n# Install ROS 2 Python client\nsudo apt install python3-rclpy\n</code></pre>"},{"location":"python-basics/#core-python-concepts","title":"\ud83d\udcda Core Python Concepts","text":""},{"location":"python-basics/#1-variables-and-data-types","title":"1. Variables and Data Types","text":"<pre><code># Numbers\nx = 10          # integer\ny = 3.14        # float\nz = 2 + 3j      # complex\n\n# Strings\nname = \"Robot\"\nmessage = 'Hello, World!'\n\n# Booleans\nis_robot = True\nis_human = False\n\n# Lists (mutable)\njoint_angles = [0.0, 1.57, 0.0, 0.0, 0.0, 0.0]\njoint_names = [\"shoulder\", \"elbow\", \"wrist\"]\n\n# Tuples (immutable)\nposition = (1.0, 2.0, 3.0)\n\n# Dictionaries\nrobot_config = {\n    \"name\": \"UR3e\",\n    \"dof\": 6,\n    \"max_payload\": 3.0\n}\n</code></pre>"},{"location":"python-basics/#2-control-flow","title":"2. Control Flow","text":"<pre><code># If statements\nif joint_angle &gt; 1.57:\n    print(\"Joint limit exceeded!\")\nelif joint_angle &lt; -1.57:\n    print(\"Joint limit exceeded!\")\nelse:\n    print(\"Joint angle is safe\")\n\n# For loops\nfor i in range(6):\n    print(f\"Joint {i}: {joint_angles[i]}\")\n\n# While loops\ncount = 0\nwhile count &lt; 5:\n    print(f\"Count: {count}\")\n    count += 1\n</code></pre>"},{"location":"python-basics/#3-functions","title":"3. Functions","text":"<pre><code>def calculate_distance(point1, point2):\n    \"\"\"Calculate Euclidean distance between two points.\"\"\"\n    import math\n    dx = point2[0] - point1[0]\n    dy = point2[1] - point1[1]\n    dz = point2[2] - point1[2]\n    return math.sqrt(dx*dx + dy*dy + dz*dz)\n\n# Function with default parameters\ndef move_robot(x=0.0, y=0.0, z=0.0, speed=1.0):\n    \"\"\"Move robot to specified position.\"\"\"\n    print(f\"Moving to ({x}, {y}, {z}) at speed {speed}\")\n    return True\n\n# Call functions\ndistance = calculate_distance((0, 0, 0), (1, 1, 1))\nmove_robot(1.0, 2.0, 3.0)\n</code></pre>"},{"location":"python-basics/#mathematics-and-numpy","title":"\ud83d\udd22 Mathematics and NumPy","text":""},{"location":"python-basics/#numpy-basics","title":"NumPy Basics","text":"<pre><code>import numpy as np\n\n# Create arrays\njoint_angles = np.array([0.0, 1.57, 0.0, 0.0, 0.0, 0.0])\nposition = np.array([1.0, 2.0, 3.0])\n\n# Array operations\nangles_deg = np.degrees(joint_angles)\nangles_rad = np.radians(angles_deg)\n\n# Matrix operations\nrotation_matrix = np.array([\n    [1, 0, 0],\n    [0, 1, 0],\n    [0, 0, 1]\n])\n\n# Matrix multiplication\nnew_position = rotation_matrix @ position\n</code></pre>"},{"location":"python-basics/#common-mathematical-operations","title":"Common Mathematical Operations","text":"<pre><code>import numpy as np\nimport math\n\n# Trigonometric functions\nangle = np.pi / 4\nsin_val = np.sin(angle)\ncos_val = np.cos(angle)\ntan_val = np.tan(angle)\n\n# Square root and power\ndistance = np.sqrt(16)\nsquared = np.power(4, 2)\n\n# Random numbers\nrandom_angle = np.random.uniform(-np.pi, np.pi)\nrandom_position = np.random.randn(3)  # 3D normal distribution\n</code></pre>"},{"location":"python-basics/#data-visualization-with-matplotlib","title":"\ud83d\udcca Data Visualization with Matplotlib","text":""},{"location":"python-basics/#basic-plotting","title":"Basic Plotting","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Create data\ntime = np.linspace(0, 10, 100)\njoint_angle = np.sin(time)\n\n# Create plot\nplt.figure(figsize=(10, 6))\nplt.plot(time, joint_angle, 'b-', linewidth=2, label='Joint Angle')\nplt.xlabel('Time (s)')\nplt.ylabel('Angle (rad)')\nplt.title('Joint Angle vs Time')\nplt.grid(True)\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"python-basics/#multiple-plots","title":"Multiple Plots","text":"<pre><code># Create subplots\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n\n# First subplot\nax1.plot(time, np.sin(time), 'r-', label='Sine')\nax1.set_ylabel('Amplitude')\nax1.legend()\nax1.grid(True)\n\n# Second subplot\nax2.plot(time, np.cos(time), 'g-', label='Cosine')\nax2.set_xlabel('Time (s)')\nax2.set_ylabel('Amplitude')\nax2.legend()\nax2.grid(True)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"python-basics/#ros-2-integration","title":"\ud83e\udd16 ROS 2 Integration","text":""},{"location":"python-basics/#basic-ros-2-node","title":"Basic ROS 2 Node","text":"<pre><code>#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Float64MultiArray\nfrom geometry_msgs.msg import Pose\n\nclass RobotController(Node):\n    def __init__(self):\n        super().__init__('robot_controller')\n\n        # Create publisher\n        self.joint_pub = self.create_publisher(\n            Float64MultiArray, \n            '/joint_commands', \n            10\n        )\n\n        # Create subscriber\n        self.pose_sub = self.create_subscription(\n            Pose,\n            '/robot_pose',\n            self.pose_callback,\n            10\n        )\n\n        # Create timer\n        self.timer = self.create_timer(0.1, self.timer_callback)\n\n        self.get_logger().info('Robot controller node started')\n\n    def pose_callback(self, msg):\n        \"\"\"Callback for robot pose updates.\"\"\"\n        x, y, z = msg.position.x, msg.position.y, msg.position.z\n        self.get_logger().info(f'Robot at: ({x:.2f}, {y:.2f}, {z:.2f})')\n\n    def timer_callback(self):\n        \"\"\"Timer callback for periodic tasks.\"\"\"\n        # Send joint commands\n        joint_msg = Float64MultiArray()\n        joint_msg.data = [0.0, 1.57, 0.0, 0.0, 0.0, 0.0]\n        self.joint_pub.publish(joint_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = RobotController()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"python-basics/#file-io-and-data-handling","title":"\ud83d\udd27 File I/O and Data Handling","text":""},{"location":"python-basics/#reading-and-writing-files","title":"Reading and Writing Files","text":"<pre><code># Write data to file\njoint_data = [0.0, 1.57, 0.0, 0.0, 0.0, 0.0]\n\nwith open('joint_angles.txt', 'w') as f:\n    for angle in joint_data:\n        f.write(f\"{angle}\\n\")\n\n# Read data from file\nangles = []\nwith open('joint_angles.txt', 'r') as f:\n    for line in f:\n        angles.append(float(line.strip()))\n\nprint(f\"Read angles: {angles}\")\n</code></pre>"},{"location":"python-basics/#csv-files","title":"CSV Files","text":"<pre><code>import csv\n\n# Write CSV\nwith open('robot_data.csv', 'w', newline='') as f:\n    writer = csv.writer(f)\n    writer.writerow(['Time', 'Joint1', 'Joint2', 'Joint3'])\n    writer.writerow([0.0, 0.0, 1.57, 0.0])\n    writer.writerow([0.1, 0.1, 1.67, 0.1])\n\n# Read CSV\nwith open('robot_data.csv', 'r') as f:\n    reader = csv.reader(f)\n    header = next(reader)  # Skip header\n    for row in reader:\n        time, j1, j2, j3 = float(row[0]), float(row[1]), float(row[2]), float(row[3])\n        print(f\"Time: {time}, Joints: [{j1}, {j2}, {j3}]\")\n</code></pre>"},{"location":"python-basics/#testing-and-debugging","title":"\ud83e\uddea Testing and Debugging","text":""},{"location":"python-basics/#basic-testing","title":"Basic Testing","text":"<pre><code>def test_calculate_distance():\n    \"\"\"Test the calculate_distance function.\"\"\"\n    # Test case 1: Distance from origin\n    result = calculate_distance((0, 0, 0), (1, 1, 1))\n    expected = np.sqrt(3)\n    assert abs(result - expected) &lt; 1e-6, f\"Expected {expected}, got {result}\"\n\n    # Test case 2: Same point\n    result = calculate_distance((1, 2, 3), (1, 2, 3))\n    expected = 0.0\n    assert abs(result - expected) &lt; 1e-6, f\"Expected {expected}, got {result}\"\n\n    print(\"All tests passed!\")\n\n# Run tests\ntest_calculate_distance()\n</code></pre>"},{"location":"python-basics/#debugging-tips","title":"Debugging Tips","text":"<pre><code># Use print statements\nprint(f\"Debug: joint_angles = {joint_angles}\")\n\n# Use pdb debugger\nimport pdb\npdb.set_trace()  # Code stops here for debugging\n\n# Use logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\nlogger.debug(f\"Joint angles: {joint_angles}\")\n</code></pre>"},{"location":"python-basics/#common-robotics-patterns","title":"\ud83d\udcf1 Common Robotics Patterns","text":""},{"location":"python-basics/#state-machine","title":"State Machine","text":"<pre><code>class RobotState:\n    IDLE = \"IDLE\"\n    MOVING = \"MOVING\"\n    ERROR = \"ERROR\"\n\nclass RobotController:\n    def __init__(self):\n        self.state = RobotState.IDLE\n        self.target_position = None\n\n    def update(self):\n        if self.state == RobotState.IDLE:\n            if self.target_position:\n                self.state = RobotState.MOVING\n                print(\"Starting movement...\")\n\n        elif self.state == RobotState.MOVING:\n            if self.reached_target():\n                self.state = RobotState.IDLE\n                print(\"Movement completed\")\n\n        elif self.state == RobotState.ERROR:\n            print(\"Robot in error state\")\n\n    def reached_target(self):\n        # Simulate reaching target\n        return True\n</code></pre>"},{"location":"python-basics/#pid-controller","title":"PID Controller","text":"<pre><code>class PIDController:\n    def __init__(self, kp, ki, kd):\n        self.kp = kp\n        self.ki = ki\n        self.kd = kd\n        self.prev_error = 0\n        self.integral = 0\n\n    def compute(self, setpoint, measurement, dt):\n        error = setpoint - measurement\n\n        # Proportional term\n        p_term = self.kp * error\n\n        # Integral term\n        self.integral += error * dt\n        i_term = self.ki * self.integral\n\n        # Derivative term\n        derivative = (error - self.prev_error) / dt\n        d_term = self.kd * derivative\n\n        # Update previous error\n        self.prev_error = error\n\n        # Compute output\n        output = p_term + i_term + d_term\n        return output\n\n# Usage example\npid = PIDController(kp=1.0, ki=0.1, kd=0.01)\ncontrol_output = pid.compute(setpoint=1.0, measurement=0.5, dt=0.01)\n</code></pre>"},{"location":"python-basics/#practice-exercises","title":"\u2705 Practice Exercises","text":""},{"location":"python-basics/#exercise-1-joint-limit-checker","title":"Exercise 1: Joint Limit Checker","text":"<pre><code>def check_joint_limits(joint_angles, limits):\n    \"\"\"\n    Check if joint angles are within limits.\n\n    Args:\n        joint_angles: List of joint angles\n        limits: List of (min, max) tuples for each joint\n\n    Returns:\n        List of booleans indicating if each joint is within limits\n    \"\"\"\n    # Your code here\n    pass\n\n# Test data\njoints = [0.0, 1.57, 0.0, 0.0, 0.0, 0.0]\nlimits = [(-3.14, 3.14)] * 6  # All joints have same limits\n\n# Test your function\nresults = check_joint_limits(joints, limits)\nprint(f\"Joint limits check: {results}\")\n</code></pre>"},{"location":"python-basics/#exercise-2-trajectory-generator","title":"Exercise 2: Trajectory Generator","text":"<pre><code>def generate_trajectory(start_pos, end_pos, num_points):\n    \"\"\"\n    Generate a linear trajectory between two positions.\n\n    Args:\n        start_pos: Starting position (x, y, z)\n        end_pos: Ending position (x, y, z)\n        num_points: Number of points in trajectory\n\n    Returns:\n        List of positions along the trajectory\n    \"\"\"\n    # Your code here\n    pass\n\n# Test your function\nstart = (0, 0, 0)\nend = (1, 1, 1)\ntrajectory = generate_trajectory(start, end, 10)\nprint(f\"Trajectory: {trajectory}\")\n</code></pre>"},{"location":"python-basics/#getting-help","title":"\ud83c\udd98 Getting Help","text":""},{"location":"python-basics/#python-resources","title":"Python Resources","text":"<ul> <li>Official Docs: python.org</li> <li>NumPy Docs: numpy.org</li> <li>Matplotlib Docs: matplotlib.org</li> </ul>"},{"location":"python-basics/#course-support","title":"Course Support","text":"<ul> <li>Piazza: Ask questions on course forum</li> <li>Office Hours: Get help from TA or instructor</li> <li>Lab Sessions: Hands-on help during labs</li> </ul>"},{"location":"python-basics/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<p>After mastering Python basics:</p> <ol> <li>Set up ROS 2: See ROS Setup Guide</li> <li>Learn Gazebo: See Gazebo Setup</li> <li>Start Week 3 lab: See Week 3 Lab</li> <li>Practice coding: Work on exercises and small projects</li> </ol>   **Ready to control robots? Let's set up ROS 2 next! \ud83e\udd16**  [\ud83e\udd16 ROS Setup](ros-setup.md){ .md-button .md-button--primary } [\ud83c\udfae Gazebo Setup](gazebo-setup.md){ .md-button } [\ud83d\udcda Back to Resources](resources.md){ .md-button }   <p>Last updated: Fall 2025 \u2022 Back to Resources</p>"},{"location":"resources/","title":"\ud83d\udcda Resources &amp; Wiki","text":"**Your one-stop reference for all robotics tools and resources**  *Quick links, installation guides, and helpful references*"},{"location":"resources/#quick-start-guides","title":"\ud83d\ude80 Quick Start Guides","text":"<ul> <li> <p> Ubuntu Setup</p> <p>Complete Ubuntu installation and setup guide</p> <p> Ubuntu Guide</p> </li> <li> <p> ROS Installation</p> <p>Install and configure ROS 2 (Humble)</p> <p> ROS Guide</p> </li> <li> <p> Python Basics</p> <p>Essential Python for robotics programming</p> <p> Python Guide</p> </li> <li> <p> Git &amp; GitHub</p> <p>Version control basics for lab work</p> <p> Git Guide</p> </li> </ul>"},{"location":"resources/#lab-tools-software","title":"\ud83e\uddea Lab Tools &amp; Software","text":"<ul> <li> <p>:material-gazebo:{ .lg .middle } Gazebo Simulation</p> <p>Set up and use Gazebo for robot simulation</p> <p> Gazebo Guide</p> </li> <li> <p> Development Environment</p> <p>Configure your IDE and development tools</p> <p> Dev Setup</p> </li> <li> <p> UR3e Robot</p> <p>Understanding and programming the UR3e arm</p> <p> UR3e Guide</p> </li> </ul>"},{"location":"resources/#reference-materials","title":"\ud83d\udcd6 Reference Materials","text":"<ul> <li> <p> Kinematics Reference</p> <p>DH parameters, transformations, FK/IK formulas</p> <p> Kinematics</p> </li> <li> <p> Math Tools</p> <p>Linear algebra, matrices, and math utilities</p> <p> Math Tools</p> </li> <li> <p> Code Examples</p> <p>Common code snippets and examples</p> <p> Examples</p> </li> </ul>"},{"location":"resources/#external-resources","title":"\ud83d\udd17 External Resources","text":""},{"location":"resources/#official-documentation","title":"Official Documentation","text":"<ul> <li>ROS 2 Documentation - Complete ROS 2 reference</li> <li>Gazebo Tutorials - Simulation guides</li> <li>Python Documentation - Python language reference</li> <li>Ubuntu Help - Ubuntu system help</li> </ul>"},{"location":"resources/#community-resources","title":"Community Resources","text":"<ul> <li>ROS Answers - Q&amp;A forum</li> <li>Stack Overflow - Programming help</li> <li>Reddit r/robotics - Community discussions</li> <li>YouTube Robotics Channels - Video tutorials</li> </ul>"},{"location":"resources/#course-specific","title":"Course-Specific","text":"<ul> <li>Lab Code Repository - All lab materials</li> <li>Course Schedule - Weekly topics and deadlines</li> <li>Lab Instructions - Detailed lab guides</li> </ul>"},{"location":"resources/#troubleshooting","title":"\ud83c\udd98 Troubleshooting","text":"Common Issue Quick Fix Detailed Guide Ubuntu won't boot Check USB drive, try different port Ubuntu Setup ROS not working Restart terminal, source environment ROS Setup Python errors Check syntax, verify installations Python Basics Git issues Check credentials, verify remote Git Basics Simulation problems Restart Gazebo, check models Gazebo Setup"},{"location":"resources/#mobile-friendly-quick-links","title":"\ud83d\udcf1 Mobile-Friendly Quick Links","text":""},{"location":"resources/#essential-commands","title":"Essential Commands","text":"<pre><code># Ubuntu\nsudo apt update &amp;&amp; sudo apt upgrade\n\n# ROS 2\nsource /opt/ros/humble/setup.bash\nros2 --help\n\n# Python\npython3 --version\npip3 install package_name\n\n# Git\ngit status\ngit add .\ngit commit -m \"message\"\n</code></pre>"},{"location":"resources/#quick-file-locations","title":"Quick File Locations","text":"<ul> <li>ROS workspace: <code>~/ros2_ws/</code></li> <li>Python packages: <code>~/.local/lib/python3.x/site-packages/</code></li> <li>Git repos: <code>~/</code> (or wherever you cloned them)</li> <li>Lab materials: <code>~/enme480-labs/</code></li> </ul>   **Need help with something specific? Check the guides above or ask on [Piazza](https://piazza.com/umd/fall2025/enme480)!**   <p>Last updated: Fall 2025 \u2022 Back to Home</p>"},{"location":"ros-setup/","title":"\ud83e\udd16 ROS 2 Setup Guide","text":"**Install and configure ROS 2 Humble for robotics development**  *Get ROS 2 running on Ubuntu for ENME480 labs and projects*"},{"location":"ros-setup/#overview","title":"\ud83c\udfaf Overview","text":"<p>This guide will help you install ROS 2 Humble (Hawksbill) on Ubuntu 22.04. ROS 2 is the Robot Operating System that we'll use throughout the course for robot programming and simulation.</p>"},{"location":"ros-setup/#prerequisites","title":"\ud83d\udcbb Prerequisites","text":"<p>Before starting, ensure you have: - \u2705 Ubuntu 22.04 LTS installed (ROS 2 Humble Tier-1 platform) - \u2705 Internet connection for downloading packages - \u2705 Basic Ubuntu knowledge (terminal commands) - \u2705 At least 10GB free space</p>"},{"location":"ros-setup/#after-setting-up-ubuntu-2204","title":"After setting up Ubuntu 22.04","text":"<ol> <li> <p>First, we will make sure our dependencies are in place. Within WSL2 run:</p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade\n</code></pre> <p>In order to update all system packages (you may need to enter your password)</p> <pre><code> sudo install -m 0755 -d /etc/apt/keyrings &amp;&amp; curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg &amp;&amp; sudo chmod a+r /etc/apt/keyrings/docker.gpg\n\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\nsudo apt install -y apt-transport-https ca-certificates curl software-properties-common\n\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\necho \"deb [signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt update\n</code></pre> <p>These commands set up package registries within WSL, which is how Ubuntu knows where to look for packages (apps) we want to install. If you'd like a more detailed breakdown of what each command here does, feel free to ask a TA.</p> <pre><code>sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin git python-is-python3 docker\n</code></pre> <p>This command will install docker (which we use to standarize everyones ROS installation), git (which we use to sync code across computers) and remaps the name \"python3\" to \"python\" to make Ubuntu happier when running our code. </p> </li> <li> <p>Now, we will download the code from GitHub. To do this, run:</p> <pre><code> cd ~/ &amp;&amp; git clone https://github.com/MarylandRoboticsCenter/ENME480_mrc.git\n</code></pre> <p>To move to the right folder and download the GitHub repo containing the docker image we need.</p> </li> <li> <p>With that done, we need to make sure the user groups are set up to allow us to compile and run docker images. Run:</p> <pre><code>sudo groupadd docker\n\nsudo usermod -aG docker $USER\n\nnewgrp docker\n\nsudo systemctl restart docker\n</code></pre> <p>So that you are able to build and run docker images. These commands make a gruop who can manage docker images, then add you to it, then resets part of Ubuntu so it recognizes the new group. Once this is done, all the parts are in place to build our docker image.</p> </li> <li> <p>Now, we will build our image.</p> <pre><code>cd ~/ENME480_mrc/docker &amp;&amp; userid=$(id -u) groupid=$(id -g) docker compose -f humble-enme480_ur3e-nvidia-compose.yml build\n</code></pre> <p>The first part of this command (before the &amp;&amp;) puts you in the folder containing the docker image we want to build, while the second part actually builds our image. This step can take a while, since you have to download a lot of data. If you get a permission error at this step try restarting wsl.</p> <p>Next, try running</p> <pre><code>nvidia-smi\n</code></pre> <p>You should get an output which looks something like</p> <p>If you do, follow the next step, if not skip to step 7.</p> </li> <li> <p>Getting the an output from nvidia-smi means you have a Nvidia GPU installed in your computer with drivers properly configured. In this step, we will enable the GPU within docker to speed up our simulations. First, run the following commands:</p> <pre><code>sudo touch /etc/docker/daemon.json\n\nsudo chmod 777 /etc/docker/daemon.json\n\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n      &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\nsed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\nsudo apt-get update\n\nexport NVIDIA_CONTAINER_TOOLKIT_VERSION=1.17.8-1\nsudo apt-get install -y \\\n      nvidia-container-toolkit=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \\\n      nvidia-container-toolkit-base=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \\\n      libnvidia-container-tools=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \\\n      libnvidia-container1=${NVIDIA_CONTAINER_TOOLKIT_VERSION}\n</code></pre> <p>This will install the Nvidia container toolkit which allows Docker to use your GPU. 6. With the container toolkit installed, we can now configure docker and compose our image. </p> <pre><code>echo $'{\"runtimes\": {\"nvidia\": {\"path\": \"nvidia-container-runtime\", \"runtimeArgs\": []}}}' &gt; /etc/docker/daemon.json &amp;&amp; sudo systemctl restart docker\n</code></pre> <p>This command will add a line to the settings file to enable running with the Nvidia GPU then resets Docker to reload the configuration.</p> <pre><code>docker compose -f humble-enme480_ur3e-nvidia-compose.yml run --rm enme480_ur3e-docker\n</code></pre> <p>Finally, this command will compose and run our image. This is the command you will want to run in order to get into the Docker and use ROS. Once it finishes you should see that the username in the terminal will have changed to \"enme480_docker\" to let you know that you are in the docker container. You can skip step 7 if you've done this, step 7 is for people not running with Nvidia GPUs. From here, you can go to the VSCode setup or continue to set up what ever IDE you'd like to use. 7. If you are not running with an Nvidia GPU you can skip setting up the Nvidia toolkit and instead just run:</p> <pre><code>docker compose -f humble-enme480_ur3e-compose.yml run --rm enme480_ur3e-docker\n</code></pre> <p>This is the command you will need to run to enter the Docker and use ROS. The next step is to configure what ever IDE you'd like to use. We recommend VSCode for it's Docker integration, but you are free to use any IDE you'd like.</p> </li> </ol>"},{"location":"ros-setup/#verify-installation","title":"\ud83e\uddea Verify Installation","text":""},{"location":"ros-setup/#test-basic-installation","title":"Test Basic Installation","text":"<p>From within the docker image, run the following command: <pre><code>ros2 run demo_nodes_cpp talker\n</code></pre> This shouuld begin outputting a list of number to the terminal. Open a new terminal, enter the docer image and run: <pre><code>ros2 run demo_nodes_cpp listener\n</code></pre> This second script should output the messages being sent by the talker.</p>"},{"location":"ros-setup/#test-in-new-terminal","title":"Test in New Terminal","text":"<pre><code># Open new terminal and run\nros2 --help\n# test gazebo, our simulation suite\nign gazebo\n</code></pre>"},{"location":"ros-setup/#common-issues-solutions","title":"\ud83d\udd27 Common Issues &amp; Solutions","text":""},{"location":"ros-setup/#installation-problems","title":"Installation Problems","text":"Error Solution GPG error Re-run GPG key commands Package not found Check Ubuntu version compatibility Permission denied Use <code>sudo</code> for system commands"},{"location":"ros-setup/#environment-issues","title":"Environment Issues","text":"Problem Solution Command not found Source setup.bash or restart terminal Package not found Check if package is installed Version mismatch Ensure Ubuntu and ROS versions match"},{"location":"ros-setup/#essential-ros-2-concepts","title":"\ud83d\udcda Essential ROS 2 Concepts","text":""},{"location":"ros-setup/#core-concepts","title":"Core Concepts","text":"<ul> <li>Nodes: Individual processes that perform computation</li> <li>Topics: Asynchronous communication mechanism</li> <li>Services: Synchronous request-response communication</li> <li>Actions: Long-running tasks with feedback</li> <li>Messages: Data structures for communication</li> </ul>"},{"location":"ros-setup/#basic-commands","title":"Basic Commands","text":"<pre><code># List running nodes\nros2 node list\n\n# List topics\nros2 topic list\n\n# Echo topic data\nros2 topic echo /topic_name\n\n# List services\nros2 service list\n\n# Call a service\nros2 service call /service_name service_type \"data\"\n</code></pre>"},{"location":"ros-setup/#development-setup","title":"\ud83d\udee0\ufe0f Development Setup","text":""},{"location":"ros-setup/#create-ros-2-workspace","title":"Create ROS 2 Workspace","text":"<pre><code># Create workspace directory\nmkdir -p ~/ros2_ws/src\ncd ~/ros2_ws\n\n# Build workspace\ncolcon build\n\n# Source workspace\nsource install/setup.bash\n\n# Add to bashrc\necho \"source ~/ros2_ws/install/setup.bash\" &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"ros-setup/#install-useful-tools","title":"Install Useful Tools","text":"<pre><code># Install rqt (GUI tools)\nsudo apt install ros-humble-rqt\n\n# Install rviz2 (3D visualization)\nsudo apt install ros-humble-rviz2\n\n# Install turtlesim (tutorial package)\nsudo apt install ros-humble-turtlesim\n</code></pre>"},{"location":"ros-setup/#first-ros-2-program","title":"\ud83c\udfae First ROS 2 Program","text":""},{"location":"ros-setup/#create-a-simple-publisher","title":"Create a Simple Publisher","text":"<pre><code># Navigate to workspace\ncd ~/ros2_ws/src\n\n# Create package\nros2 pkg create --build-type ament_cmake my_first_pkg\n\n# Navigate to package\ncd my_first_pkg/src\n\n# Create Python file\ntouch my_first_node.py\n</code></pre>"},{"location":"ros-setup/#add-code-to-my_first_nodepy","title":"Add Code to my_first_node.py","text":"<pre><code>#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\n\nclass MyFirstNode(Node):\n    def __init__(self):\n        super().__init__('my_first_node')\n        self.publisher_ = self.create_publisher(String, 'my_topic', 10)\n        timer_period = 1.0\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n\n    def timer_callback(self):\n        msg = String()\n        msg.data = 'Hello from my first ROS 2 node!'\n        self.publisher_.publish(msg)\n        self.get_logger().info('Publishing: \"%s\"' % msg.data)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = MyFirstNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"ros-setup/#build-and-run","title":"Build and Run","text":"<pre><code># Build workspace\ncd ~/ros2_ws\ncolcon build\n\n# Source workspace\nsource install/setup.bash\n\n# Run node\nros2 run my_first_pkg my_first_node\n</code></pre>"},{"location":"ros-setup/#debugging-troubleshooting","title":"\ud83d\udd0d Debugging &amp; Troubleshooting","text":""},{"location":"ros-setup/#useful-debugging-commands","title":"Useful Debugging Commands","text":"<pre><code># Check node status\nros2 node info /node_name\n\n# Monitor topic frequency\nros2 topic hz /topic_name\n\n# Check message type\nros2 topic type /topic_name\n\n# List node parameters\nros2 param list\n\n# Get parameter value\nros2 param get /node_name parameter_name\n</code></pre>"},{"location":"ros-setup/#common-debugging-steps","title":"Common Debugging Steps","text":"<ol> <li>Check if node is running: <code>ros2 node list</code></li> <li>Verify topic exists: <code>ros2 topic list</code></li> <li>Check message data: <code>ros2 topic echo /topic_name</code></li> <li>Monitor system resources: <code>htop</code>, <code>ros2 topic hz</code></li> </ol>"},{"location":"ros-setup/#ros-2-tools-guis","title":"\ud83d\udcf1 ROS 2 Tools &amp; GUIs","text":""},{"location":"ros-setup/#command-line-tools","title":"Command Line Tools","text":"<ul> <li>ros2: Main command line interface</li> <li>ros2 topic: Topic management</li> <li>ros2 service: Service management</li> <li>ros2 node: Node management</li> <li>ros2 param: Parameter management</li> </ul>"},{"location":"ros-setup/#graphical-tools","title":"Graphical Tools","text":"<ul> <li>rqt: Plugin-based GUI framework</li> <li>rviz2: 3D visualization tool</li> <li>plotjuggler: Data plotting and analysis</li> <li>rqt_graph: Node and topic visualization</li> </ul>"},{"location":"ros-setup/#verification-checklist","title":"\u2705 Verification Checklist","text":"<ul> <li>[ ] ROS 2 Humble installed successfully</li> <li>[ ] Environment sourced correctly</li> <li>[ ] Basic commands working (<code>ros2 --help</code>)</li> <li>[ ] Demo nodes running (<code>ros2 run demo_nodes_cpp talker</code>)</li> <li>[ ] Workspace created and building</li> <li>[ ] First custom node working</li> <li>[ ] Tools installed (rqt, rviz2)</li> </ul>"},{"location":"ros-setup/#getting-help","title":"\ud83c\udd98 Getting Help","text":""},{"location":"ros-setup/#ros-2-resources","title":"ROS 2 Resources","text":"<ul> <li>Official Docs: docs.ros.org</li> <li>ROS Answers: answers.ros.org</li> <li>ROS Wiki: wiki.ros.org</li> </ul>"},{"location":"ros-setup/#course-support","title":"Course Support","text":"<ul> <li>Piazza: Ask questions on course forum</li> <li>Office Hours: Get help from TA or instructor</li> <li>Lab Sessions: Hands-on help during labs</li> </ul>"},{"location":"ros-setup/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<p>After completing ROS 2 setup:</p> <ol> <li>Learn Python basics: See Python Basics</li> <li>Set up Gazebo: See Gazebo Setup</li> <li>Start Week 3 lab: See Week 3 Lab</li> <li>Practice ROS 2: Run tutorials and examples</li> </ol>   **Ready to start programming robots? Let's learn Python next! \ud83d\udc0d**  [\ud83d\udc0d Python Basics](python-basics.md){ .md-button .md-button--primary } [\ud83c\udfae Gazebo Setup](gazebo-setup.md){ .md-button } [\ud83d\udcda Back to Resources](resources.md){ .md-button }   <p>Last updated: Fall 2025 \u2022 Back to Resources</p>"},{"location":"schedule/","title":"Schedule \u2014 Fall 2025","text":"<p>Heads-up: Locations can change; watch Piazza for updates. Legend: bold = Lab (RAL), Lectures in TWS1100, Studios in KEB 2111.</p> <p>Use the tabs to view the plan as a calendar, by week, a sortable table, or filtered by section.</p> Calendar (interactive)  Lectures (TWS1100)  Studios (KEB 2111) Labs (RAL EAF 3117) |  0101 (Thu 12\u20132)  0102 (Fri 8\u201310)  0103 (Tue 12\u20132) <p>How this works</p> <p>This calendar reads events from <code>/calendar/events.json</code> and bolds lab sessions. Locations appear when you click an event.</p> By week (expandable) Week 1 \u00b7 9/1\u20139/5 <p>Mon (Lecture): No Lecture (Mon) Tue (Lab/Studio, 0103): Lab Intro \u2192 Week 01 Wed (Lecture): Intro &amp; Linear Algebra Primer Thu (Lab/Studio, 0101): Lab Intro \u2192 Week 01 Fri (Lab/Studio, 0102): Lab Intro \u2192 Week 01</p> Week 2 \u00b7 9/8\u20139/12 <p>Mon: Linear Algebra Primer Tue (0103): RAL Intro, Setup Wed: Linear Algebra Primer Thu (0101): RAL Intro, Setup Fri (0102): RAL Intro, Setup</p> Week 3 \u00b7 9/15\u20139/19 <p>Mon: Rigid Motions Tue (0103): Python Intro, ROS Intro, Studio 1 \u2192 Week 03 Wed: Rigid Motions Thu (0101): Python Intro, ROS Intro, Studio 1 \u2192 Week 03 Fri (0102): Python Intro, ROS Intro, Studio 1 \u2192 Week 03</p> Week 4 \u00b7 9/22\u20139/26 <p>Mon: Rigid Motions Tue (0103): Gazebo Demo, Studio 2 \u2192 Week 04 Wed: Rigid Motions Thu (0101): Gazebo Demo, Studio 2 \u2192 Week 04 Fri (0102): Gazebo Demo, Studio 2 \u2192 Week 04</p> Week 5 \u00b7 9/29\u201310/3 <p>Mon: Forward Kinematics Tue (0103): FK Lab 1.1 \u2192 Week 05 Wed: Forward Kinematics Thu (0101): FK Lab 1.1 \u2192 Week 05 Fri (0102): FK Lab 1.1 \u2192 Week 05</p> Week 6 \u00b7 10/6\u201310/10 <p>Mon: Velocity Kinematics Tue (0103): FK Lab 1.2 \u2192 Week 06 Wed: Velocity Kinematics Thu (0101): FK Lab 1.2 \u2192 Week 06 Fri (0102): FK Lab 1.2 \u2192 Week 06</p> Week 7 \u00b7 10/13\u201310/17 <p>Mon/Tue: No Lecture Wed: Velocity Kinematics Thu/Fri: No Lab (Make-up/Office Hours)</p> Week 8 \u00b7 10/20\u201310/24 <p>Exam week</p> <p>Mon: Exam </p> <p>Tue/Thu/Fri: IK Studio \u2192 Week 08 Wed: Inverse Kinematics</p> Week 9 \u00b7 10/27\u201310/31 <p>Mon/Wed: Inverse Kinematics Tue/Thu/Fri: IK Lab \u2192 Week 09</p> Week 10 \u00b7 11/3\u201311/7 <p>Mon: Inverse Kinematics \u2192 Dynamics Tue/Thu/Fri: IK Lab \u2192 Week 10 Wed: Dynamics</p> Week 11 \u00b7 11/10\u201311/14 <p>Mon/Wed: Dynamics Tue/Thu/Fri: Intro to Cameras \u2192 Week 11</p> Week 12 \u00b7 11/17\u201311/21 <p>Exam 2 this week</p> <p>Wed: Exam 2 </p> <p>Mon: Path &amp; Trajectory Planning Tue/Thu/Fri: Camera Lab \u2192 Week 12</p> Week 13 \u00b7 11/24\u201311/29 <p>Mon: Path &amp; Trajectory Planning Tue: No Lab (Make-up/Office Hours) Wed\u2013Fri: No Lecture (Thanksgiving week)</p> Week 14 \u00b7 12/1\u201312/5 <p>Mon: Path &amp; Trajectory Planning Tue/Thu/Fri: Final Project \u2192 Week 14 Wed: Independent Joint Control</p> Week 15 \u00b7 12/8\u201312/12 <p>Mon/Wed: Independent Joint Control Tue/Thu/Fri: Final Project \u2192 Week 15</p> Table (sortable) <p>Click a column header to sort (Week, Dates, etc.). One small JS file makes all Markdown tables sortable.</p> Week Dates Mon (Lecture) Tue (Lab/Studio) Wed (Lecture) Thu (Lab/Studio) Fri (Lab/Studio) 1 9/1\u20139/5 No Lecture (Mon) Lab Intro Intro &amp; Linear Algebra Primer Lab Intro Lab Intro 2 9/8\u20139/12 Linear Algebra Primer RAL Intro, Setup Linear Algebra Primer RAL Intro, Setup RAL Intro, Setup 3 9/15\u20139/19 Rigid Motions Python Intro, ROS Intro, Studio 1 Rigid Motions Python Intro, ROS Intro, Studio 1 Python Intro, ROS Intro, Studio 1 4 9/22\u20139/26 Rigid Motions Gazebo Demo, Studio 2 Rigid Motions Gazebo Demo, Studio 2 Gazebo Demo, Studio 2 5 9/29\u201310/3 Forward Kinematics FK Lab 1.1 Forward Kinematics FK Lab 1.1 FK Lab 1.1 6 10/6\u201310/10 Velocity Kinematics FK Lab 1.2 Velocity Kinematics FK Lab 1.2 FK Lab 1.2 7 10/13\u201310/17 No Lecture (Mon/Tue) No Lecture Velocity Kinematics No Lab (Make-up/Office Hours) No Lab (Make-up/Office Hours) 8 10/20\u201310/24 Exam IK Studio Inverse Kinematics IK Studio IK Studio 9 10/27\u201310/31 Inverse Kinematics IK Lab Inverse Kinematics IK Lab IK Lab 10 11/3\u201311/7 Inverse Kinematics IK Lab Dynamics IK Lab IK Lab 11 11/10\u201311/14 Dynamics Intro to Cameras Dynamics Intro to Cameras Intro to Cameras 12 11/17\u201311/21 Path &amp; Trajectory Planning Camera Lab Exam 2 Camera Lab Camera Lab 13 11/24\u201311/29 Path &amp; Trajectory Planning No Lab (Make-up/Office Hours) No Lecture (Wed\u2013Fri) No Lecture No Lecture 14 12/1\u201312/5 Path &amp; Trajectory Planning Final Project Independent Joint Control Final Project Final Project 15 12/8\u201312/12 Independent Joint Control Final Project Independent Joint Control Final Project Final Project By section <p>Pick your section to see only your lab day.</p> <p>==== \"0101 \u2014 Thu 12\u20132 (KEB 2111 / EAF)\" - W1 (9/1\u20139/5): Lab Intro \u2192 Week 01 - W2: RAL Intro, Setup - W3: Python/ROS Intro \u2014 Studio 1 \u2192 Week 03 - W4: Gazebo Demo \u2014 Studio 2 \u2192 Week 04 - W5: FK Lab 1.1 \u2192 Week 05 - W6: FK Lab 1.2 \u2192 Week 06 - W7: No Lab (Make-up/Office Hours) - W8: IK Studio \u2192 Week 08 - W9: IK Lab \u2192 Week 09 - W10: IK Lab \u2192 Week 10 - W11: Intro to Cameras \u2192 Week 11 - W12: Camera Lab \u2192 Week 12 - W13: No Lecture (Thanksgiving week) - W14: Final Project \u2192 Week 14 - W15: Final Project \u2192 Week 15</p> <p>==== \"0102 \u2014 Fri 8\u201310 (KEB 2111 / EAF)\" - Same flow as 0101 but on Fridays (see the \"Table\" tab for details).</p> <p>==== \"0103 \u2014 Tue 12\u20132 (KEB 2111 / EAF)\" - W1 (9/1\u20139/5): Lab Intro \u2192 Week 01 - W2: RAL Intro, Setup - W3: Python/ROS Intro \u2014 Studio 1 \u2192 Week 03 - W4: Gazebo Demo \u2014 Studio 2 \u2192 Week 04 - W5: FK Lab 1.1 \u2192 Week 05 - W6: FK Lab 1.2 \u2192 Week 06 - W7: No Lecture (Mon/Tue) - W8: IK Studio \u2192 Week 08 - W9: IK Lab \u2192 Week 09 - W10: IK Lab \u2192 Week 10 - W11: Intro to Cameras \u2192 Week 11 - W12: Camera Lab \u2192 Week 12 - W13: No Lab (Make-up/Office Hours) - W14: Final Project \u2192 Week 14 - W15: Final Project \u2192 Week 15</p>"},{"location":"syllabus/","title":"Syllabus \u2014 Fall 2025","text":"<p>Course: ENME480 \u2014 Intro to Robotics Credits: 3 Dates: Sep 2, 2025 \u2013 Dec 12, 2025 Professor: Dr. Nikhil Chopra \u2014 nchopra@umd.edu Office Hours: Wed 10\u201311:30, 2149 Martin Hall \u2014 Zoom link Teaching Assistants: Alex Beyer (abeyer@umd.edu), Kaustubh Joshi (kjoshi@umd.edu) TA Office Hours: TBD Canvas (ELMS): http://www.elms.umd.edu/ Piazza (official Q&amp;A): http://piazza.com/umd/fall2025/enme480 Lab GitHub org: https://github.com/ENME480</p>"},{"location":"syllabus/#course-description","title":"Course Description","text":"<p>This course introduces elementary concepts in robotics with integrated theory and lab components. Labs emphasize interdisciplinary teamwork, developing and testing code on UR3e robotic arms across programming studios and hands-on lab sections.</p>"},{"location":"syllabus/#learning-outcomes","title":"Learning Outcomes","text":"<ul> <li>Apply mathematics, science, and engineering to robotics problems  </li> <li>Analyze and interpret experimental data  </li> <li>Use robot geometry for kinematics analysis  </li> <li>Apply robot dynamics for planning and control</li> </ul>"},{"location":"syllabus/#required-resources","title":"Required Resources","text":"<ul> <li>Course website: ELMS-Canvas  </li> <li>Textbook: Robot Modeling and Control (2e), Spong, Hutchinson, Vidyasagar, 2020, ISBN 978-1119523994  </li> <li>Hardware/Software: Laptop capable of running ROS 2 (setup guided in labs)</li> </ul>"},{"location":"syllabus/#course-structure","title":"Course Structure","text":"<ul> <li>Lectures &amp; in-class assignments: Short comprehension questions (extra credit) may be assigned after lectures.  </li> <li>Studios &amp; Labs: Run by TAs in KEB 2111 (programming) and EAF 3119 (Robotics &amp; Autonomy Lab). Safety seminar + online training required before using robots.  </li> <li>Homework: Posted Fridays 11:59 pm; due one week later via Canvas. Extensions via Piazza only (solutions release soon after deadlines).  </li> <li>Exams: Two midterms (see Schedule). One page of notes (front/back) permitted.  </li> <li>Final Project: Vision-enabled pick-and-place with UR3e: locate blocks, grasp, and build a tower. Group project with write-up and video.</li> </ul>"},{"location":"syllabus/#major-assignments-weighting","title":"Major Assignments &amp; Weighting","text":"Component % Homework 20% Studio/Lab Assignments 20% Midterm 1 20% Midterm 2 20% Final Project 20% Extra Credit: In-class assignments Up to 5% <p>Final grade cutoffs: A+: 97, A: 94, A-: 90; B+: 87, B: 84, B-: 80; C+: 77, C: 74, C-: 70; D+: 67, D: 64, D-: 60; F: &lt; 60.</p>"},{"location":"syllabus/#communication-participation","title":"Communication &amp; Participation","text":"<ul> <li>Piazza is official for course questions; Canvas hosts materials/announcements.  </li> <li>Professional, inclusive discussion is expected in all channels and sessions.  </li> <li>Attendance and on-time arrival for studios/labs are essential; coordinate via Piazza if you must miss your assigned session.</li> </ul>"},{"location":"syllabus/#policies-summary","title":"Policies (Summary)","text":"<ul> <li>Academic Integrity: The University\u2019s Code applies; collaboration on graded work is prohibited unless stated. Unauthorized use of course-assistance sites or AI-generated solutions is not permitted. Pledge required on each assignment/exam.  </li> <li>AI Usage (Course-specific): Brainstorming/review OK; final work must be your own. Do not run AI-generated code on physical robots. </li> <li>Accessibility &amp; Accommodations: See ADS; contact instructor promptly for arrangements.  </li> <li>Campus resources: Emergency Preparedness, Basic Needs, Veteran Resources, Title IX, Course Evaluation\u2014see Policies page.</li> </ul>"},{"location":"ubuntu-setup/","title":"\ud83d\udc27 Ubuntu Setup Guide","text":""},{"location":"ubuntu-setup/#system-requirements","title":"\ud83d\udcbb System Requirements","text":""},{"location":"ubuntu-setup/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>RAM: 8GB (16GB recommended)</li> <li>Storage: 60GB free space (100GB recommended)</li> <li>Processor: 64-bit processor (Intel/AMD) or ARM64 (Apple Silicon)</li> </ul>"},{"location":"ubuntu-setup/#recommended-setup","title":"Recommended Setup","text":"<ul> <li>RAM: 16GB or more</li> <li>Storage: 256GB SSD</li> <li>Processor: Multi-core processor</li> <li>Graphics: Dedicated GPU (optional, for simulation)</li> </ul>"},{"location":"ubuntu-setup/#choose-your-platform","title":"\ud83d\udcbb Choose Your Platform","text":"<p>If you are on Windows then you have two choices here:     - A Virtual Machine (VM). This will emulate a second computer running Ubuntu 22.04 inside on your computer. This approach usually works well but can come with a lot of overhead, leading to programms running slowly and crashes.     - Windows Subsystem for Linux (WSL), Microsofts official way of running Linux code on Windows. This approach has much less overhead and runs faster, but can require some extra steps. </p> macOS (Apple Silicon) \u2014 UTM VMWindows \u2014 WSL 2 (Ubuntu 22.04)Windows - VMLinux / Dual-boot (optional) <p>At the moment, getting the Docker image this course uses working in WSL requires that you have an Nvidia GPU. This can be checked by hitting your Windows key and typing dxdiag. A popup will appear asking about checking for signed drivers, you can click either option. This should lead you to a window which looks like:  Click on the Display tabs on the top to see all available GPUs. If none of them are an NVIDIA GeForce chip you should follow the steps to set up the VM on Windows instead of WSL.</p> <ol> <li>Open Powershell (search \"powershell\" in the Windows menu).  </li> <li> <p>Install Ubuntu 22.04:</p> <pre><code>wsl --install Ubuntu-22.04\n</code></pre> <p>This installs the exact distro we use. Using a different Ubuntu version often breaks ROS compatibility. Note: if you have never used WSL before this command will install some necessary drivers first, then say that it failed to install Ubuntu. If this happens reset your computer and try again, it should work now.</p> </li> <li> <p>You should notice that powershell has gona from looking like this:  </p> </li> </ol> <p>to something like this: </p> <p>This means you are inside WSL. The green part of the lowest line shows your username and domain, while the blue part shows the folder the terminal is currently inside. From here on out, assume that any command we don't explicilty say to run outside WSL should be run from here. </p> <p>Ubuntu 22.04 LTS native install is fine if you prefer dual-boot. Ensure disk space \u2265 60 GB.</p>"},{"location":"ubuntu-setup/#step-1-download-utm","title":"Step 1: Download UTM","text":"<p>Download UTM from the official website: https://mac.getutm.app</p>"},{"location":"ubuntu-setup/#step-2-download-ubuntu-2204-arm64","title":"Step 2: Download Ubuntu 22.04 ARM64","text":"<p>Get Ubuntu 22.04 ARM64 (Desktop or Server): https://cdimage.ubuntu.mirror.onlime.sl/ubuntu/daily-live/20220417/ Choose 22.04 LTS 64-bit (ARM).</p>"},{"location":"ubuntu-setup/#step-3-create-new-virtual-machine","title":"Step 3: Create New Virtual Machine","text":"<p>Open UTM and you'll see the welcome screen with options to create a new virtual machine, browse the gallery, or access user guides.</p> <p></p> <p>Choose [Virtualize] then [Linux], choose your downloaded iso image file, and click [Continue] with all of the boxes unchecked.</p> <p></p> <p></p> <p>Click on Browse and select the ISO file you downloaded in Step 2</p> <p></p> <p>On the next screen, leave the memory at 4096 MB and CPU Cores at [Default]. Then specify the amount of space you want to allocate to the virtual machine. It is recommended that you don\u2019t go below around 30GB. Leaving it at the default 64GB is fine, or allocate a higher number if you prefer. Preferred space is around 50GB</p> <p></p> <p></p> <p>(Optional) Here you can select a storage location for the VM or just leave it as is. This is to configure a shared directory to make files accessible between macOS and your Ubuntu VM. Click \"Browse...\" to select a folder.</p> <p></p> <p>Once done, enter the details for your VM as you want and press done.</p>"},{"location":"ubuntu-setup/#step-4-start-the-vm","title":"Step 4: Start the VM","text":"<p>Click the play button to start your virtual machine. You'll see the GRUB boot menu where you can select \"Try or Install Ubuntu\".</p> <p></p> <p></p>"},{"location":"ubuntu-setup/#step-11-ubuntu-installation-welcome","title":"Step 11: Ubuntu Installation Welcome","text":"<p>The below window will be shown and once done, open up \"Install Ubuntu 22.04 LTS\". The Ubuntu installer will start and show the welcome screen. Select your language and click \"Continue\".</p> <p></p> <p></p> <p>Choose your keyboard layout. \"English (US)\" is selected by default. You can test your keyboard in the text field below. (Normally, you can leave it as is and just press continue)</p> <p></p> <p>Uncheck the \"Download updates while installing\" so that you have a faster installation</p> <p></p> <p>Select \"Erase disk and install Ubuntu\" since this is a virtual machine. The installer will show a warning about deleting all files.</p> <p></p> <p></p> <p></p> <p>Enter the details you want and press \"Continue\". The installer will copy files and install Ubuntu. This process may take several minutes depending on your system performance.</p> <p></p> <p>Once installation is complete, you'll see the \"Installation Complete\" screen. Click \"Restart Now\" to finish the setup.</p>"},{"location":"ubuntu-setup/#step-6-first-boot","title":"Step 6: First Boot","text":"<p>After restart, you'll see the Ubuntu login screen. Enter your username and password to log in.</p>"},{"location":"ubuntu-setup/#troubleshooting","title":"Troubleshooting","text":"<p>If your OS doesn't boot up to the welcome screen, restart the VM and press <code>ESC</code>, and use your arrow keys to go to \"Boot Manager\", press \"ENTER\", go to <code>ubuntu</code> and press \"ENTER\"</p> <p>You'll be greeted with the Ubuntu desktop environment with the default jellyfish wallpaper. The dock on the left contains common applications.</p> <p>References: </p> <ol> <li>UTM's Ubuntu guide</li> <li>Blog Post </li> </ol>"},{"location":"ubuntu-setup/#step-1-download-virtualbox","title":"Step 1: Download VirtualBox","text":"<p>Download VirtualBox from the official website: https://www.virtualbox.org</p>"},{"location":"ubuntu-setup/#step-2-download-ubuntu-2204-arm64_1","title":"Step 2: Download Ubuntu 22.04 ARM64","text":"<p>Get Ubuntu 22.04 ARM64 (Desktop or Server): https://releases.ubuntu.com/jammy/</p> <p>Choose 22.04 LTS 64-bit (AMD).</p>"},{"location":"ubuntu-setup/#step-3-create-new-virtual-machine_1","title":"Step 3: Create New Virtual Machine","text":"<p>Open UTM and you'll see the welcome screen with options to create a new virtual machine, browse the gallery, or access user guides.</p> <p></p> <p>Choose [Virtualize] then [Linux], choose your downloaded iso image file, and click [Continue] with all of the boxes unchecked.</p> <p></p> <p></p> <p>Click on Browse and select the ISO file you downloaded in Step 2</p> <p></p> <p>On the next screen, leave the memory at 4096 MB and CPU Cores at [Default]. Then specify the amount of space you want to allocate to the virtual machine. It is recommended that you don\u2019t go below around 30GB. Leaving it at the default 64GB is fine, or allocate a higher number if you prefer. Preferred space is around 50GB</p> <p></p> <p></p> <p>(Optional) Here you can select a storage location for the VM or just leave it as is. This is to configure a shared directory to make files accessible between macOS and your Ubuntu VM. Click \"Browse...\" to select a folder.</p> <p></p> <p>Once done, enter the details for your VM as you want and press done.</p>"},{"location":"ubuntu-setup/#step-4-start-the-vm_1","title":"Step 4: Start the VM","text":"<p>Click the play button to start your virtual machine. You'll see the GRUB boot menu where you can select \"Try or Install Ubuntu\".</p> <p></p> <p></p>"},{"location":"ubuntu-setup/#step-11-ubuntu-installation-welcome_1","title":"Step 11: Ubuntu Installation Welcome","text":"<p>The below window will be shown and once done, open up \"Install Ubuntu 22.04 LTS\". The Ubuntu installer will start and show the welcome screen. Select your language and click \"Continue\".</p> <p></p> <p></p> <p>Choose your keyboard layout. \"English (US)\" is selected by default. You can test your keyboard in the text field below. (Normally, you can leave it as is and just press continue)</p> <p></p> <p>Uncheck the \"Download updates while installing\" so that you have a faster installation</p> <p></p> <p>Select \"Erase disk and install Ubuntu\" since this is a virtual machine. The installer will show a warning about deleting all files.</p> <p></p> <p></p> <p></p> <p>Enter the details you want and press \"Continue\". The installer will copy files and install Ubuntu. This process may take several minutes depending on your system performance.</p> <p></p> <p>Once installation is complete, you'll see the \"Installation Complete\" screen. Click \"Restart Now\" to finish the setup.</p>"},{"location":"ubuntu-setup/#step-6-first-boot_1","title":"Step 6: First Boot","text":"<p>After restart, you'll see the Ubuntu login screen. Enter your username and password to log in.</p>"},{"location":"ubuntu-setup/#troubleshooting_1","title":"Troubleshooting","text":"<p>If your OS doesn't boot up to the welcome screen, restart the VM and press <code>ESC</code>, and use your arrow keys to go to \"Boot Manager\", press \"ENTER\", go to <code>ubuntu</code> and press \"ENTER\"</p> <p>You'll be greeted with the Ubuntu desktop environment with the default jellyfish wallpaper. The dock on the left contains common applications.</p> <p>References: </p> <ol> <li>UTM's Ubuntu guide</li> <li>Blog Post </li> </ol>"},{"location":"ubuntu-setup/#post-installation-setup","title":"\u2699\ufe0f Post-Installation Setup","text":"<p>Open up Terminal using <code>Ctrl + Alt + T</code> or from the menu on the bottom left and selecting it.</p>"},{"location":"ubuntu-setup/#step-1-update-system","title":"Step 1: Update System","text":"<pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\n</code></pre>"},{"location":"ubuntu-setup/#step-2-install-essential-tools","title":"Step 2: Install Essential Tools","text":"<pre><code># add new package sources so we can find everything we want to install\nsudo install -m 0755 -d /etc/apt/keyrings &amp;&amp; curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg &amp;&amp; sudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n# reload lists\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n# install packages we will use to download other things\nsudo apt install -y apt-transport-https ca-certificates curl software-properties-common\n\n# grab docker from the internet\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\n# write the new package sources to our list\necho \"deb [signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\n# reload lists again\nsudo apt update\n\n# Development tools\nsudo apt install build-essential cmake git curl wget\n\n# Python tools\nsudo apt install python3-pip python3-venv python-is-python3\n\n# Docker\nsudo apt install docker\nsudo apt install docker-compose*\n\n# check to make sure ubuntu actually grabbed all the packages we want\nsudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin git python-is-python3 docker\n</code></pre>"},{"location":"ubuntu-setup/#step-3-configure-docker-to-run-as-non-root-user","title":"Step 3: Configure Docker to Run as Non-Root User","text":"<p>By default Docker can only be run as an admin, which will cause it to throw lots of random, hard to diagnose errors. These steps will set up Docker so it can be run by anyone. Docker is supposed to run these steps manually, but sometimes doesn't so you may see some random warnings or errors about groups already existing or users already being in the group. This is totally fine, we want to rerun these commands to make sure the entire process worked.</p> <p>Create the docker group if it does not exist: <pre><code>sudo groupadd docker\n</code></pre> Add your user to the docker group: <pre><code>sudo usermod -aG docker $USER\n</code></pre> Log in to the new docker group (to avoid having to log out and log in again; but if not enough, try to reboot): <pre><code>newgrp docker\n</code></pre> Check if Docker can be run without root: <pre><code>docker run hello-world\n</code></pre> This should download a small program and print a short message confirming that Docker works. If it doesn't, reboot using the command: <pre><code>reboot\n</code></pre></p>"},{"location":"ubuntu-setup/#enme480-docker-installation","title":"ENME480 Docker Installation","text":""},{"location":"ubuntu-setup/#step-1-clone-the-repo","title":"Step 1: Clone the Repo","text":"<p>Open up MRC's ENME480 GitHub Repo. You can either download the zip or open up your terminal</p> <pre><code>cd \ngit clone https://github.com/MarylandRoboticsCenter/ENME480_mrc.git\n</code></pre> <p>This will download the repository content into your <code>HOME</code> directory. Next, build Docker image (run the command from the docker folder). This needs to be done every time the Docker file is changed. Here's the commands to do that:</p> <p>For MacOS users, change Line no. 4 in the docker file <code>humble-enme480_ur3e.Dockerfile</code> </p> <p><pre><code># BEFORE\nFROM osrf/ros:humble-desktop AS humble-mod_desktop\n\n# AFTER\nFROM arm64v8/ros:humble AS humble-mod_desktop\n</code></pre> Do not do this on anything other than a MAC! MACs require code that has been compiled in a special way in order to work and this code does not work on other computers!</p>"},{"location":"ubuntu-setup/#step-2-build-and-run-the-docker","title":"Step 2: Build and Run the Docker","text":"<p>For Everyone, run</p> <pre><code>cd ~/ENME480_mrc/docker/\nuserid=$(id -u) groupid=$(id -g) docker compose -f humble-enme480_ur3e-compose.yml build\n</code></pre> <p>Once it is successfully built, run the container with:</p> <pre><code>docker compose -f humble-enme480_ur3e-compose.yml run --rm enme480_ur3e-docker\n</code></pre> <p>In the future, some exercises will require you to open multiple terminals in the same Docker image. In order to achieve this, run:</p> <p><pre><code>docker exec -ti &lt;DELETE THIS AND HIT TAB TO AUTOFILL&gt; bash\n</code></pre> To spawn a new terminal in the already running container. If you repeatedly run the docker compose command you will either get errors or create clones of the container which can not talk to one another.</p> <p>You should see that your name in the terminal has changed from what is was before to enme480_mrc. This means you are inside the Docker container and can run ROS code.</p>"},{"location":"ubuntu-setup/#step-3-wslnative-ubuntu-only-configure-docker-to-run-on-nvidia-gpu","title":"Step 3 (WSL/Native Ubuntu ONLY): Configure Docker to run on NVIDIA GPU","text":"<p>First, try running:</p> <pre><code>nvidia-smi\n</code></pre> <p>You should get an output which looks something like:</p> <p></p> <p>If you do not see an output like this you either don't have an Nvidia GPU or it is not set up correctly. You will not be able to complete the rest of these steps.</p> <p>Getting the correct output from nvidia-smi means you have a Nvidia GPU installed in your computer with drivers properly configured. Now, we will enable the GPU within docker to speed up our simulations. First, run the following commands:</p> <pre><code>sudo touch /etc/docker/daemon.json\n\nsudo chmod 777 /etc/docker/daemon.json\n\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\nsed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\nsudo apt-get update\n\nexport NVIDIA_CONTAINER_TOOLKIT_VERSION=1.17.8-1\nsudo apt-get install -y \\\n    nvidia-container-toolkit=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \\\n    nvidia-container-toolkit-base=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \\\n    libnvidia-container-tools=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \\\n    libnvidia-container1=${NVIDIA_CONTAINER_TOOLKIT_VERSION}\n</code></pre> <p>This will install the Nvidia container toolkit which allows Docker to use your GPU. With the container toolkit installed, we can now configure docker and compose our image:</p> <pre><code>echo $'{\"runtimes\": {\"nvidia\": {\"path\": \"nvidia-container-runtime\", \"runtimeArgs\": []}}}' &gt; /etc/docker/daemon.json &amp;&amp; sudo systemctl restart docker\n</code></pre> <p>This command will add a line to the settings file to enable running with the Nvidia GPU then resets Docker to reload the configuration.</p> <pre><code>cd ~/ENME480_mrc/docker/\nuserid=$(id -u) groupid=$(id -g) docker compose -f humble-enme480_ur3e-nvidia-compose.yml build\n</code></pre> <p>Finally, this command will compose and run our image. This is the command you will want to run in order to get into the Docker and use ROS. Once it finishes you should see that the username in the terminal will have changed to \"enme480_docker\" to let you know that you are in the docker container. From now on, this is the command you will use to launch the docker image.</p> <p>If you do this step you will launch the container with the command:</p> <pre><code>docker compose -f humble-enme480_ur3e-nvidia-compose.yml run --rm enme480_ur3e-docker\n</code></pre> <p>From now on. The command to connect to a running Docker conatiner (i.e. one you have open in a nother terminal) is still:</p> <pre><code>docker exec -ti &lt;hit your tab button&gt; bash\n</code></pre> <p>You should see that your name in the terminal has changed from what is was before to enme480_mrc. This means you are inside the Docker container and can run ROS code.</p>"},{"location":"ubuntu-setup/#tests-for-week-2","title":"Tests for Week 2","text":"<p>From within the docker iamge, ensure the demo nodes are actually downloaded by running:</p> <pre><code>sudo apt update &amp;&amp; sudo apt install ros-humble-demo-nodes-cpp\n</code></pre> <p>To ensure everything is running sucessfully launch the following commands from within the Docker image:</p> <pre><code>ros2 run demo_nodes_cpp talker\n</code></pre> <p>This shouuld begin outputting a list of number to the terminal. Open a new terminal, enter the Docker image and run:</p> <pre><code>ros2 run demo_nodes_cpp listener\n</code></pre> <p>This second script should output the messages being sent by the talker.</p>"},{"location":"ubuntu-setup/#test-in-new-terminal","title":"Test in New Terminal","text":"<pre><code># Open new terminal and run\nros2 --help\n# test gazebo, our simulation suite\nign gazebo\n</code></pre>"},{"location":"ubuntu-setup/#getting-help","title":"\ud83c\udd98 Getting Help","text":""},{"location":"ubuntu-setup/#if-something-goes-wrong","title":"If Something Goes Wrong","text":"<ol> <li>Check Ubuntu Forums: ubuntuforums.org</li> <li>Ask on Piazza: Course Q&amp;A forum</li> <li>Office Hours: Get help from TA or instructor</li> <li>Ubuntu Documentation: help.ubuntu.com</li> </ol>"},{"location":"ubuntu-setup/#emergency-recovery","title":"Emergency Recovery","text":"<ul> <li>Boot from USB and use \"Try Ubuntu\" mode</li> <li>Reinstall Ubuntu as last resort</li> </ul> <p>Last updated: Fall 2025 \u2022 Back to Resources</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/","title":"ENME480 Final Project - Pick and Place Task using UR3e","text":""},{"location":"_labcode/Final%20Project/Final_Project_Details/#objective","title":"Objective","text":"<p>The objective of this project is to control the UR3e to move (at least) three AR-tagged blocks to desired positions using camera image as inputs. We will use OpenCV for processing the image data. The program will also integrate the functions of previous lab assignments. The major objectives are the following - Use OpenCV functions to find the centroid of each block - Convert the pixel coordinates in an image to coordinates in the world frame using a perspective matrix - Move the blocks from the detected positions to predefined desired positions</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#task-description","title":"Task Description","text":"<p>The lab environment is shown below:</p> <p></p> <p>You will be given 3 blocks with different Aruco markers. Your task is to move them out of the workspace into predefined positions. To do so, you will need to find the centroid postion of the top side of each block with an image from the camera mounted above the table, facing down on the workspace. You will convert the detected pixel coordinates to the table frame using a persepctive transform. Then using your inverse kinematics solution, you will pick up the block using a suction gripper mounted at the end effector. Your task is to place each block at a specific location outside the workspace.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#overview-of-the-ros-package","title":"Overview of the ROS Package","text":"<p>The project package should be located on the local lab machines in RAL. You can also find the package with redacted scripts here: https://github.com/ENME480/enme480_project.</p> <p>The nodes have been added to the <code>setup.py</code> file, so you do not need to add that. You will find five scripts as listed in the table below:</p> Script Name Description <code>get_perspective_warping_with_aruco.py</code> Script to create the perspective matrix <code>aruco_detection_test.py</code> Script to test the perspective transform and get coordinates of the blocks in table frame <code>block_detection_aruco.py</code> ROS Node for detecting blocks, uses the same function and changes from <code>aruco_detection_test.py</code> <code>kinematic_functions.py</code> Script to insert all of your FK and IK functions from previous labs <code>main_pipeline.py</code> The main pipeline to strategize and sequence movement of the blocks <p>Please do not edit anything outside the given code snippets (it will lead to errors which will be difficult to identify)</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#procedure-for-setup-in-ral","title":"Procedure for Setup in RAL","text":"<p>Please follow the following steps before you start editing the scripts on RAL machines</p> <ol> <li> <p>UR3e Setup</p> <ul> <li>Power on the robot</li> <li>Release the brakes</li> </ul> </li> <li> <p>Restore the package to original form and pull the latest version</p> </li> </ol> <pre><code>cd rosPackages/ENME480_ws/src/enme480_project\ngit checkout .\ngit pull\n</code></pre> <ol> <li>Interfacing the Robot with PC</li> </ol> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS</li> </ul>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#script-descriptions","title":"Script Descriptions","text":"<p>You are recommended to complete each script in the order suggested in the table. </p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#get_perspective_warping_with_arucopy","title":"<code>get_perspective_warping_with_aruco.py</code>","text":"<p>This script will generate a perspective matrix for the camera to table frame. You need to edit one line to input the reference points on the table. Ensure that you are entering the values in <code>mm</code>. This script will generate a <code>perspective_matrix.npy</code> file in the folder.</p> <p>Before you run this script, ensure that you are in the correct directory. Assuming you have already entered the docker container, run</p> <pre><code>cd ENME480_ws/src/enme480_project/enme480_project/\npython3 get_perspective_warping_with_aruco.py\n</code></pre>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#troubleshooting","title":"Troubleshooting:","text":"<p>If you get a missing keyboard package error run the following command</p> <pre><code>pip install keyboard\n</code></pre> <p>Once run, you will see a window with the live camera feed. Click on the reference points in the same order that you have listed in your script. It will calulate the perspective transform and a new window will pop-up showing a blue dot at <code>(175,175)</code> on the table coordinate frame. If this is right, you can proceed to the next script.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#aruco_detection_testpy","title":"<code>aruco_detection_test.py</code>","text":"<p>This script will give you a live detection of the aruco markers and their location w.r.t the table frame in real-time. You need to modify the <code>image_frame_to_table_frame()</code> function in the script. Use the math from prespective transforms to do the same. You can find a file discussing perspective transforms in the main folder on this repository.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#block_detection_arucopy","title":"<code>block_detection_aruco.py</code>","text":"<p>This is the ROS node and a Python class for all the functions in the <code>aruco_detection_test.py</code> script. If your <code>aruco_detection_test.py</code> could detect the block coordinates correctly, please copy the same function to the snippet for <code>image_frame_to_table_frame()</code> function in this script as well.</p> <p>You can test this script by running the following commands:</p> <ul> <li>In a new terminal in the docker container, launch the camera node:</li> </ul> <pre><code>ros2 launch usb_cam camera.launch.py\n</code></pre>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#troubleshooting_1","title":"Troubleshooting:","text":"<p>If you get a Pydantic error run the following command</p> <pre><code>sudo pip install pydantic==1.10.9\n</code></pre> <p>Once the camera node is up and running, run the following command in a seperate terminal:</p> <pre><code>ros2 run enme480_project aruco_tracker\n</code></pre> <p>It will publish data under two topics <code>/aruco_detection/image</code> and <code>/aruco_detection/positions</code></p> <p>You can view the image using </p> <pre><code>ros2 run rqt_image_view rqt_image_view\n</code></pre> <p>and it should show the same image in the window as the one you saw with <code>aruco_detection_test.py</code>, once you select the topic.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#kinematic_functionspy","title":"<code>kinematic_functions.py</code>","text":"<p>This script will use your functions from previous labs and if you have the script working correctly for your FK and IK labs, you can copy the exact same functions here under the functions <code>calculate_dh_transform()</code> and <code>inverse_kinematics()</code> within the given snippets. We need to verify if your IK script is working correctly so please call the TAs over top show your final IK code working before you copy this.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#main_pipelinepy","title":"<code>main_pipeline.py</code>","text":"<p>This script is where you will sequence and startegize the pick and place process. In this script, you have to edit the following functions:</p> <ol> <li> <p><code>move_arm()</code></p> <p>This function will take in the desired joint positions and publish them using the message data structure given in code comments</p> </li> <li> <p><code>gripper_control()</code></p> <p>This function will take in the desired state of the gripper and publish it using the message data structure given in code comments</p> </li> <li> <p><code>move_block()</code></p> <p>Here, you need to work on giving the sequence of positions you want the block to move to for moving a block from an initial position to a final position. Keep in mind that every block needs to be picked up, raised up and then moved. Do not give it a sequence to drag it accross the table.</p> </li> <li> <p><code>process_blocks()</code></p> <p>This function is where you will enter the startegy and sorting method to place the blocks in their desired positions given their IDs, pre-defined destinations.</p> </li> </ol> <p>Once everything is ready, call the TAs over before you execute the node</p> <pre><code>ros2 run enme480_project main_pipeline\n</code></pre>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#submission-requirements","title":"Submission Requirements","text":"<p>One single PDF containing the following:</p> <ul> <li>Pseudo code for detecting and moving the block  (no specific format to be followed)</li> <li>Math for camera frame to table frame (your intuition behind the perspective warping, and transformation from camera frame to image frame)</li> <li>Video of pick and place task on UR3e (as a link (GDrive/YouTube) in the report)</li> <li>Extra Credit: Stacking (3.33 pts per block) - Max 10pts possible </li> </ul>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/","title":"Week 10 - UR3e Forward Kinematics","text":""},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#objectives","title":"Objectives","text":"<ul> <li>Use forward kinematics (FK) to compute the pose of a UR3e robot arm's end effector.</li> <li>Determine where a laser pointer on the end effector intersects with a workbench at an arbitrary height.</li> <li>Publish commands to control the UR3e robot in ROS2 and visualize results.</li> </ul>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#1-getting-started-with-the-ur3e","title":"1. Getting Started with the UR3e","text":"<ul> <li>Power on the robot</li> <li> <p>Release the brakes</p> </li> <li> <p>Interfacing the Robot with PC</p> </li> </ul> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS</li> </ul> <p>In one more terminal windows launch these commands:</p> <pre><code>ros2 launch ur3e_mrc ur3e_enme480.launch\n</code></pre>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#2-modify-the-fk-script-to-move-the-robot","title":"2. Modify the FK script to move the robot","text":"<p>Due to inaccuracies in some of the DH tables, resulting in safety risks, we are giving you a code structure that you need to enter your code in.</p> <p>It is located in <code>~/rosPackages/ENME480_ws/enme480_fk_labs/enme480_fk_labs/ur3e_fk.py</code></p> <p>If you are using your own code, remember to change the node name to <code>ur3e_fk_publisher</code></p> <p>To run it:</p> <pre><code>ros2 run enme480_lab_fk ur3e_fk joint1 joint2 joint3 joint4 joint5 joint6\n</code></pre>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#3-predicting-where-the-laser-point-will-land","title":"3. Predicting where the laser point will land","text":"<p>Since you know the position and orientation of the end effector (attached with a laser pointer), you have to predict where the laser point will land on the workbench. (Hint: Think in terms of vector and plane intersection)</p> <p>Assume the <code>z_table = 0</code>. </p> <p>We are providing you with the code in lab, but you need to show the math behind it in your lab report.</p> <p>Turning on the laser pointer:</p> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#4-test-points","title":"4. Test Points","text":"<p>Run the robot for the following test points:</p> Test Point Inputs (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) End Effector Position (Your Code) <code>(x y z)</code> Laser Position on Workbench (from Code) (<code>x,y</code>) Laser Position on Workbench(Measured) <code>(x, y)</code> [0, -45, 0, 45, -90, 60] [-30, -60, 80, -10, -90, -30] [30 -70 80 -10 -90 10] [-30, -60, 60, -10, -90, -30]"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#submission","title":"Submission","text":"<p>Please create a neatly typed/written report for the lab including the following:</p> <ul> <li>Correct frame and axes assignments for the UR3e</li> <li>A correct DH table for the UR3e (with the updated dimensions)</li> <li>A detailed derivation of how the position of laser point is predicted on the workbench.</li> <li>Error Analysis (for at least 2 points)</li> <li>Your code snippets for the functions supposed to be changed (function for moving the robot and calulating DH transformation matrix)</li> </ul>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/","title":"Week 11 - UR3e Inverse Kinematics","text":""},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#objectives","title":"Objectives","text":"<ul> <li>Use inverse kinematics (IK) to compute the required joint angles of a UR3e robot arm for its end effector to reach a specific point.</li> <li>Determine if the laser pointer is close to the predicted cartesian coordinates.</li> <li>Publish commands to control the UR3e robot in ROS2 and visualize results.</li> </ul>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#1-getting-started-with-the-ur3e","title":"1. Getting Started with the UR3e","text":"<ul> <li>Power on the robot</li> <li>Release the brakes</li> </ul>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#interfacing-the-robot-with-pc","title":"Interfacing the Robot with PC","text":"<p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS.</li> </ul> <p>In one more terminal window launch this command:</p> <pre><code>ros2 launch ur3e_mrc ur3e_enme480.launch\n</code></pre>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#2-modify-the-ik-script-to-move-the-robot","title":"2. Modify the IK script to move the robot","text":"<p>Due to inaccuracies in some of your IK calculations, resulting in safety risks due to singulartities, we are giving you a code structure that you need to enter your code in.</p> <p>It is located in <code>~/rosPackages/ENME480_ws/src/enme480_fk_labs/enme480_fk_labs/ur3e_ik.py</code></p> <p>To refresh the folder to original state run the following commands:</p> <pre><code>cd ~/ENME480_ws/src/enme480_lab_fk\ngit checkout .\n</code></pre> <p>You need to modify the following functions within the given snippet (do not change anything else in the code):</p> <ul> <li><code>send_command()</code> - will be the same as last time (just remove conversion to radians since IK takes care of it)</li> <li><code>calculate_dh_transform()</code> - will be exactly same as last time (just make changes to DH parameters if wrong)</li> <li><code>inverse_kinematics()</code> - will be exactly similar as your simulation code</li> </ul> <p>Helpful Tip: Use tools like Pastebin or Google Docs to move your code from your laptop to the lab machine</p> <p>If you are using your own code, remember to change the node name to <code>ur3e_ik_publisher</code></p> <p>To run it:</p> <pre><code>ros2 run enme480_lab_fk ur3e_ik x y z yaw\n</code></pre> <p>If your IK code has high or slight error, you will receive a prompt on your terminal. Please follow the instructions. The robot will move regardless but those error mean that you need to check your calculations.</p>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#3-predicting-where-the-laser-point-will-land","title":"3. Predicting where the laser point will land","text":"<p>Since we are constraining IK to always face down, the laser point will exactly point at the same <code>(x,y)</code> as the end effector. You just need to measure z. Your prediction will depend on your DH transformation.</p> <p>Turning on the laser pointer:</p> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre> <p>If your DH transform is right, you should recieve a similar transformation matrix as the <code>Correct Transformation Matrix</code> on your terminal. Otherwise, work on it to get a matrix as similar as possible</p>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#4-test-points","title":"4. Test Points","text":"<p>Run the robot for the following test points and record the following data:</p> Test Point Inputs (x, y, z, Yaw) Joint Angles (Your Code)  <code>(\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4)</code> Correct Joint Angles <code>(\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4)</code> Laser Position on Workbench (Your Prediction) <code>(x, y)</code> Laser Position on Workbench (Correct Prediction) <code>(x, y)</code> Laser Position on Workbench (Measured Prediction) <code>(x, y)</code> End Effector Position (Your Prediction) <code>(x, y, z)</code> End Effector Position (Correct Prediction) <code>(x, y, z)</code> End Effector Position (Measured) <code>(x, y, z)</code> [0.2, 0.2, 0.2, 0] [0.2, 0.4, 0.2, 0] [0.3, 0.4, 0.1, 45] [0.3, 0.2, 0.25, 60] [0.25, 0.3, 0.3, -30]"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#5-before-you-leave-the-lab","title":"5. Before you leave the lab","text":"<p>Send yourself the backup/copy of your script and restore the package to its blank version.</p> <p>IMPORTANT: The below command will erase your script from the computer so take a backup of it before you run it</p> <pre><code>cd ~/rosPackages/ENME480_ws/src/enme480_lab_fk\ngit checkout .\n</code></pre>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#submission","title":"Submission","text":"<p>Please create a neatly typed/written report for the lab including the following: 1. Your IK derivation - you can resue the one from Week 8 submission if that was right. If anything changed or you noticed errors in your previous derivation, make a note of it in the report including the reason behind the error. 2. Comparsion table for Step 4. 3. Write a paragraph on the reasons behind discrepancies in measurements and calculations. 4. What are the potential sources of singlularities and how will avoid them when you are implementing the code? If you found any singularities, be sure to list them and discuss possible causes. 5. Code snippet of <code>inverse_kinematics()</code> function that you used.</p>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/","title":"Week 2 - Software Setup","text":""},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#overview","title":"Overview:","text":"<p>This lab will walk you through installing and configuring and testing the sofftware we will need for this class.</p>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#slides","title":"Slides:","text":"<p>Lab 2 Slides</p>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#goals","title":"Goals:","text":"<p>In this lab, we will follow the pages on the wiki to: - Install Ubuntu - Set up the ROS2 MRC Docker Image - Set up an IDE to work with the Docker Image</p>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#relevant-wiki-pages","title":"Relevant Wiki Pages:","text":"<p>Software Setup</p> <p>Dev Environmnet Information</p>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#next-steps","title":"Next Steps:","text":""},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#additional-resources","title":"Additional Resources:","text":"<p>Piazza</p>"},{"location":"_labcode/Week%203%20-%20ROS/","title":"Week 3 - Introduction to ROS (Robot Operating System)","text":""},{"location":"_labcode/Week%203%20-%20ROS/#overview","title":"Overview","text":"<p>Introduction to ROS (Robot Operating System), the fundamental framework for robotics development and simulation.</p>"},{"location":"_labcode/Week%203%20-%20ROS/#materials","title":"Materials","text":"<ul> <li>ENME480_IntroToROS.pdf - Comprehensive introduction to ROS concepts and usage</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#key-topics","title":"Key Topics","text":"<ul> <li>ROS Fundamentals: Understanding the Robot Operating System architecture</li> <li>Core Concepts: Nodes, topics, services, and actions</li> <li>Communication: How ROS components communicate with each other</li> <li>Development Workflow: Building and running ROS applications</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#learning-objectives","title":"Learning Objectives","text":"<ul> <li>Understand ROS architecture and philosophy</li> <li>Learn basic ROS concepts (nodes, topics, services)</li> <li>Set up ROS development environment</li> <li>Create simple ROS programs</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#prerequisites","title":"Prerequisites","text":"<ul> <li>Week 2: Ubuntu and Python basics</li> <li>Basic understanding of programming concepts</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#ros-concepts-covered","title":"ROS Concepts Covered","text":"<ul> <li>Nodes: Individual processes that perform computation</li> <li>Topics: Asynchronous communication mechanism</li> <li>Services: Synchronous request-response communication</li> <li>Messages: Data structures for communication</li> <li>Packages: Organizational units for ROS code</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#next-steps","title":"Next Steps","text":"<p>This ROS foundation will enable you to work with Gazebo simulation in Week 4.</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/","title":"Week 4 - Studio 4.1 - Gazebo Demo","text":"<p>The objective of this lab is to install the UR3e packages and have a working simulation of the robot in Gazebo.</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#package-installation","title":"Package Installation","text":"<p>There are two methods to do this:</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#1-source-installation","title":"1. Source Installation","text":"<p>Clone the following repositories in your workspace:</p> <pre><code>git clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Driver.git\ngit clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation.git\n</code></pre> <p>Build and source the workspace</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#2-pre-configured-docker-container","title":"2. Pre-configured Docker Container","text":"<p>Find the Dockerfile in <code>/Resources/Docker Container/humble_dockerfile.Dockerfile</code> and build and run the container. This is the preferred method but it can lead to issues with Gazebo (looking into a foolproof solution - will be updated this week)</p> <pre><code>sudo docker build -t humble_image -f humble_dockerfile.Dockerfile .\nsudo docker run -it humble_image\n</code></pre>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#troubleshooting-no-joint-trajcetory-controller-or-controller-interface","title":"Troubleshooting - no joint trajcetory controller or controller interface","text":"<p>If you run into an issue with building packages due to missing a joint controller run:</p> <pre><code>sudo apt install ros-humble-joint-trajectory-controller\n\nsudo apt install ros-humble-controller-interface\n\nsudo apt install ros-humble-ur-*\n\nsudo apt install ros-humble-control-*\n\nsudo apt install ros-humble-ros2-control-*\n</code></pre>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#troubleshooting-on-macs","title":"Troubleshooting on Macs","text":"<p>Gazebo doesn\u2019t directly support ARM64 architecture. As a result, we need to manually compile and install it.</p> <p>Install necessary dependencies:</p> <pre><code>sudo apt-add-repository ppa:dartsim\n\nsudo apt update\n\nsudo apt install libdart-dev libdart-utils-dev libdart-external-ikfast-dev libsdformat9-dev libfreeimage-dev libprotoc-dev libprotobuf-dev protobuf-compiler freeglut3-dev libcurl4-openssl-dev libtinyxml-dev libtinyxml2-dev libtar-dev libtbb-dev libogre-1.9-dev libxml2-dev pkg-config qtbase5-dev libqwt-qt5-dev libltdl-dev libgts-dev libboost-thread-dev libboost-system-dev libboost-filesystem-dev libboost-program-options-dev libboost-regex-dev libboost-iostreams-dev libsimbody-dev libignition-common3-dev libignition-fuel-tools4-dev libignition-transport8-dev libignition-math6-dev libignition-msgs5-dev\n</code></pre> <ol> <li> <p>Clone the Gazebo source code from GitHub: <pre><code>cd ~/Downloads/\n\ngit clone https://github.com/osrf/gazebo\n</code></pre></p> </li> <li> <p>Modify the line 647 of <code>SearchForStuff.cmake</code> in <code>Downloads/gazebo/cmake</code>. Change from 9.8 to 9.7 as the default libsdformat version of ubuntu22 is 9.7.</p> </li> <li> <p>Compile and install Gazebo:</p> </li> </ol> <pre><code>cd ~/Downloads/gazebo\nmkdir build &amp;&amp; cd build\ncmake ../\nmake -j3\nsudo make install\n</code></pre> <ol> <li>Add Gazebo to your environment path by modifying .bashrc*:</li> </ol> <pre><code>export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\nexport PATH=/usr/local/bin:$PATH\nexport PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH\n</code></pre> <ol> <li>In your workspace, add the <code>gazebo_ros</code> package:</li> </ol> <pre><code>cd ~/enme480_ws/src\ngit clone https://github.com/ros-simulation/gazebo_ros_pkgs\ncd gazebo_ros_pkgs\ngit checkout ros2\ncd ~/enme480_ws/src\ngit clone -b humble https://github.com/ros-controls/gazebo_ros2_control\n</code></pre> <ol> <li>Build and source your workspace</li> </ol>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#running-ur3-demo-on-gazebo","title":"Running UR3 Demo on Gazebo","text":"<p>Launch the UR3e in Gazebo</p> <pre><code>ros2 launch ur_simulation_gazebo ur_sim_control.launch.py\n</code></pre> <p>It should open up two windows with UR3e arm in Gazebo &amp; RViz. </p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#troubleshooting-gazebo-does-not-open-up-waiting-for-controller","title":"Troubleshooting - Gazebo does not open up; waiting for controller","text":"<p>Run the following command in a seperate terminal before launching the previous command (in order to use this method, start and source 3 consoles, run this command, then the one above it then the last command on this page).</p> <pre><code>gazebo -s libgazebo_ros_init.so -s libgazebo_ros_factory.so myworld.world\n</code></pre> <p>To test if the simulation works, run the following command</p> <p><pre><code>ros2 launch ur_robot_driver test_joint_trajectory_controller.launch.py\n</code></pre> This will keep moving the robot continously in multiple positions.</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#assignment","title":"Assignment","text":"<p>Prepare a report answering the following questions and posting relevant screenshots 1. Screenshots of Gazebo &amp; RViz with the UR3 in 3 different positions 2. Show the topics </p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/","title":"Week 4 - Studio 4.2 - Rotation Matrices in Python","text":""},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#overview","title":"Overview","text":"<p>This assignment involves modifying a Python script named <code>studio_4_2.py</code> (located in the this folder) that performs matrix operations using rotation matrices. The task includes defining a function to generate a 3x3 rotation matrix, initializing a specific vector, and calculating the result of matrix multiplications involving two angles.</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#requirements","title":"Requirements","text":"<ul> <li>Python 3.x</li> <li>NumPy library</li> </ul>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#instructions","title":"Instructions","text":"<ol> <li>Define a function <code>R(phi)</code>:</li> <li> <p>This function should take an angle <code>\u03c6</code> (phi) as input and generate a 3x3 rotation matrix using the formula:</p> <p>\\(<code>R(\\phi) =   \\begin{bmatrix}  \\cos\\phi &amp; -\\sin\\phi &amp; 0 \\\\  \\sin\\phi &amp; \\cos\\phi &amp; 0 \\\\  0 &amp; 0 &amp; 1  \\end{bmatrix}</code>\\)</p> </li> <li> <p>Define a vector <code>v1</code>:</p> </li> <li> <p>Inside the <code>Test()</code> function, define a 3x1 NumPy array:</p> <p>\\(<code>v_1 =   \\begin{bmatrix}  1 \\\\  0.6 \\\\  0.8  \\end{bmatrix}</code>\\)</p> </li> <li> <p>Calculate the result <code>v2</code>:</p> </li> <li> <p>Use the angles <code>\u03c61 = 0.5</code> and <code>\u03c62 = 0.8</code> to compute the matrix multiplication:</p> <p>\\(<code>v_2 = R(\\phi_2) R(\\phi_1) v_1</code>\\)</p> </li> <li> <p>Run the script:</p> </li> <li> <p>Execute the script from the terminal using:</p> <pre><code>python studio_4_2.py\n</code></pre> </li> <li> <p>The output should display the calculated value of <code>v2</code>.</p> </li> </ol>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#submission","title":"Submission","text":"<ul> <li>Submit a PDF containing your <code>studio_4_2.py</code> script and a screenshot of the terminal output to ELMS.</li> </ul>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#notes","title":"Notes","text":"<ul> <li>Ensure that the script runs without errors and outputs the correct <code>v2</code> value.</li> <li>Refer to the rubric on ELMS for grading</li> <li>You will not be assessed if you do not follow the given script format</li> </ul>"},{"location":"_labcode/Week%205%20-%20UR3e%20Intro/UR3eOperation/","title":"Week 5 - UR3e Intro &amp; Operation","text":""},{"location":"_labcode/Week%205%20-%20UR3e%20Intro/UR3eOperation/#objectives","title":"Objectives","text":"<ul> <li>Learn how to use the Pendant</li> <li>Interface UR3e with ROS packages on RAL machines</li> <li>Visualize ROS Processes</li> <li>Use MoveIt to operate the robot</li> </ul>"},{"location":"_labcode/Week%205%20-%20UR3e%20Intro/UR3eOperation/#procedure","title":"Procedure","text":"<ol> <li> <p>You will be shown how to use the pendant</p> </li> <li> <p>Power on the robot</p> </li> <li>Release the brakes</li> <li>Try Freedrive</li> <li>Try Emergency Stop</li> <li>Try setting the joint anngles to moe the robot (Forward Kinematics)</li> <li>Try setting the final end effector position to move the robot (Inverse Kinematics)</li> <li></li> <li> <p>Interfacing the Robot with PC</p> </li> </ol> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li> <p>Follow instructions in the file</p> </li> <li> <p>Visualize ROS Processes</p> </li> <li> <p>Get the list of ROS topics</p> </li> <li>Open up RQT</li> <li>Visualize Node Graphs</li> <li> <p>You will be shown how to generate plots in RQT to analyze data</p> </li> <li> <p>Move the robot using MoveIt</p> </li> <li> <p>Open up the MoveIt node</p> </li> </ul> <pre><code>ros2 launch ur_moveit_config ur_moveit.launch.py ur_type:=ur3e\n</code></pre> <ul> <li>You will be shown how to move the robot using MoveIt</li> </ul>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/","title":"Week 6 - UR3e Forward Kinematics on Gazebo","text":""},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#objectives","title":"Objectives","text":"<ul> <li>Add elements to your Gazebo environment</li> <li>Calculate DH parameters of UR3e</li> <li>Create a publisher to move the robot to desired joint states</li> <li>Find the end effector pose</li> <li>Validate and compare the pose readings from DH-parameter calculation &amp; end effector</li> </ul>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#1-adding-physical-elements-in-gazebo","title":"1. Adding Physical Elements in Gazebo","text":"<p>Your aim is to add a base plate to your Gazebo environment and mount the robot on top of it, and link them.</p> <p>To do so, we modify the Unified Robot Description Format (URDF) file for the environment. This is an XML (Extensible Markup Language) specification. Another commonly known markup language is HTML. The major contrast between XML and HTML is that in addition to diplaying data, XML allows different applications to exchange and store data and its structure in a way that is universally understood. For more info, refer to this link: http://wiki.ros.org/urdf/XML/model</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#step-1-build-the-ur-description-package","title":"Step 1: Build the UR Description Package","text":"<p>This package contains the mesh files and all the description files to simulate the UR robots. Clone the repositiory in your src folder of your workspace</p> <pre><code>git clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Description.git\n</code></pre> <p>Build and source your workspace</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#step-2-modify-the-description-files-to-add-a-plate","title":"Step 2: Modify the Description Files to Add a Plate","text":"<p>Check the <code>urdf</code> folder in the directory. We will be modifying <code>ur.urdf.xacro</code> and creating a duplicate of <code>ur_macro.xacro</code> and rename the copy as <code>enme480_fk.xacro</code>. As to why we are modifying these files, will be explained in the studio session.</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#-changes-in-ururdfxacro","title":"- Changes in <code>ur.urdf.xacro</code> :","text":"<p>Here just change two things:</p> <ul> <li>Replace the main macro file being imported from <code>ur_macro.xacro</code> to <code>enme480_fk.xacro</code></li> <li>The default <code>ur_type</code> value should be <code>ur3e</code> (just to make life easy by making your command shorter)</li> </ul>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#-changes-in-enme480_fkxacro","title":"- Changes in <code>enme480_fk.xacro</code>","text":"<p>Add the following snippet to add the plate mesh to the environment. The code will be explained in class and you have to figure out where to add the snippets. Keep a base plate dimensions of <code>0.3 x 0.3 x 0.01</code></p> <p>Snippet 1: Defining the description of Base Plate</p> <pre><code>   &lt;!-- Define the base plate --&gt;\n   &lt;link name=\"${tf_prefix}base_plate\"&gt;\n     &lt;visual&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt;  &lt;!-- Modify Adjust origin as needed --&gt;\n       &lt;geometry&gt;\n         &lt;box size=\"0 0 0\"/&gt;  &lt;!-- Modify Size of the base plate (length x width x height) --&gt;\n       &lt;/geometry&gt;\n       &lt;material name=\"orange\"/&gt;\n     &lt;/visual&gt;\n     &lt;collision&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt; &lt;!-- Modify this --&gt;\n       &lt;geometry&gt;\n         &lt;box size=\"0 0 0\"/&gt; &lt;!-- Modify this --&gt;\n       &lt;/geometry&gt;\n     &lt;/collision&gt;\n     &lt;inertial&gt;\n       &lt;mass value=\"1.0\"/&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt; &lt;!-- Modify this --&gt;\n       &lt;inertia ixx=\"0.001\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.001\" iyz=\"0.0\" izz=\"0.001\"/&gt;\n     &lt;/inertial&gt;\n   &lt;/link&gt;\n</code></pre> <p>Snippet 2: Defining the relationship between base plate and the robot</p> <p>You will find a code block that defines how the base link connects to the environment. Replace that with the snippet below</p> <pre><code>   &lt;!-- base_joint fixes ..... to the environment  (Find this similar part in the code and replace it) --&gt;\n   &lt;joint name=\"${tf_prefix}base_joint\" type=\"fixed\"&gt;\n     &lt;xacro:insert_block name=\"origin\" /&gt;\n     &lt;parent link=\"${parent}\" /&gt;\n     &lt;child link=\"${tf_prefix}.................\" /&gt; &lt;!-- Modify this --&gt;\n   &lt;/joint&gt;\n\n   &lt;!-- Attach base plate to the robot's base link --&gt;\n   &lt;joint name=\"${tf_prefix}base_to_base_plate\" type=\"fixed\"&gt;\n     &lt;parent link=\"${tf_prefix}............\" /&gt; &lt;!-- Modify this based on the child and parent --&gt;\n     &lt;child link=\"${tf_prefix}.............\" /&gt; &lt;!-- Modify this based on child and parent Hint Check the subsequent code to know the childparent --&gt;\n     &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\"/&gt;  &lt;!-- Adjust origin to place the base plate correctly --&gt;\n   &lt;/joint&gt;\n</code></pre> <p>Try launching the robot simulation to check if the pate is visible and the robot is standing on the plate:</p> <pre><code>ros2 launch ur_simulation_gazebo ur_sim_control.launch.py ur_type:=ur3e\n</code></pre> <p>You can modify the launch file to have <code>ur3e</code> as the default argument so that you don't need to specify it everytime</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#2-dh-parameters-of-ur3e","title":"2. DH Parameters of UR3e","text":"<p>Link for UR3e specifications: https://www.universal-robots.com/media/1807464/ur3e-rgb-fact-sheet-landscape-a4.pdf</p> <p>The PDF for UR3 dimensions is included in the folder for <code>Week 6</code> and the zero configuration (all joint angles are 0) for the robot looks like given in this image</p> <p>You need to create a DH-table for the robot and annotate the given PDF to show the frames and axes used. The unknowns here will be the joint angles. Include the base plate in your calculations as well.</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#3-creating-a-publisher-script-to-move-the-robot","title":"3. Creating a Publisher script to move the robot","text":"<p>(NEW) Bridge packages for custom topics between ur_driver and ENME480 labs</p> <ul> <li>Clone the following repositories into your workspace</li> </ul> <p><pre><code>git clone https://github.com/MarylandRoboticsCenter/ur3e_mrc.git\ngit clone https://github.com/ENME480/ur3e_enme480.git\n</code></pre> - Build and source your workspace.</p> <p>We have a predefined custom message for obtaining position and sending commands:</p> <p>CommandUR3e.msg  <pre><code>float64[] destination\nfloat64 v\nfloat64 a\nbool io_0\n</code></pre> (destination is the set of joint angles <code>[theta1 theta2 theta3 theta4 theta5 theta6]</code>)</p> <p>PositionUR3e.msg <pre><code>float64[] position\nbool is_ready\n</code></pre></p> <p>(position is the set of 6DoF pose of the end effector <code>[x y z roll pitch yaw]</code>)</p> <p>Now run the following command: <pre><code>ros2 launch ur3e_enme480 ur3e_sim_enme480.launch.py\n</code></pre></p> <p>You should be able to see the topics <code>/ur3/position</code> and <code>/ur3/command</code>. Refer to this link for details of the package and its usage.</p> <p>~~Using the topic <code>/joint_trajectory_controller/joint_trajectory</code> and the message type <code>JointTrajectory</code> and <code>JointTrajectoryPoint</code> from <code>trajectory_msgs</code>, create a publisher to move the robot to desired joint angles. Keep in mind that the angles given to th robot sould be in radians but we want to give the input in degrees so ensure that you have converted that.~~</p> <p>Using the topic <code>/ur3/command</code> and the message type <code>CommandUR3e</code> from <code>ur3e_mrc.msg</code>, create a publisher to move the robot to desired joint angles. Keep in mind that the angles given to the robot should be in radians but we want to give the input in degrees so ensure that you have converted that. You can set the velocity and acceleration as <code>1.0</code></p> <p>The second step is to create a function (or multiple functions) in the same Python class to calculate the end effector pose using forward kinematics via DH-parameters, and print that out as the final transformation matrix.</p> <p>Your code will have a structure like this (it can be different but just a baseline)</p> <pre><code>import ....\n\nclass ForwardKinematicsUR3e(...)\n\n  def __init__(self): \n    ...\n    ...\n\n  def move_robot(...):\n    ...\n    ...\n\n  def calculate_fk_from_dh(...):\n    ...\n    ...\n\n\ndef main(...):\n\n  ...\n  ...\n\nif __name__ == '__main__':\n  main()\n</code></pre> <p>Hint: Use the structure from your <code>pubsub</code> codes which you have done previously. ~~You can get the message info for <code>JointTrajectory</code> and <code>JointTrajectoryPoint</code> here: http://docs.ros.org/en/noetic/api/trajectory_msgs/html/msg/JointTrajectory.html &amp; http://docs.ros.org/en/noetic/api/trajectory_msgs/html/msg/JointTrajectoryPoint.html~~</p> <p>Your command should look something like this:</p> <p><pre><code>ros2 run &lt;package_name&gt; ur3e_fk 0 0 0 0 0 0\n</code></pre> where the numbers represent the six joint angles in degrees. Hint: Look into how you can send arguments to a Python script</p> <p>Don't forget to add the node to your <code>setup.py</code> in your package.</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#4-get-the-end-effector-pose-from-ur3position","title":"4. Get the end effector pose from <code>/ur3/position</code>","text":"<p>~~Here you will be using the <code>/tf</code> topic which denotes the transformations in your workspace. The topic publishes the relative transform between all the joints. Your goal is to find the relative transform between the <code>base_plate</code> and the last link on the robot (figure out which is the last link). You will be shown what <code>tf</code> is in class.~~</p> <p>~~Get the relative transform and print the position and orientation. (Hint: There is a tf2 library that will help you to trnasform between frames without needing to do calcuulations.)~~</p> <p>TF (TransForm) calculations are being done on the backend now. You will get the position of the end effector from <code>/ur3/position</code>. </p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#5-compare-the-readings","title":"5. Compare the readings","text":"<p>You need to compare the readings from the DH-parameters method with the actual robot position through <code>/tf</code>. Put that in a table for the following 5 test cases:</p> <p>Set 1: <code>[0 0 0 0 0 0]</code> (robot should be horizontal)</p> <p>Set 2: <code>[0 0 -90 90 0 0]</code></p> <p>Set 3: <code>[0 -45 45 -90 30 90]</code></p> <p>Set 4: <code>[90 -60 30 20 10 50]</code></p> <p>Set 5: <code>[0 -90 0 0 0 0]</code> (robot should be upright)</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#submission","title":"Submission","text":"<ol> <li> <p>Show a screenshot of the base plate with the robot </p> </li> <li> <p>Show the DH Table for the robot</p> </li> <li> <p>Show a figure with frames and axes marked</p> </li> <li> <p>For each test case, show:</p> </li> <li> <p>The set of joint angle values (\u03b81, \u03b82, \u03b83, \u03b84, \u03b85, \u03b86)</p> </li> <li>The final transformation matrix (from Python script). You can add it as a readable image of the output window as well.</li> <li>The calculated pose from DH table in simulation vs the pose from <code>/ur3/position</code></li> <li> <p>The scalar error</p> </li> <li> <p>Discuss the sources of error</p> </li> <li> <p>An appendix to show your scripts</p> </li> <li> <p><code>enme480_fk.xacro</code></p> </li> <li>FK publisher (including the Python script for DH transformation)</li> <li>~~<code>tf</code> subscriber~~ Screenshot of messages received from <code>/ur3/position</code></li> </ol> <p>Add everything in one single PDF file and upload it.</p>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/","title":"Week 8 - UR3e Inverse Kinematics on Gazebo","text":""},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#objectives","title":"Objectives","text":"<p>The objective of this lab is to derive and implement a solution to the inverse kinematics problem for the UR3 robot. In this lab we will:</p> <ul> <li>Derive elbow-up inverse kinematic equations for the UR3</li> <li>Write a publisher that moves the UR3 to a point in space specified by the user</li> </ul>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#task-description","title":"Task Description","text":"<p>The joints and links of the UR3 robot are annotated in Figure 1. The goal is to find the rotation angles of the 6 joints <code>(\u03b81, ... , \u03b86)</code>, so that the end-effector (end of Link 10) can reach to a given position <code>(x_grip, y_grip, z_grip)</code> and orientation <code>{\u03b8_yaw, \u03b8_pitch, \u03b8_roll}</code> input by the user. There are many possible solutions to the inverse kinematics problem. To make the derivation manageable, we will only implement one of the elbow-up solution in this lab. <code>\u03b8_pitch</code> and <code>\u03b8_roll</code> of the end-effector are fixed by letting the vacuum gripper aluminum plate (Link 9) always be parallel to the x-y plane of world frame coordinates (i.e., desk plane), and \u03b85 is always equal to \u221290\u00b0. Thus, the user will input the desired position and yaw angle of the end-effector in world frame coordinates <code>(xWgrip, yWgrip, zWgrip, yawWgrip)</code>, and the output of the program should be the joint angles <code>\u03b81 to \u03b86</code>.</p> <p></p>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#solution-steps","title":"Solution Steps","text":"<p>In this section, a suggested solution approach is described.</p> <ol> <li>Establish the world coordinate frame (frame w) centered at the corner of the UR3\u2019s base shown in Figure 2. We will solve the inverse kinematics problem in the base frame (frame 0), so we will convert the coordinates (\ud835\udc65\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d) entered by the user to base frame coordinates (\ud835\udc65\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d). The origin of the base frame is at (-0.15, 0.15, 0.01) in the world frame. Set \ud835\udf035 = \u221290\u00b0 in unit of radian.\"</li> </ol> <p></p> <ol> <li>We will define a \u201cwrist center\u201d as \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b which equals the same desired \ud835\udc67 value of the vacuum gripper, and \ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b are the coordinates of <code>\ud835\udf036</code>\u2019s \ud835\udc67 axis (see Figure 1). Link 9 (gripper plate) has a length of 0.0535 meters from the center line of the gripper to the center line of Joint 6. Given the desired position of the gripper <code>(\ud835\udc65\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d)</code> in the base frame and the yaw angle, find wrist\u2019s center point (\ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b).</li> <li>Given the wrist\u2019s center point (\ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b), find the waist angle \ud835\udf031. Figure 3 shows the top-down view of the robot, which is helpful for formulating the relations.</li> <li>Solve for the value of <code>\ud835\udf036</code>, given \ud835\udf031 and the desired yaw angle (should be converted to radian from the input degree value). \ud835\udf036 = 0 when Link 9 is parallel to Link 4 and Link 6.</li> <li>We will define another virtual point. A projected end point (\ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51) is a point off the UR3 but lies along the Link 6 axis, as shown in Figure 1 and Figure 3. For example, if \ud835\udf031 = 0 then \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51 = 0. If \ud835\udf031 = 90\u00b0 then \ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51 = 0. Use the top-down view (Figure 3) to find \ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51 and \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51 from \ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b. Figure 4 is a side view that is a projection of the robot onto a plane perpendicular to the x-y plane of world frame and rotated by \ud835\udf031 about the base frame. From this figure we can see that \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51 is \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b offset by a constant. The end of the gripper is 0.052m from the center of the gripper plate in the z-axis direction.</li> </ol> <p></p> <p></p> <ol> <li>Find \ud835\udf032, \ud835\udf033 and \ud835\udf034 from the end point (\ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51). In Figure 4, a parallel to the base construction line through Joint 2 and a parallel to the base construction line through Joint 4 are helpful in finding the needed partial angles. \ud835\udf032 and \ud835\udf033 can be found from the geometry, while \ud835\udf034 is determined due to the requirement that Link 7 and Link 9 must be parallel to the x-y plane of the world frame.</li> </ol> <p>Now that your code solves for all the joint variables <code>(\ud835\udf031 to \ud835\udf036)</code>, send these six values to the publisher you created in FK lab to move the robot to those angles so that it gets to the desired position.</p>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#implementation-in-ros2-gazebo","title":"Implementation in ROS2 &amp; Gazebo","text":"<ol> <li>Pull the latest commit for ur3e_enme480 package</li> </ol> <pre><code>cd ~/&lt;your_workspace&gt;/src/ur3e_enme480\ngit pull\n</code></pre> <ol> <li>Download the URDF <code>enme480_ik.xacro</code> (from <code>Code Resources</code> in Week 7 on this page) in your <code>urdf</code> folder. Replace <code>ur.urdf.xacro</code> as well.</li> </ol> <p>Add the <code>UR3SuctionCupMount.stl</code> from <code>Code Resources</code> to your <code>Universal_Robots_ROS2_Description//meshes/ur3/visual/</code> folder.</p> <ol> <li>Create a publisher <code>ur3e_ik_sim.py</code> with node name <code>ur3e_sim_ik_publisher</code>. It will have a structure somewhat like this:</li> </ol> <pre><code>import ....\n\nclass InverseKinematicsUR3e(...)\n\n  def __init__(self): \n    ...\n    ...\n    self.publisher_ = self.create_publisher(CommandUR3e, '/ur3/command', 10)\n    ...\n    ...\n\n  def move_robot(...):\n    ...\n    ...\n\n  def calculate_fk_from_dh(...):\n    ...\n    ...\n\n  def inverse_kinematics(self, xWgrip, yWgrip, zWgrip, yawWgrip):\n\n    # TODO: Function that calculates an elbow up \n    # inverse kinematics solution for the UR3\n\n    # Step 1: find gripper position relative to the base of UR3,\n    # and set theta_5 equal to -pi/2\n\n\n    # Step 2: find x_cen, y_cen, z_cen\n\n\n    # Step 3: find theta_1\n\n\n    # Step 4: find theta_6 \n\n\n    # Step 5: find x3_end, y3_end, z3_end\n\n\n    # Step 6: find theta_2, theta_3, theta_4\n\n    # Return the set of joint angles to move the robot\n\n\ndef main(...):\n\n  ...\n  ...\n\nif __name__ == '__main__':\n  main()\n</code></pre> <p>You command should look like this:</p> <pre><code>ros2 run &lt;package_name&gt; ur3e_sim_ik_publisher &lt;x&gt; &lt;y&gt; &lt;z&gt; &lt;Yaw&gt;\n</code></pre>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#test-cases","title":"Test Cases","text":"Test Point Inputs (x, y, z, yaw) IK solution (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) Output from <code>/ur3/position</code> (0.2, 0.3, 0.3, 45) (0.1, 0.4, 0.1, 90) (0.2, 0.2, 0.2, 0) (0.2, -0.2, 0.1, 0) (0.2, 0.3, 0.4, 30) ## Submission <ol> <li>A pdf of your code complete with comments describing the steps you've taken</li> <li>A pdf containing a (neatly) written/typed solution for IK showing how you derived your equations from the geometry</li> <li>Screenshots of UR3e in Gazebo for all test cases</li> <li>A comparison of error between your IK script and the output of the <code>ur3/position</code> topic for the test cases with a discussion of possible error sources.</li> <li>A brief discussion of any possible singularities in the math and what could be done to avoid them (you don't need to implement this, we just want you thinking about strategies!)</li> </ol>"},{"location":"blog/","title":"Announcements","text":"<p>Course updates will appear here (and on Canvas/Piazza). Create new posts by adding dated Markdown files to <code>docs/blog/</code>.</p>"},{"location":"blog/2025-09-01-welcome/","title":"Welcome to ENME480 (FA 2025)","text":"<p>Check the Schedule for weekly topics and labs. The Labs section links to the code submodule. Good luck &amp; have fun!</p>"},{"location":"labs/","title":"\ud83e\uddea Labs Overview","text":"**Your hands-on journey into robotics starts here!**  *Weekly labs combine programming, simulation, and real robot programming*"},{"location":"labs/#lab-structure","title":"\ud83c\udfaf Lab Structure","text":""},{"location":"labs/#two-types-of-sessions","title":"Two Types of Sessions","text":"<ul> <li>\ud83e\uddea Programming Studios (KEB 2111) - Software, simulation, theory</li> <li>\ud83e\udd16 Robot Labs (EAF 3119) - Real robot programming and testing</li> </ul>"},{"location":"labs/#weekly-schedule","title":"Weekly Schedule","text":"<ul> <li>Alternating format - Programming one week, robot work the next</li> <li>Group-based - Work with classmates to solve problems</li> <li>Progressive difficulty - Skills build week by week</li> </ul>"},{"location":"labs/#lab-progression","title":"\ud83d\udcc5 Lab Progression","text":"Week Focus Type Location Key Skills Week 1 Course Intro &amp; Setup Setup KEB 2111 Environment, safety Week 2 Ubuntu &amp; Python Programming KEB 2111 Linux, Python basics Week 3 ROS Introduction Programming KEB 2111 ROS fundamentals Week 4 Gazebo &amp; Python Programming KEB 2111 Simulation, matrices Week 5 UR3e Robot Intro Robot EAF 3119 Robot operation Week 6 Forward Kinematics Programming KEB 2111 DH parameters, FK Week 7 No Lab - - Catch up week Week 8 Inverse Kinematics Programming KEB 2111 IK algorithms Week 9 No Lab - - Catch up week Week 10 FK Lab Robot EAF 3119 Real robot FK Week 11 IK Lab Robot EAF 3119 Real robot IK Week 12-15 Final Project Both Both Vision-enabled pick &amp; place"},{"location":"labs/#getting-started-with-labs","title":"\ud83d\ude80 Getting Started with Labs","text":""},{"location":"labs/#before-your-first-lab","title":"Before Your First Lab","text":"<ol> <li>\u2705 Complete safety training (required for robot access)</li> <li>\ud83d\udcbb Set up Ubuntu environment on your laptop</li> <li>\ud83d\udc0d Install Python and basic packages</li> <li>\ud83d\udcda Read pre-lab materials for the week</li> <li>\ud83d\udd27 Bring laptop with required software</li> </ol>"},{"location":"labs/#what-to-expect-each-week","title":"What to Expect Each Week","text":"<ul> <li>Pre-lab reading - understand concepts before arriving</li> <li>In-lab exercises - hands-on problem solving</li> <li>Group collaboration - work with classmates</li> <li>TA support - help available during lab time</li> <li>Post-lab work - complete any unfinished exercises</li> </ul>"},{"location":"labs/#lab-locations","title":"\ud83c\udfe2 Lab Locations","text":""},{"location":"labs/#keb-2111-programming-studio","title":"KEB 2111 - Programming Studio","text":"<ul> <li>Building: KEB (Kim Engineering Building)</li> <li>Room: 2111</li> <li>Equipment: Computers, software, simulation tools</li> <li>Activities: Programming, theory, simulation</li> </ul>"},{"location":"labs/#eaf-3119-robot-lab","title":"EAF 3119 - Robot Lab","text":"<ul> <li>Building: EAF (Engineering Annex F)</li> <li>Room: 3119</li> <li>Equipment: UR3e robots, safety equipment, tools</li> <li>Activities: Real robot programming, testing</li> </ul>"},{"location":"labs/#lab-requirements","title":"\ud83d\udccb Lab Requirements","text":""},{"location":"labs/#equipment-needed","title":"Equipment Needed","text":"<ul> <li>Laptop with Ubuntu installed</li> <li>USB drive for Ubuntu boot (if needed)</li> <li>Safety gear (provided in robot lab)</li> <li>Notebook for taking notes</li> </ul>"},{"location":"labs/#software-requirements","title":"Software Requirements","text":"<ul> <li>Ubuntu 20.04 or later</li> <li>Python 3.8+ with key packages</li> <li>ROS Noetic (Robot Operating System)</li> <li>Gazebo simulation environment</li> <li>Git for version control</li> </ul>"},{"location":"labs/#lab-learning-objectives","title":"\ud83c\udf93 Lab Learning Objectives","text":""},{"location":"labs/#technical-skills","title":"Technical Skills","text":"<ul> <li>Programming: Python, ROS, simulation</li> <li>Robotics: Kinematics, control, planning</li> <li>Simulation: Gazebo, virtual testing</li> <li>Hardware: Robot operation, safety</li> </ul>"},{"location":"labs/#professional-skills","title":"Professional Skills","text":"<ul> <li>Problem solving - tackle complex robotics challenges</li> <li>Collaboration - work effectively in teams</li> <li>Documentation - record your work and findings</li> <li>Time management - complete labs efficiently</li> </ul>"},{"location":"labs/#lab-materials","title":"\ud83d\udcda Lab Materials","text":""},{"location":"labs/#where-to-find-materials","title":"Where to Find Materials","text":"<ul> <li>This website - weekly lab pages with instructions</li> <li>Lab-Code repository - all code, files, and resources</li> <li>Canvas - assignments, due dates, submissions</li> <li>Piazza - discussions, questions, clarifications</li> </ul>"},{"location":"labs/#lab-code-organization","title":"Lab Code Organization","text":"<pre><code>labs/Lab-Code/\n\u251c\u2500\u2500 Week 1 Materials/          # Course intro\n\u251c\u2500\u2500 Week 2 - Ubuntu &amp; Python/  # Environment setup\n\u251c\u2500\u2500 Week 3 - ROS/              # ROS introduction\n\u251c\u2500\u2500 Week 4 - Gazebo &amp; Python/  # Simulation basics\n\u251c\u2500\u2500 Week 5 - UR3e Intro/       # Robot operation\n\u251c\u2500\u2500 Week 6 - Forward Kinematics/ # FK concepts\n\u251c\u2500\u2500 Week 8 - Inverse Kinematics/ # IK algorithms\n\u251c\u2500\u2500 Week 10 - Forward Kinematics Lab/ # Real robot FK\n\u251c\u2500\u2500 Week 11 - Inverse Kinematics Lab/ # Real robot IK\n\u2514\u2500\u2500 Final Project/              # End-of-semester project\n</code></pre>"},{"location":"labs/#lab-support","title":"\ud83c\udd98 Lab Support","text":""},{"location":"labs/#during-lab","title":"During Lab","text":"<ul> <li>Teaching Assistant - available for technical help</li> <li>Instructor - available for concept questions</li> <li>Peers - collaborate with classmates</li> <li>Documentation - use provided resources</li> </ul>"},{"location":"labs/#outside-lab-hours","title":"Outside Lab Hours","text":"<ul> <li>Office hours - get help from TA or instructor</li> <li>Piazza - ask questions and help others</li> <li>Course website - review materials and instructions</li> <li>Lab-Code repository - access all materials anytime</li> </ul>"},{"location":"labs/#lab-success-tips","title":"\ud83c\udfc6 Lab Success Tips","text":""},{"location":"labs/#before-lab","title":"Before Lab","text":"<ul> <li>Read materials thoroughly</li> <li>Set up environment at home first</li> <li>Prepare questions you want to ask</li> <li>Arrive early to get settled</li> </ul>"},{"location":"labs/#during-lab_1","title":"During Lab","text":"<ul> <li>Start early - don't wait for others</li> <li>Ask questions when you're stuck</li> <li>Help classmates - teaching reinforces learning</li> <li>Document everything - notes help with post-lab work</li> </ul>"},{"location":"labs/#after-lab","title":"After Lab","text":"<ul> <li>Complete exercises you didn't finish</li> <li>Review concepts that were unclear</li> <li>Prepare for next week - stay ahead</li> <li>Submit deliverables on time</li> </ul>"},{"location":"labs/#quick-navigation","title":"\ud83d\udd17 Quick Navigation","text":"**Ready to start building robots? Choose your week below! \ud83d\ude80**  [\ud83d\udccb Week 1 - Intro](week-01.md){ .md-button .md-button--primary } [\ud83d\udc27 Week 2 - Setup](week-02.md){ .md-button } [\ud83d\udd27 Week 3 - ROS](week-03.md){ .md-button } [\ud83c\udfae Week 4 - Gazebo](week-04.md){ .md-button } [\ud83e\udd16 Week 5 - Robot](week-05.md){ .md-button }   <p>Last updated: Fall 2025 \u2022 Back to Home</p>"},{"location":"labs/#current-week","title":"Current Week","text":"<ul> <li>Week 1 - Course Introduction</li> <li>Week 2 - Ubuntu &amp; Python</li> <li>Week 3 - ROS Basics</li> </ul>"},{"location":"labs/#key-resources","title":"Key Resources","text":"<ul> <li>Safety Guidelines</li> <li>Lab Policies</li> <li>Help &amp; Support</li> <li>Course Schedule</li> </ul>"},{"location":"labs/final-project/","title":"Final Project \u2014 Vision-Enabled Pick &amp; Place","text":"<p>Build a pipeline to detect blocks on a table, move UR3e to them, grasp, and stack into a tower. Team-based; submit write-up + demo video.</p> <ul> <li>\ud83d\udcc1 Repo folder: <code>labs/Lab-Code/Final Project/</code></li> </ul>"},{"location":"labs/final-project/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/final-project/#enme480-final-project-pick-and-place-task-using-ur3e","title":"ENME480 Final Project - Pick and Place Task using UR3e","text":""},{"location":"labs/final-project/#objective","title":"Objective","text":"<p>The objective of this project is to control the UR3e to move (at least) three AR-tagged blocks to desired positions using camera image as inputs. We will use OpenCV for processing the image data. The program will also integrate the functions of previous lab assignments. The major objectives are the following - Use OpenCV functions to find the centroid of each block - Convert the pixel coordinates in an image to coordinates in the world frame using a perspective matrix - Move the blocks from the detected positions to predefined desired positions</p>"},{"location":"labs/final-project/#task-description","title":"Task Description","text":"<p>The lab environment is shown below:</p> <p></p> <p>You will be given 3 blocks with different Aruco markers. Your task is to move them out of the workspace into predefined positions. To do so, you will need to find the centroid postion of the top side of each block with an image from the camera mounted above the table, facing down on the workspace. You will convert the detected pixel coordinates to the table frame using a persepctive transform. Then using your inverse kinematics solution, you will pick up the block using a suction gripper mounted at the end effector. Your task is to place each block at a specific location outside the workspace.</p>"},{"location":"labs/final-project/#overview-of-the-ros-package","title":"Overview of the ROS Package","text":"<p>The project package should be located on the local lab machines in RAL. You can also find the package with redacted scripts here: https://github.com/ENME480/enme480_project.</p> <p>The nodes have been added to the <code>setup.py</code> file, so you do not need to add that. You will find five scripts as listed in the table below:</p> Script Name Description <code>get_perspective_warping_with_aruco.py</code> Script to create the perspective matrix <code>aruco_detection_test.py</code> Script to test the perspective transform and get coordinates of the blocks in table frame <code>block_detection_aruco.py</code> ROS Node for detecting blocks, uses the same function and changes from <code>aruco_detection_test.py</code> <code>kinematic_functions.py</code> Script to insert all of your FK and IK functions from previous labs <code>main_pipeline.py</code> The main pipeline to strategize and sequence movement of the blocks <p>Please do not edit anything outside the given code snippets (it will lead to errors which will be difficult to identify)</p>"},{"location":"labs/final-project/#procedure-for-setup-in-ral","title":"Procedure for Setup in RAL","text":"<p>Please follow the following steps before you start editing the scripts on RAL machines</p> <ol> <li> <p>UR3e Setup</p> <ul> <li>Power on the robot</li> <li>Release the brakes</li> </ul> </li> <li> <p>Restore the package to original form and pull the latest version</p> </li> </ol> <pre><code>cd rosPackages/ENME480_ws/src/enme480_project\ngit checkout .\ngit pull\n</code></pre> <ol> <li>Interfacing the Robot with PC</li> </ol> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS</li> </ul>"},{"location":"labs/final-project/#script-descriptions","title":"Script Descriptions","text":"<p>You are recommended to complete each script in the order suggested in the table. </p>"},{"location":"labs/final-project/#get_perspective_warping_with_arucopy","title":"<code>get_perspective_warping_with_aruco.py</code>","text":"<p>This script will generate a perspective matrix for the camera to table frame. You need to edit one line to input the reference points on the table. Ensure that you are entering the values in <code>mm</code>. This script will generate a <code>perspective_matrix.npy</code> file in the folder.</p> <p>Before you run this script, ensure that you are in the correct directory. Assuming you have already entered the docker container, run</p> <pre><code>cd ENME480_ws/src/enme480_project/enme480_project/\npython3 get_perspective_warping_with_aruco.py\n</code></pre>"},{"location":"labs/final-project/#troubleshooting","title":"Troubleshooting:","text":"<p>If you get a missing keyboard package error run the following command</p> <pre><code>pip install keyboard\n</code></pre> <p>Once run, you will see a window with the live camera feed. Click on the reference points in the same order that you have listed in your script. It will calulate the perspective transform and a new window will pop-up showing a blue dot at <code>(175,175)</code> on the table coordinate frame. If this is right, you can proceed to the next script.</p>"},{"location":"labs/final-project/#aruco_detection_testpy","title":"<code>aruco_detection_test.py</code>","text":"<p>This script will give you a live detection of the aruco markers and their location w.r.t the table frame in real-time. You need to modify the <code>image_frame_to_table_frame()</code> function in the script. Use the math from prespective transforms to do the same. You can find a file discussing perspective transforms in the main folder on this repository.</p>"},{"location":"labs/final-project/#block_detection_arucopy","title":"<code>block_detection_aruco.py</code>","text":"<p>This is the ROS node and a Python class for all the functions in the <code>aruco_detection_test.py</code> script. If your <code>aruco_detection_test.py</code> could detect the block coordinates correctly, please copy the same function to the snippet for <code>image_frame_to_table_frame()</code> function in this script as well.</p> <p>You can test this script by running the following commands:</p> <ul> <li>In a new terminal in the docker container, launch the camera node:</li> </ul> <pre><code>ros2 launch usb_cam camera.launch.py\n</code></pre>"},{"location":"labs/final-project/#troubleshooting_1","title":"Troubleshooting:","text":"<p>If you get a Pydantic error run the following command</p> <pre><code>sudo pip install pydantic==1.10.9\n</code></pre> <p>Once the camera node is up and running, run the following command in a seperate terminal:</p> <pre><code>ros2 run enme480_project aruco_tracker\n</code></pre> <p>It will publish data under two topics <code>/aruco_detection/image</code> and <code>/aruco_detection/positions</code></p> <p>You can view the image using </p> <pre><code>ros2 run rqt_image_view rqt_image_view\n</code></pre> <p>and it should show the same image in the window as the one you saw with <code>aruco_detection_test.py</code>, once you select the topic.</p>"},{"location":"labs/final-project/#kinematic_functionspy","title":"<code>kinematic_functions.py</code>","text":"<p>This script will use your functions from previous labs and if you have the script working correctly for your FK and IK labs, you can copy the exact same functions here under the functions <code>calculate_dh_transform()</code> and <code>inverse_kinematics()</code> within the given snippets. We need to verify if your IK script is working correctly so please call the TAs over top show your final IK code working before you copy this.</p>"},{"location":"labs/final-project/#main_pipelinepy","title":"<code>main_pipeline.py</code>","text":"<p>This script is where you will sequence and startegize the pick and place process. In this script, you have to edit the following functions:</p> <ol> <li> <p><code>move_arm()</code></p> <p>This function will take in the desired joint positions and publish them using the message data structure given in code comments</p> </li> <li> <p><code>gripper_control()</code></p> <p>This function will take in the desired state of the gripper and publish it using the message data structure given in code comments</p> </li> <li> <p><code>move_block()</code></p> <p>Here, you need to work on giving the sequence of positions you want the block to move to for moving a block from an initial position to a final position. Keep in mind that every block needs to be picked up, raised up and then moved. Do not give it a sequence to drag it accross the table.</p> </li> <li> <p><code>process_blocks()</code></p> <p>This function is where you will enter the startegy and sorting method to place the blocks in their desired positions given their IDs, pre-defined destinations.</p> </li> </ol> <p>Once everything is ready, call the TAs over before you execute the node</p> <pre><code>ros2 run enme480_project main_pipeline\n</code></pre>"},{"location":"labs/final-project/#submission-requirements","title":"Submission Requirements","text":"<p>One single PDF containing the following:</p> <ul> <li>Pseudo code for detecting and moving the block  (no specific format to be followed)</li> <li>Math for camera frame to table frame (your intuition behind the perspective warping, and transformation from camera frame to image frame)</li> <li>Video of pick and place task on UR3e (as a link (GDrive/YouTube) in the report)</li> <li>Extra Credit: Stacking (3.33 pts per block) - Max 10pts possible </li> </ul>"},{"location":"labs/week-01/","title":"Week 01 \u2014 Lab Intro","text":"<p>Focus: course/lab onboarding, environments, safety overview, space orientation (KEB 2111 &amp; EAF 3119).</p> <p>Location: KEB 2111</p> <p>\u2705 Deliverables:</p> <ul> <li>Confirm environment + accounts</li> <li>Complete safety training checkpoint (details in Canvas/Piazza)</li> <li>Lab Survey</li> </ul>"},{"location":"labs/week-02/","title":"Week 02 \u2014 RAL Intro &amp; Setup / Ubuntu + Python Intro","text":""},{"location":"labs/week-02/#week-2-software-setup","title":"Week 2 - Software Setup","text":""},{"location":"labs/week-02/#overview","title":"Overview:","text":"<p>This lab will walk you through installing and configuring and testing the sofftware we will need for this class.</p>"},{"location":"labs/week-02/#slides","title":"Slides:","text":"<p>Lab 2 Slides</p>"},{"location":"labs/week-02/#goals","title":"Goals:","text":"<p>In this lab, we will follow the pages on the wiki to: - Install Ubuntu - Set up the ROS2 MRC Docker Image - Set up an IDE to work with the Docker Image</p>"},{"location":"labs/week-02/#relevant-wiki-pages","title":"Relevant Wiki Pages:","text":"<p>Software Setup</p> <p>Dev Environmnet Information</p>"},{"location":"labs/week-02/#next-steps","title":"Next Steps:","text":""},{"location":"labs/week-02/#additional-resources","title":"Additional Resources:","text":"<p>Piazza</p>"},{"location":"labs/week-03/","title":"Week 3 \u00b7 ROS 2 (Humble) with Python","text":"<p>This week you\u2019ll learn how ROS 2 is organized and practice the core ideas you\u2019ll use all semester: workspaces, packages, publish/subscribe, and a tiny sim (turtlesim). The steps below point you to the official Humble tutorials\u2014follow them carefully.</p>"},{"location":"labs/week-03/#part-a-setup","title":"Part A - Setup","text":"<p>First, we'll show you how to make shortcut commands to launch your Docker image. The commands you need to run will vary depending on wether or not you are using the Nvidia container.</p> <p>For people not using the Nvidia container, run: <pre><code>echo -e \"#\"'!'\"/bin/bash\\nexport userid=$(id -u) groupid=$(id -g)\\ncd ~/ENME480_mrc/docker\\ndocker compose -f humble-enme480_ur3e-compose.yml run --rm enme480_ur3e-docker\" &gt; startDocker.sh\n\necho -e \"#\"'!'\"/bin/bash\\ncontainer=\"'$(docker ps | grep docker-enme480_ur3e-docker-run | cut -b 1-12)'\"\\necho Found running container \"'$container'\". Connecting...\\ndocker exec -ti \"'$container'\" bash\" &gt; connectToDocker.sh\n</code></pre></p> <p>For people who are using the Nvidia container, run: <pre><code>echo -e \"#\"'!'\"/bin/bash\\nexport userid=$(id -u) groupid=$(id -g)\\ncd ~/ENME480_mrc/docker\\ndocker compose -f humble-enme480_ur3e-nvidia-compose.yml run --rm enme480_ur3e-docker\" &gt; startDocker.sh\n\necho -e \"#\"'!'\"/bin/bash\\ncontainer=\"'$(docker ps | grep docker-enme480_ur3e-docker-run | cut -b 1-12)'\"\\necho Found running container \"'$container'\". Connecting...\\ndocker exec -ti \"'$container'\" bash\" &gt; connectToDocker.sh\n</code></pre></p> <p>These commands will create two bash files (essentially just lists of other commands) that will allow you to launch the Docker container with: <pre><code>bash startDocker.sh\n</code></pre></p> <p>And connect to it from another terminal with: <pre><code>bash connectToDocker.sh\n</code></pre> Provided you are in the folder where these files are.</p> <p>IMPORTANT: This the following folders will be linked (outside the docker --&gt; inside the docker)</p> <p><pre><code>ENME480_mrc/src --&gt; enme480_ws/src\nENME480_mrc/config --&gt; enme480_ws/config\n</code></pre> This is where you should place any files you want to keep when the docker shuts down (i.e. assignment code). Any changes made to files in these folders in the docker will be reflected outside the docker and vice versa. (Credit to Benjamin Ruby for the original version of the script)</p>"},{"location":"labs/week-03/#part-b-pre-flight-check-510-min","title":"\ud83d\udeeb Part B \u2014 Pre-flight check (5\u201310 min)","text":"<p>1) Using the commands from above, open your Docker image contianing ROS 2) Open a new terminal and verify ROS 2 is available (e.g., <code>ros2 --version</code> or <code>ros2 --help</code>). <pre><code>ros2 topic list\n</code></pre> It will show you a list of topics, most likely <code>/rosout</code> and <code>/parameter_events</code></p> <p>3) Try opening up Gazebo <pre><code>ign gazebo\n</code></pre> It should open up a window with examples to different test environments</p> <p>4) Try opening up <code>rqt</code> <pre><code>rqt\n</code></pre> If <code>rqt</code> does not open up anything or throws an error, install any required extenstions <pre><code>sudo apt install ros-humble-rqt*\n</code></pre> or try reopening it with  <pre><code>rqt --force-discover\n</code></pre></p>"},{"location":"labs/week-03/#troubleshooting","title":"Troubleshooting","text":"<p>During any of these steps if your display doesn't open up, follow the follwoing steps</p> <p>Checkpoint B (no submission yet): You can run the above commands without any errors.</p>"},{"location":"labs/week-03/#part-c-workspace-package-setup-only","title":"\ud83d\udce6 Part C \u2014 Workspace &amp; package (setup only)","text":"<p>Follow the official Humble tutorials step-by-step (do not copy solution code from elsewhere):</p> <p>1) Create a workspace: Use the Create a workspace guide and build once so the structure is valid.    \u21aa Guide: docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-A-Workspace/Creating-A-Workspace.html</p> <p>2) Create a Python package: Inside your <code>src/</code>, make a new package for this week (any sensible name, e.g., <code>week3</code>).    \u21aa Guide: docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html</p> <p>Checkpoint C: Your workspace builds with <code>colcon</code> and your package appears in the build output.</p>"},{"location":"labs/week-03/#part-d-talker-listener","title":"\ud83d\udce1 Part D \u2014 Talker / Listener","text":"<p>Use the publisher/subscriber (Python) tutorial as your primary reference:</p> <ul> <li>Tutorial: docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html</li> </ul> <p>Task C1 \u2014 Publisher (\u201ctalker\u201d) Create a node that publishes numbers at a steady rate on a topic you choose (e.g., <code>/numbers</code>). (Use the tutorial to recall how to create a publisher node; adapt it to publish numbers rather than strings.)</p> <p>Task C2 \u2014 Subscriber (\u201clistener\u201d) Create a node that subscribes to your numbers topic and maintains a cumulative sum. After each new message arrives, it should publish the running sum on a new topic (e.g., <code>/sum_topic</code>). (Re-use the subscriber pattern from the tutorial; add your own sum logic and a second publisher.)</p> <p>Task C3 \u2014 Inspect with CLI Use the Understanding topics tutorial to: list topics, echo your sum topic, and show topic info (type, publishers/subscribers). \u21aa docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html</p> <p>Hints (conceptual, not solutions): - Topic names must match exactly; message types must be consistent. - If a terminal shows \u201cno publisher/subscriber\u201d, confirm both nodes are running and your workspace is sourced. - Keep node/topic names short and meaningful.</p> <p>Checkpoint D \u2014 Screenshots to capture: - Talker output (brief). - Listener output showing a running sum. - <code>ros2 topic list</code> and a short <code>ros2 topic echo</code> of your sum topic.</p>"},{"location":"labs/week-03/#part-e-turtlesim-drive-in-a-circle","title":"\ud83d\udc22 Part E \u2014 Turtlesim (drive in a circle)","text":"<p>Read the turtlesim, ros2, and rqt tutorial first: docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Introducing-Turtlesim/Introducing-Turtlesim.html</p> <p>Task D1 \u2014 Launch turtlesim Start the turtlesim simulator in one terminal (see tutorial).</p> <p>Task D2 \u2014 Velocity publisher In your package, create a node that publishes velocity commands to turtlesim so the turtle moves in a circle (non-zero linear \\(x\\) and angular \\(z\\)). (You\u2019ll find the correct topic name in the tutorial; use the CLI to explore message fields.)</p> <p>Task D3 \u2014 Observe &amp; Inspect Use <code>ros2 topic list</code> / <code>ros2 topic echo</code> to confirm motion and pose updates; open rqt and view the Node Graph and Topic Monitor. - rqt info: docs.ros.org/en/humble/Concepts/Intermediate/About-RQt.html</p> <p>Checkpoint E \u2014 Screenshots to capture: - Turtlesim window with a clear circular path. - Your velocity publisher terminal (brief output). - <code>ros2 topic list</code> and a short <code>ros2 topic echo</code> of the pose topic. - rqt with Node Graph / Topic Monitor visible.</p>"},{"location":"labs/week-03/#what-were-assessing","title":"\ud83d\udd0e What we\u2019re assessing","text":"<ul> <li>You can follow official Humble docs and adapt examples to a new task.  </li> <li>Your nodes publish/subscribe correctly and use appropriate topic names and message types.  </li> <li>You can inspect systems via CLI and rqt and explain what you see.</li> </ul>"},{"location":"labs/week-03/#deliverables-single-pdf-upload","title":"\ud83d\udce4 Deliverables (single PDF upload)","text":"<p>Include concise screenshots (one image may show multiple windows):</p> <ul> <li>Talker/Listener: talker output; listener output showing running sum; <code>ros2 topic list</code>; brief <code>ros2 topic echo</code> of your sum topic.  </li> <li>Turtlesim: turtlesim showing a circle; velocity publisher terminal; <code>ros2 topic list</code>; brief <code>ros2 topic echo</code> of the pose topic; rqt with Node Graph/Topic Monitor visible.  </li> <li>A terminal view of your package tree (folder/files) helps grading.</li> </ul> <p>Also submit the three Python files you created this week as separate attachments or in the PDF appendix (clearly named).</p>"},{"location":"labs/week-03/#helpful-tips-for-the-turtlesim-velocity-publisher","title":"Helpful tips for the turtlesim velocity publisher","text":"<ul> <li>Topic to command motion: <code>/turtle1/cmd_vel</code>. That\u2019s the velocity command topic turtlesim listens to. See the turtlesim tutorial for context. </li> <li>Message type: </li> <li>Make edits to <code>package.xml</code> to include <code>geometry_msgs</code> -<code>geometry_msgs/Twist</code> with two parts: <code>linear</code> and <code>angular</code>, each a 3-D vector (<code>x</code>, <code>y</code>, <code>z</code>). For a planar turtle,   you\u2019ll typically set <code>linear.x</code> and <code>angular.z</code> only (m/s and rad/s). </li> <li>If you\u2019re unsure of fields, ask ROS directly:   ```bash   ros2 interface show geometry_msgs/msg/Twist</li> </ul>"},{"location":"labs/week-04/","title":"Week 04 \u2014 Gazebo Demo (Studio 2)","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 4 - Gazebo &amp; Python/</code></li> </ul>"},{"location":"labs/week-04/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-04/#week-4-studio-41-gazebo-demo","title":"Week 4 - Studio 4.1 - Gazebo Demo","text":"<p>The objective of this lab is to install the UR3e packages and have a working simulation of the robot in Gazebo.</p>"},{"location":"labs/week-04/#package-installation","title":"Package Installation","text":"<p>There are two methods to do this:</p>"},{"location":"labs/week-04/#1-source-installation","title":"1. Source Installation","text":"<p>Clone the following repositories in your workspace:</p> <pre><code>git clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Driver.git\ngit clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation.git\n</code></pre> <p>Build and source the workspace</p>"},{"location":"labs/week-04/#2-pre-configured-docker-container","title":"2. Pre-configured Docker Container","text":"<p>Find the Dockerfile in <code>/Resources/Docker Container/humble_dockerfile.Dockerfile</code> and build and run the container. This is the preferred method but it can lead to issues with Gazebo (looking into a foolproof solution - will be updated this week)</p> <pre><code>sudo docker build -t humble_image -f humble_dockerfile.Dockerfile .\nsudo docker run -it humble_image\n</code></pre>"},{"location":"labs/week-04/#troubleshooting-no-joint-trajcetory-controller-or-controller-interface","title":"Troubleshooting - no joint trajcetory controller or controller interface","text":"<p>If you run into an issue with building packages due to missing a joint controller run:</p> <pre><code>sudo apt install ros-humble-joint-trajectory-controller\n\nsudo apt install ros-humble-controller-interface\n\nsudo apt install ros-humble-ur-*\n\nsudo apt install ros-humble-control-*\n\nsudo apt install ros-humble-ros2-control-*\n</code></pre>"},{"location":"labs/week-04/#troubleshooting-on-macs","title":"Troubleshooting on Macs","text":"<p>Gazebo doesn\u2019t directly support ARM64 architecture. As a result, we need to manually compile and install it.</p> <p>Install necessary dependencies:</p> <pre><code>sudo apt-add-repository ppa:dartsim\n\nsudo apt update\n\nsudo apt install libdart-dev libdart-utils-dev libdart-external-ikfast-dev libsdformat9-dev libfreeimage-dev libprotoc-dev libprotobuf-dev protobuf-compiler freeglut3-dev libcurl4-openssl-dev libtinyxml-dev libtinyxml2-dev libtar-dev libtbb-dev libogre-1.9-dev libxml2-dev pkg-config qtbase5-dev libqwt-qt5-dev libltdl-dev libgts-dev libboost-thread-dev libboost-system-dev libboost-filesystem-dev libboost-program-options-dev libboost-regex-dev libboost-iostreams-dev libsimbody-dev libignition-common3-dev libignition-fuel-tools4-dev libignition-transport8-dev libignition-math6-dev libignition-msgs5-dev\n</code></pre> <ol> <li> <p>Clone the Gazebo source code from GitHub: <pre><code>cd ~/Downloads/\n\ngit clone https://github.com/osrf/gazebo\n</code></pre></p> </li> <li> <p>Modify the line 647 of <code>SearchForStuff.cmake</code> in <code>Downloads/gazebo/cmake</code>. Change from 9.8 to 9.7 as the default libsdformat version of ubuntu22 is 9.7.</p> </li> <li> <p>Compile and install Gazebo:</p> </li> </ol> <pre><code>cd ~/Downloads/gazebo\nmkdir build &amp;&amp; cd build\ncmake ../\nmake -j3\nsudo make install\n</code></pre> <ol> <li>Add Gazebo to your environment path by modifying .bashrc*:</li> </ol> <pre><code>export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\nexport PATH=/usr/local/bin:$PATH\nexport PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH\n</code></pre> <ol> <li>In your workspace, add the <code>gazebo_ros</code> package:</li> </ol> <pre><code>cd ~/enme480_ws/src\ngit clone https://github.com/ros-simulation/gazebo_ros_pkgs\ncd gazebo_ros_pkgs\ngit checkout ros2\ncd ~/enme480_ws/src\ngit clone -b humble https://github.com/ros-controls/gazebo_ros2_control\n</code></pre> <ol> <li>Build and source your workspace</li> </ol>"},{"location":"labs/week-04/#running-ur3-demo-on-gazebo","title":"Running UR3 Demo on Gazebo","text":"<p>Launch the UR3e in Gazebo</p> <pre><code>ros2 launch ur_simulation_gazebo ur_sim_control.launch.py\n</code></pre> <p>It should open up two windows with UR3e arm in Gazebo &amp; RViz. </p>"},{"location":"labs/week-04/#troubleshooting-gazebo-does-not-open-up-waiting-for-controller","title":"Troubleshooting - Gazebo does not open up; waiting for controller","text":"<p>Run the following command in a seperate terminal before launching the previous command (in order to use this method, start and source 3 consoles, run this command, then the one above it then the last command on this page).</p> <pre><code>gazebo -s libgazebo_ros_init.so -s libgazebo_ros_factory.so myworld.world\n</code></pre> <p>To test if the simulation works, run the following command</p> <p><pre><code>ros2 launch ur_robot_driver test_joint_trajectory_controller.launch.py\n</code></pre> This will keep moving the robot continously in multiple positions.</p>"},{"location":"labs/week-04/#assignment","title":"Assignment","text":"<p>Prepare a report answering the following questions and posting relevant screenshots 1. Screenshots of Gazebo &amp; RViz with the UR3 in 3 different positions 2. Show the topics </p>"},{"location":"labs/week-05/","title":"Week 5 - UR3e Intro &amp; Operation","text":""},{"location":"labs/week-05/#objectives","title":"Objectives","text":"<ul> <li>Learn how to use the Pendant</li> <li>Interface UR3e with ROS packages on RAL machines</li> <li>Visualize ROS Processes</li> </ul>"},{"location":"labs/week-05/#files","title":"Files","text":"<p>Data Collection Sheet: pdf, docx</p>"},{"location":"labs/week-05/#procedure","title":"Procedure","text":"<p>First, you will set up the pendant</p> <p>Press the power button, shown here:</p> <p></p> <p>Once the robot is powered on, it will still be in a disarmed state. Press the button shown below to arm it. You should expect to hear a series of loud clicks; this is the brakes releasing. Note that you will need to press the arm button twice; once to power on the robot and once to release the brakes.</p> <p></p> <p>Next, you can try using free drive to control the robot. To do so, press the black button on the back of the teaching pendant. This will allow you to manually move each joint of the robot. Be careful not to do this too quickly otherwise the robot may lock you out.</p> <p></p> <p>The teaching pendant also has an E-Stop button on its face. If the robot ever moves in a way you don't expect, E-Stop it. A stopped robot is better than a hurt classmate or a broken robot. Try pressing it now. In order to release it, you'll need to spin the knob to pop it back up and then re-release the brakes.</p> <p></p>"},{"location":"labs/week-05/#2-connect-the-robot-to-the-computer","title":"2. Connect the Robot to the Computer","text":"<ol> <li>Wake the computer up and log in to the enme480 user using the password ENME480 (all caps).</li> <li> <p>Find the <code>README.md</code> file within the <code>ENME480_mrc</code> folder. You can also open up VS Code from the sidebar and open the <code>ENME480_mrc</code> folder and open the <code>README.md</code> file from there. Do <code>Ctrl + Shift + V</code> to enable a more readable view of the README file. This will contain a list of steps to connect the robot to the computer. You should be dropped into a Docker envrionment similar to the one you've alrady been working in.</p> <p>2.1. For easier readability, you can open the README file in preview mode by clicking the preview button. This will render all the formatting.   </p> </li> <li> <p>Follow the steps as laid out in the file. You'll know it worked when the \"Control by MRC\" script on the robot arm runs succesfully and the computer prints a confirmation message in the terminal. Warning: E-Stopping the robot while it is controlled by the computer will breka the drivers. You need to redo this process if that happens.</p> <p>3.1. The confirmation command should read: \"Robot connected to reverse interface. Redy to receive control commands.\" and will print in the terminal where you are running ur_robot_control driver.   3.2. Be careful not to use the touchpad functions on the pendant once you've launched the driver. If you do, you'll have to relaunch the driver.</p> </li> </ol>"},{"location":"labs/week-05/#3-enabling-the-laser-and-publishing-joint-angles-to-the-robot","title":"3. Enabling the Laser and Publishing Joint Angles to the Robot","text":"<ol> <li>Now we are ready to begin publishing joint angles to the robot. To do this, run the command with angles on your datasheet.</li> </ol> <pre><code>ros2 topic pub --once /ur3/command ur3e_mrc/msg/CommandUR3e \"destination: [tht1, tht2, tht3, tht4, tht5, tht6] \nv: 1.0 \na: 1.0 \nio_0: false\"\n</code></pre> <p>This message contains a few parts: - \"ros2 topic pub --once\" will publish a message on a certain topic once, then stop (instead of endlessly republishing the same message). - We are publishing on the topic \"ur3/command\" with a message type \"ur3e_mrc/msg/CommandUR3e\" - The \"ur3e_mrc/msg/CommandUR3e\" message has four fields:</p> <ul> <li>\"destination\": a set of 6 angles, one per joint. These angles are in RADIANS! Sanity check any angle you're putting in before hitting enter - an angle of +/-90 probably doesn't make sense here, for example.</li> <li> <p>\"v\" and \"a\": these control the velocity and acceleration of the robots joints, respectively. There are internal afeties set to prevent the robot from moving too fast, but we've also explicitly set the speed here to something low enough that you'll have time to react if the robot moves unexpectedly.</p> </li> <li> <p>\"io_0\": this field will turn the laser pointer off during the motion of the arm. This is to make sure the laser never accidentally shines in someones eyes.</p> </li> <li> <p>The TAs should have attached a laser pointer to your robot. In order to enable the laser pointer run the command:</p> </li> </ul> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre> <p>From within the docker. Your laser should now be on, so make sure the robot only points down towards the table. If your laser still is not on, call a TA.</p> <ol> <li>Check the data sheets we handed out in lab for the angles you need to populate the command. For this lab, you will be measuring the coordinates of where the laser pointer hits the table after each move. Make sure youre using the set of axes defined on the table.</li> </ol>"},{"location":"labs/week-05/#wrap-up-and-shutdown","title":"Wrap Up and Shutdown","text":"<p>Once you are done you can use any time you have left to redo some of what we showed during the prior lab with listing topics and using RQT to see how the robot works under the hood. </p> <p>Before leaving, rehome the robot by going to the \"Move\" screen and clicking the \"Home\" button in the bottom middle of the screen. You will then need to hold down the \"Move to new position\" button until the robot is fully in position, at which point the screen will change to confirm the mvoe is complete. Make sure that you fully shut the robot down and close all temrinals on the computer before you leave!</p>"},{"location":"labs/week-05/#next-steps","title":"Next Steps","text":"<p>In next weeks lab we will show you how to calculate the forward kinematics for our 6 DoF robot usng DH parameters and then how to simulate the Forward Kinematics using Gazebo. The goal of this weeks lab is to get data that you can validate during next weeks lab. If you'd like to get ahead, you can also being working out how to project the laser pointer down onto the table if you given a homogenous transform showing the position and orientation of the pointer.</p>"},{"location":"labs/week-05/#submission","title":"Submission","text":"<p>No submissions for this week. However, make sure you collect the data for this week properly. There will be a joint submission with next week's studio covering the entire forward kinematics assignment.</p> <p>&lt;!-- 2. Interfacing the Robot with PC</p> <p>Now that you've seen the teaching pendant we also want to demonstrate some of the same visualization tools you saw in the prior lab on the real robot. First, log into the ENME480 account on the computers (password ENME480) and locate the commands2run.txt file.  Open the file and follow the instructions within to allow the computer to control the robot. Once this is done, the only control on the pendant which will do anything is the E-Stop button. It is important whenever you are running code that one of your groupmates is holding the pendant and is ready to E-Stop if the robot moves unpredictably. </p> <ol> <li> <p>Visualize ROS Processes on the Physical System</p> </li> <li> <p>Get the list of ROS topics</p> </li> <li>Open up RQT</li> <li>Visualize Node Graphs</li> <li>You will be shown how to generate plots in RQT to analyze data --!&gt;</li> </ol>"},{"location":"labs/week-06/","title":"Week 06 \u2014 Forward Kinematics Lab 1.2","text":""},{"location":"labs/week-06/#objectives","title":"Objectives","text":"<ul> <li>Implement a ROS 2 publisher node (Python/rclpy) to command a UR3e in Gazebo.</li> <li>Derive the Forward Kinematics for the UR3e using DH Transformations</li> <li>Validate FK numerically against the simulator\u2019s reported pose and reason about modeling error sources. Compare against the values obtained from last week's lab </li> </ul>"},{"location":"labs/week-06/#useful-files","title":"Useful Files","text":"<ul> <li>UR3e Dimensions</li> <li>UR3e Zero Position</li> </ul>"},{"location":"labs/week-06/#procedure","title":"Procedure","text":""},{"location":"labs/week-06/#step-1-pull-the-latest-version-of-the-repo","title":"Step 1: Pull the latest version of the Repo","text":"<p>The repository and docker files has been updated to include the updated simulation tools so you'll need to build the docker environment again</p> <p>Before doing that take a backup of your current <code>/src</code> folder so that you don't accidentally lose access to your previous work.</p> <pre><code>cd\nmkdir -p backup/week5\ncp -r ~/ENME480_mrc/src/ ~/backup/week5\n</code></pre> <p>Next, we pull the latest version of the repository</p> <pre><code>cd ~/ENME480_mrc\ngit checkout .\ngit pull\n</code></pre> <p>Next, we add a helper package to the repository:</p> <pre><code>cd ~/ENME480_mrc/src\ngit clone https://github.com/ENME480/ur3e_enme480.git\n</code></pre>"},{"location":"labs/week-06/#step-2-build-and-run-docker","title":"Step 2: Build and run docker","text":"<p>For MacOS/VM users, change Line no. 4 in the docker file <code>humble-enme480_ur3e.Dockerfile</code> at <code>~/ENME480_mrc/docker</code></p> <pre><code># BEFORE\nFROM osrf/ros:humble-desktop AS humble-mod_desktop\n\n# AFTER\nFROM arm64v8/ros:humble AS humble-mod_desktop\n</code></pre> <p>Do not do this on anything other than a MAC! MACs require code that has been compiled in a special way in order to work and this code does not work on other computers!</p> <p>For Everyone, run</p> <pre><code>cd ~/ENME480_mrc/docker/\nuserid=$(id -u) groupid=$(id -g) docker compose -f humble-enme480_ur3e-compose.yml build\n</code></pre> <p>Create the <code>startDocker.sh</code> and <code>connectToDocker.sh</code> scripts again if you haven't yet</p> <p>For people not using the Nvidia container, run: <pre><code>cd\n\necho -e \"#\"'!'\"/bin/bash\\nexport userid=$(id -u) groupid=$(id -g)\\ncd ~/ENME480_mrc/docker\\ndocker compose -f humble-enme480_ur3e-compose.yml run --rm enme480_ur3e-docker\" &gt; startDocker.sh\n\necho -e \"#\"'!'\"/bin/bash\\ncontainer=\"'$(docker ps | grep docker-enme480_ur3e-docker-run | cut -b 1-12)'\"\\necho Found running container \"'$container'\". Connecting...\\ndocker exec -ti \"'$container'\" bash\" &gt; connectToDocker.sh\n</code></pre></p> <p>For people who are using the Nvidia container, run: <pre><code>cd \n\necho -e \"#\"'!'\"/bin/bash\\nexport userid=$(id -u) groupid=$(id -g)\\ncd ~/ENME480_mrc/docker\\ndocker compose -f humble-enme480_ur3e-nvidia-compose.yml run --rm enme480_ur3e-docker\" &gt; startDocker.sh\n\necho -e \"#\"'!'\"/bin/bash\\ncontainer=\"'$(docker ps | grep docker-enme480_ur3e-docker-run | cut -b 1-12)'\"\\necho Found running container \"'$container'\". Connecting...\\ndocker exec -ti \"'$container'\" bash\" &gt; connectToDocker.sh\n</code></pre></p> <p>To start the docker container, run</p> <pre><code>bash startDocker.sh\n</code></pre> <p>To connect to the same docker container from another terminal, run</p> <pre><code>bash connectToDocker.sh\n</code></pre>"},{"location":"labs/week-06/#step-3-build-the-workspace","title":"Step 3: Build the workspace","text":""},{"location":"labs/week-06/#preliminary-instllations","title":"Preliminary instllations","text":"<pre><code>sudo apt update\nsudo apt install ros-humble-tf-transformations\nsudo apt install ros-humble-rqt*\n</code></pre> <p>Now, we build the workspace for the simulation</p> <p><pre><code>cd ~/enme480_ws\ncolcon build --symlink-install\n</code></pre> <code>--symlink-install</code> speeds Python iteration by avoiding rebuilds for script-only changes.</p> <p>Once done, source it</p> <pre><code>cd ~/enme480_ws\nsource install/setup.bash\n</code></pre>"},{"location":"labs/week-06/#step-4-launch-the-simulation","title":"Step 4: Launch the Simulation","text":"<p>Now we will test if the simulation environment is working</p> <ul> <li>Use <code>tmux</code> to manage multiple panes. Create several panes to work with the Gazebo simulation:</li> <li><code>tmux</code>      # Start a new session</li> <li><code>Ctrl+A b</code>  # Split horizontally</li> <li> <p><code>Ctrl+A v</code>  # Split vertically</p> </li> <li> <p>Terminal/Pane 1: Launch MRC UR3e Gazebo simulation in one of the <code>tmux</code> panes:     <pre><code>ros2 launch enme480_sim enme480_ur3e_sim.launch.py\n</code></pre></p> </li> <li> <p>Terminal/Pane 2: Launch MRC UR3e sim control package in a different <code>tmux</code> pane:     <pre><code>ros2 launch ur3e_mrc_sim ur3e_enme480.launch.py\n</code></pre></p> </li> <li> <p>Terminal/Pane 3: Launch MRC UR3e sim control package in a different <code>tmux</code> pane:     <pre><code>ros2 launch ur3e_enme480 ur3e_sim_enme480.launch.py\n</code></pre></p> </li> <li> <p>Terminal/Pane 4: Example command to move the arm:     <pre><code>ros2 topic pub --once /ur3e/command ur3e_mrc_msgs/msg/CommandUR3e \"destination: [0, -1.57, -1.57, 0, 0, 0]\nv: 1.0\na: 1.0\nio_0: false\" \n</code></pre></p> </li> </ul>"},{"location":"labs/week-06/#step-5-solve-the-ur3e-dh-table","title":"Step 5: Solve the UR3e DH Table","text":"<p>The main point of todays lab is to validate the measurements you took in lab last week. To do this, you will be solving the Forward Kinematics for the UR3e arm. Below, we have included some helpful images to get you started.</p> <p></p> <p>This is the robot in its zero configuration. Your DH Table should correspond to this when you have all free variables set to 0.</p> <p></p> <p>A top down view of the offset for the corner point.</p> <p></p> <p>Tool dimensions.</p> <p></p> <p>This is a schematic showing the lengths of the different links on the robot.</p> <p>Tips:</p> <ul> <li>The physical robots are set up assuming that the z-axis is always pointing out of the blue caps.</li> <li>Remember that you can make fixed DH Frames that don't have any free parameters. Sometimes, a transform may not be doable using the standard DH convention and this is necessary.<ul> <li>A common scenario is that a transform you want to do would require a translation or rotation about a y-axis, which is not allowed with DH parameters. In these cases, you will always end up needing an intermediate fixed frame.</li> <li>An easy sanity check for this is that if a transform leads to the old x becoming the new z or vice versa then you need an intermediate frame.</li> </ul> </li> <li>Each one of the 6 blue caps on the robot is a motor, meaning each one introduces a new free varaible representing the bending in the joint.<ul> <li>This means that, counting the base frame (0) and the end effector frame (E) you should have minimum 8 DH frames.</li> </ul> </li> <li>Your code should be a funciton which takes in a list of angles (free DH parameters) and returns the transform between the base and end effector.</li> <li> <p>To help debug your code, you can use some of the tools we've mentioned in prior labs:</p> <ul> <li>Going to RQT --&gt; Visualization --&gt; TF Tree will show you the list of every frame in the currently active robot.</li> <li>Going to your terminal and running the command </li> </ul> <pre><code>ros2 run tf2_ros tf2_echo SOURCE_FRAME TARGET_FRAME\n</code></pre> <p>will show you the current transform. Note that you will need to replace SOURCE_FRAME and TARGET_FRAME with actual frames from your TF tree! TF2 (the transform library within ROS) lets you skip frames, so you can find the transform between the base and end effector directly, for example. This can be used to debug your coe by printing out your intermediate transforms and verifying them against what tf2 says.  </p> </li> </ul>"},{"location":"labs/week-06/#step-6-create-a-publisher-script-to-move-the-arm","title":"Step 6: Create a publisher script to move the arm","text":"<p>Here, you need to write a publisher script to:</p> <ul> <li>Move the robot (using <code>/ur3e/command</code>)</li> <li>Calculate the end effector position using DH Transformations</li> </ul> <p>You are encouraged to write the entire publisher script on your own, but we have also provided a helper script if needed.</p> <p>The script is located at <code>~/enme480_ws/src/ur3e_enme480/ur3e_enme480/ur3e_fk.py</code>.</p> <p>In the helper script, we have added an approximately correct end effector transformation matrix relative to the table's origin <code>(0,0)</code> for reference. The script also calculates an estimated position where the laser pointer will hit the workbench depending on the DH calculations. </p> <p>Some tips for finishing the script:</p> <ul> <li>Finish the <code>send_command()</code> first with a placeholder matrix for the transformation</li> <li>To finish the <code>send_command()</code> function, the message definition for <code>CommandUR3e.msg</code> is </li> </ul> <pre><code>float64[] destination\nfloat64 v\nfloat64 a\nbool io_0\n</code></pre> <p>Do this similar to the way you wrote the publisher messages for previous weeks</p> <ul> <li>The helper script defines an identity matrix as placeholder to ensure you can test the script first. Make sure that you change this with your final transformation matrix.</li> <li>You can implement a recursve method or do a matrix multiplication of your choosing to calculate the final trnasformation matrix in the code.</li> </ul> <p>It can be launched as follows:</p> <pre><code>ros2 run ur3e_enme480 ur3e_fk &lt;th1&gt; &lt;th2&gt; &lt;th3&gt; &lt;th4&gt; &lt;th5&gt; &lt;th6&gt;\n</code></pre> <p>You should also be able to see the approximate final position of the end-effector fromm the <code>ur3/position</code> topic:</p> <pre><code>ros2 topic echo /ur3e/position \n</code></pre> <p>Since you know the position and orientation of the end effector (attached with a laser pointer), you have to predict where the laser point will land on the workbench. (Hint: Think in terms of vector and plane intersection)</p> <p>Assume the <code>z_table = 0</code>. </p> <p>We are providing you with the code in lab (hidden in the backend), but you need to show the math behind it in your lab report.</p>"},{"location":"labs/week-06/#test-points-same-as-last-week","title":"Test Points (same as last week)","text":"<p>Run the robot for the following test points:</p> Test Point Inputs (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) End Effector Position (Your Code) <code>(x y z)</code> Laser Position on Workbench (from Code) (<code>x,y</code>) Laser Position on Workbench(Measured) <code>(x, y)</code> [0, -0.758, 0, 0.758, -1.571, 1.048] [-0.524, -1.048, 1.396, -0.175, -1.571, -0.524] [0.524, -1.222, 1.396, -0.175, -1.571, 0.175] [-0.524, -1.048, 1.048, -0.175, -1.571, -0.524]"},{"location":"labs/week-06/#deliverablessubmission","title":"Deliverables/Submission","text":""},{"location":"labs/week-06/#report-pdf","title":"Report (PDF)","text":"<ul> <li> <p>Clear frame assignments &amp; axes drawings.</p> </li> <li> <p>DH table with your chosen convention and parameter definitions. </p> </li> <li> <p>Step-by-step derivation for the laser\u2013plane intersection.</p> </li> <li> <p>Error analysis (\u22653 points): quantify FK vs. sim pose (from <code>/ur3e/position</code>) vs. correct DH transform and laser prediction error; discuss atleast 4-5 sources of error</p> </li> <li> <p>Short description of your publisher (design &amp; message format).</p> </li> </ul>"},{"location":"labs/week-06/#code","title":"Code","text":"<ul> <li>The FK function and the publisher function you modified (with comments).</li> </ul>"},{"location":"labs/week-06/#results","title":"Results","text":"<ul> <li> <p>Filled test table (above).</p> </li> <li> <p>Plots or tables comparing predicted vs. measured laser positions.</p> </li> </ul> <p>Feel free to explore tools like <code>rqt</code> to get a deeper understanding of how the nodes are interacting with each other.</p>"},{"location":"labs/week-07/","title":"Week 07 \u2014 Make-up / Office Hours","text":"<p>No scheduled lab; use time for catch-up and TA help.</p>"},{"location":"labs/week-08/","title":"Week 08 \u2014 IK Studio","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 8 - Inverse Kinematics/</code></li> </ul>"},{"location":"labs/week-08/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-08/#week-8-ur3e-inverse-kinematics-on-gazebo","title":"Week 8 - UR3e Inverse Kinematics on Gazebo","text":""},{"location":"labs/week-08/#objectives","title":"Objectives","text":"<p>The objective of this lab is to derive and implement a solution to the inverse kinematics problem for the UR3 robot. In this lab we will:</p> <ul> <li>Derive elbow-up inverse kinematic equations for the UR3</li> <li>Write a publisher that moves the UR3 to a point in space specified by the user</li> </ul>"},{"location":"labs/week-08/#task-description","title":"Task Description","text":"<p>The joints and links of the UR3 robot are annotated in Figure 1. The goal is to find the rotation angles of the 6 joints <code>(\u03b81, ... , \u03b86)</code>, so that the end-effector (end of Link 10) can reach to a given position <code>(x_grip, y_grip, z_grip)</code> and orientation <code>{\u03b8_yaw, \u03b8_pitch, \u03b8_roll}</code> input by the user. There are many possible solutions to the inverse kinematics problem. To make the derivation manageable, we will only implement one of the elbow-up solution in this lab. <code>\u03b8_pitch</code> and <code>\u03b8_roll</code> of the end-effector are fixed by letting the vacuum gripper aluminum plate (Link 9) always be parallel to the x-y plane of world frame coordinates (i.e., desk plane), and \u03b85 is always equal to \u221290\u00b0. Thus, the user will input the desired position and yaw angle of the end-effector in world frame coordinates <code>(xWgrip, yWgrip, zWgrip, yawWgrip)</code>, and the output of the program should be the joint angles <code>\u03b81 to \u03b86</code>.</p> <p></p>"},{"location":"labs/week-08/#solution-steps","title":"Solution Steps","text":"<p>In this section, a suggested solution approach is described.</p> <ol> <li>Establish the world coordinate frame (frame w) centered at the corner of the UR3\u2019s base shown in Figure 2. We will solve the inverse kinematics problem in the base frame (frame 0), so we will convert the coordinates (\ud835\udc65\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d) entered by the user to base frame coordinates (\ud835\udc65\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d). The origin of the base frame is at (-0.15, 0.15, 0.01) in the world frame. Set \ud835\udf035 = \u221290\u00b0 in unit of radian.\"</li> </ol> <p></p> <ol> <li>We will define a \u201cwrist center\u201d as \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b which equals the same desired \ud835\udc67 value of the vacuum gripper, and \ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b are the coordinates of <code>\ud835\udf036</code>\u2019s \ud835\udc67 axis (see Figure 1). Link 9 (gripper plate) has a length of 0.0535 meters from the center line of the gripper to the center line of Joint 6. Given the desired position of the gripper <code>(\ud835\udc65\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d)</code> in the base frame and the yaw angle, find wrist\u2019s center point (\ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b).</li> <li>Given the wrist\u2019s center point (\ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b), find the waist angle \ud835\udf031. Figure 3 shows the top-down view of the robot, which is helpful for formulating the relations.</li> <li>Solve for the value of <code>\ud835\udf036</code>, given \ud835\udf031 and the desired yaw angle (should be converted to radian from the input degree value). \ud835\udf036 = 0 when Link 9 is parallel to Link 4 and Link 6.</li> <li>We will define another virtual point. A projected end point (\ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51) is a point off the UR3 but lies along the Link 6 axis, as shown in Figure 1 and Figure 3. For example, if \ud835\udf031 = 0 then \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51 = 0. If \ud835\udf031 = 90\u00b0 then \ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51 = 0. Use the top-down view (Figure 3) to find \ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51 and \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51 from \ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b. Figure 4 is a side view that is a projection of the robot onto a plane perpendicular to the x-y plane of world frame and rotated by \ud835\udf031 about the base frame. From this figure we can see that \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51 is \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b offset by a constant. The end of the gripper is 0.052m from the center of the gripper plate in the z-axis direction.</li> </ol> <p></p> <p></p> <ol> <li>Find \ud835\udf032, \ud835\udf033 and \ud835\udf034 from the end point (\ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51). In Figure 4, a parallel to the base construction line through Joint 2 and a parallel to the base construction line through Joint 4 are helpful in finding the needed partial angles. \ud835\udf032 and \ud835\udf033 can be found from the geometry, while \ud835\udf034 is determined due to the requirement that Link 7 and Link 9 must be parallel to the x-y plane of the world frame.</li> </ol> <p>Now that your code solves for all the joint variables <code>(\ud835\udf031 to \ud835\udf036)</code>, send these six values to the publisher you created in FK lab to move the robot to those angles so that it gets to the desired position.</p>"},{"location":"labs/week-08/#implementation-in-ros2-gazebo","title":"Implementation in ROS2 &amp; Gazebo","text":"<ol> <li>Pull the latest commit for ur3e_enme480 package</li> </ol> <pre><code>cd ~/&lt;your_workspace&gt;/src/ur3e_enme480\ngit pull\n</code></pre> <ol> <li>Download the URDF <code>enme480_ik.xacro</code> (from <code>Code Resources</code> in Week 7 on this page) in your <code>urdf</code> folder. Replace <code>ur.urdf.xacro</code> as well.</li> </ol> <p>Add the <code>UR3SuctionCupMount.stl</code> from <code>Code Resources</code> to your <code>Universal_Robots_ROS2_Description//meshes/ur3/visual/</code> folder.</p> <ol> <li>Create a publisher <code>ur3e_ik_sim.py</code> with node name <code>ur3e_sim_ik_publisher</code>. It will have a structure somewhat like this:</li> </ol> <pre><code>import ....\n\nclass InverseKinematicsUR3e(...)\n\n  def __init__(self): \n    ...\n    ...\n    self.publisher_ = self.create_publisher(CommandUR3e, '/ur3/command', 10)\n    ...\n    ...\n\n  def move_robot(...):\n    ...\n    ...\n\n  def calculate_fk_from_dh(...):\n    ...\n    ...\n\n  def inverse_kinematics(self, xWgrip, yWgrip, zWgrip, yawWgrip):\n\n    # TODO: Function that calculates an elbow up \n    # inverse kinematics solution for the UR3\n\n    # Step 1: find gripper position relative to the base of UR3,\n    # and set theta_5 equal to -pi/2\n\n\n    # Step 2: find x_cen, y_cen, z_cen\n\n\n    # Step 3: find theta_1\n\n\n    # Step 4: find theta_6 \n\n\n    # Step 5: find x3_end, y3_end, z3_end\n\n\n    # Step 6: find theta_2, theta_3, theta_4\n\n    # Return the set of joint angles to move the robot\n\n\ndef main(...):\n\n  ...\n  ...\n\nif __name__ == '__main__':\n  main()\n</code></pre> <p>You command should look like this:</p> <pre><code>ros2 run &lt;package_name&gt; ur3e_sim_ik_publisher &lt;x&gt; &lt;y&gt; &lt;z&gt; &lt;Yaw&gt;\n</code></pre>"},{"location":"labs/week-08/#test-cases","title":"Test Cases","text":"Test Point Inputs (x, y, z, yaw) IK solution (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) Output from <code>/ur3/position</code> (0.2, 0.3, 0.3, 45) (0.1, 0.4, 0.1, 90) (0.2, 0.2, 0.2, 0) (0.2, -0.2, 0.1, 0) (0.2, 0.3, 0.4, 30) ### Submission <ol> <li>A pdf of your code complete with comments describing the steps you've taken</li> <li>A pdf containing a (neatly) written/typed solution for IK showing how you derived your equations from the geometry</li> <li>Screenshots of UR3e in Gazebo for all test cases</li> <li>A comparison of error between your IK script and the output of the <code>ur3/position</code> topic for the test cases with a discussion of possible error sources.</li> <li>A brief discussion of any possible singularities in the math and what could be done to avoid them (you don't need to implement this, we just want you thinking about strategies!)</li> </ol>"},{"location":"labs/week-09/","title":"Week 09 \u2014 Inverse Kinematics Lab","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 11 - Inverse Kinematics Lab/</code></li> <li>Note: An <code>IK Lab Solution.pdf</code> exists in repo root for staff reference.</li> </ul>"},{"location":"labs/week-10/","title":"Week 10 \u2014 IK Lab / Dynamics intro","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 10 - Forward Kinematics Lab/</code></li> </ul>"},{"location":"labs/week-10/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-10/#week-10-ur3e-forward-kinematics","title":"Week 10 - UR3e Forward Kinematics","text":""},{"location":"labs/week-10/#objectives","title":"Objectives","text":"<ul> <li>Use forward kinematics (FK) to compute the pose of a UR3e robot arm's end effector.</li> <li>Determine where a laser pointer on the end effector intersects with a workbench at an arbitrary height.</li> <li>Publish commands to control the UR3e robot in ROS2 and visualize results.</li> </ul>"},{"location":"labs/week-10/#1-getting-started-with-the-ur3e","title":"1. Getting Started with the UR3e","text":"<ul> <li>Power on the robot</li> <li> <p>Release the brakes</p> </li> <li> <p>Interfacing the Robot with PC</p> </li> </ul> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS</li> </ul> <p>In one more terminal windows launch these commands:</p> <pre><code>ros2 launch ur3e_mrc ur3e_enme480.launch\n</code></pre>"},{"location":"labs/week-10/#2-modify-the-fk-script-to-move-the-robot","title":"2. Modify the FK script to move the robot","text":"<p>Due to inaccuracies in some of the DH tables, resulting in safety risks, we are giving you a code structure that you need to enter your code in.</p> <p>It is located in <code>~/rosPackages/ENME480_ws/enme480_fk_labs/enme480_fk_labs/ur3e_fk.py</code></p> <p>If you are using your own code, remember to change the node name to <code>ur3e_fk_publisher</code></p> <p>To run it:</p> <pre><code>ros2 run enme480_lab_fk ur3e_fk joint1 joint2 joint3 joint4 joint5 joint6\n</code></pre>"},{"location":"labs/week-10/#3-predicting-where-the-laser-point-will-land","title":"3. Predicting where the laser point will land","text":"<p>Since you know the position and orientation of the end effector (attached with a laser pointer), you have to predict where the laser point will land on the workbench. (Hint: Think in terms of vector and plane intersection)</p> <p>Assume the <code>z_table = 0</code>. </p> <p>We are providing you with the code in lab, but you need to show the math behind it in your lab report.</p> <p>Turning on the laser pointer:</p> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre>"},{"location":"labs/week-10/#4-test-points","title":"4. Test Points","text":"<p>Run the robot for the following test points:</p> Test Point Inputs (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) End Effector Position (Your Code) <code>(x y z)</code> Laser Position on Workbench (from Code) (<code>x,y</code>) Laser Position on Workbench(Measured) <code>(x, y)</code> [0, -45, 0, 45, -90, 60] [-30, -60, 80, -10, -90, -30] [30 -70 80 -10 -90 10] [-30, -60, 60, -10, -90, -30]"},{"location":"labs/week-10/#submission","title":"Submission","text":"<p>Please create a neatly typed/written report for the lab including the following:</p> <ul> <li>Correct frame and axes assignments for the UR3e</li> <li>A correct DH table for the UR3e (with the updated dimensions)</li> <li>A detailed derivation of how the position of laser point is predicted on the workbench.</li> <li>Error Analysis (for at least 2 points)</li> <li>Your code snippets for the functions supposed to be changed (function for moving the robot and calulating DH transformation matrix)</li> </ul>"},{"location":"labs/week-11/","title":"Week 11 \u2014 Dynamics + Intro to Cameras","text":"<ul> <li>\ud83d\udcc4 Camera perspective PDF in repo: <code>labs/Lab-Code/PerspectiveTransformEstimation (1).pdf</code></li> </ul>"},{"location":"labs/week-11/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-11/#week-11-ur3e-inverse-kinematics","title":"Week 11 - UR3e Inverse Kinematics","text":""},{"location":"labs/week-11/#objectives","title":"Objectives","text":"<ul> <li>Use inverse kinematics (IK) to compute the required joint angles of a UR3e robot arm for its end effector to reach a specific point.</li> <li>Determine if the laser pointer is close to the predicted cartesian coordinates.</li> <li>Publish commands to control the UR3e robot in ROS2 and visualize results.</li> </ul>"},{"location":"labs/week-11/#1-getting-started-with-the-ur3e","title":"1. Getting Started with the UR3e","text":"<ul> <li>Power on the robot</li> <li>Release the brakes</li> </ul>"},{"location":"labs/week-11/#interfacing-the-robot-with-pc","title":"Interfacing the Robot with PC","text":"<p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS.</li> </ul> <p>In one more terminal window launch this command:</p> <pre><code>ros2 launch ur3e_mrc ur3e_enme480.launch\n</code></pre>"},{"location":"labs/week-11/#2-modify-the-ik-script-to-move-the-robot","title":"2. Modify the IK script to move the robot","text":"<p>Due to inaccuracies in some of your IK calculations, resulting in safety risks due to singulartities, we are giving you a code structure that you need to enter your code in.</p> <p>It is located in <code>~/rosPackages/ENME480_ws/src/enme480_fk_labs/enme480_fk_labs/ur3e_ik.py</code></p> <p>To refresh the folder to original state run the following commands:</p> <pre><code>cd ~/ENME480_ws/src/enme480_lab_fk\ngit checkout .\n</code></pre> <p>You need to modify the following functions within the given snippet (do not change anything else in the code):</p> <ul> <li><code>send_command()</code> - will be the same as last time (just remove conversion to radians since IK takes care of it)</li> <li><code>calculate_dh_transform()</code> - will be exactly same as last time (just make changes to DH parameters if wrong)</li> <li><code>inverse_kinematics()</code> - will be exactly similar as your simulation code</li> </ul> <p>Helpful Tip: Use tools like Pastebin or Google Docs to move your code from your laptop to the lab machine</p> <p>If you are using your own code, remember to change the node name to <code>ur3e_ik_publisher</code></p> <p>To run it:</p> <pre><code>ros2 run enme480_lab_fk ur3e_ik x y z yaw\n</code></pre> <p>If your IK code has high or slight error, you will receive a prompt on your terminal. Please follow the instructions. The robot will move regardless but those error mean that you need to check your calculations.</p>"},{"location":"labs/week-11/#3-predicting-where-the-laser-point-will-land","title":"3. Predicting where the laser point will land","text":"<p>Since we are constraining IK to always face down, the laser point will exactly point at the same <code>(x,y)</code> as the end effector. You just need to measure z. Your prediction will depend on your DH transformation.</p> <p>Turning on the laser pointer:</p> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre> <p>If your DH transform is right, you should recieve a similar transformation matrix as the <code>Correct Transformation Matrix</code> on your terminal. Otherwise, work on it to get a matrix as similar as possible</p>"},{"location":"labs/week-11/#4-test-points","title":"4. Test Points","text":"<p>Run the robot for the following test points and record the following data:</p> Test Point Inputs (x, y, z, Yaw) Joint Angles (Your Code)  <code>(\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4)</code> Correct Joint Angles <code>(\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4)</code> Laser Position on Workbench (Your Prediction) <code>(x, y)</code> Laser Position on Workbench (Correct Prediction) <code>(x, y)</code> Laser Position on Workbench (Measured Prediction) <code>(x, y)</code> End Effector Position (Your Prediction) <code>(x, y, z)</code> End Effector Position (Correct Prediction) <code>(x, y, z)</code> End Effector Position (Measured) <code>(x, y, z)</code> [0.2, 0.2, 0.2, 0] [0.2, 0.4, 0.2, 0] [0.3, 0.4, 0.1, 45] [0.3, 0.2, 0.25, 60] [0.25, 0.3, 0.3, -30]"},{"location":"labs/week-11/#5-before-you-leave-the-lab","title":"5. Before you leave the lab","text":"<p>Send yourself the backup/copy of your script and restore the package to its blank version.</p> <p>IMPORTANT: The below command will erase your script from the computer so take a backup of it before you run it</p> <pre><code>cd ~/rosPackages/ENME480_ws/src/enme480_lab_fk\ngit checkout .\n</code></pre>"},{"location":"labs/week-11/#submission","title":"Submission","text":"<p>Please create a neatly typed/written report for the lab including the following: 1. Your IK derivation - you can resue the one from Week 8 submission if that was right. If anything changed or you noticed errors in your previous derivation, make a note of it in the report including the reason behind the error. 2. Comparsion table for Step 4. 3. Write a paragraph on the reasons behind discrepancies in measurements and calculations. 4. What are the potential sources of singlularities and how will avoid them when you are implementing the code? If you found any singularities, be sure to list them and discuss possible causes. 5. Code snippet of <code>inverse_kinematics()</code> function that you used.</p>"},{"location":"labs/week-12/","title":"Week 12 \u2014 Camera Lab (+ Exam 2 week)","text":"<ul> <li>\ud83d\udcc1 Camera Lab materials: use camera PDF above and any posted updates.</li> </ul>"},{"location":"labs/week-13/","title":"Week 13 \u2014 Make-up / Office Hours","text":"<p>No lab meetings (holiday week). Use time for project prep.</p>"},{"location":"labs/week-14/","title":"Week 14 \u2014 Final Project (starts)","text":"<ul> <li>\ud83d\udcc1 Final Project folder: <code>labs/Lab-Code/Final Project/</code></li> </ul>"},{"location":"labs/week-15/","title":"Week 15 \u2014 Final Project (wrap-up)","text":"<ul> <li>\ud83d\udcc1 Continue work in <code>labs/Lab-Code/Final Project/</code></li> <li>Deliverables: write-up + video demo (see syllabus).</li> </ul>"}]}