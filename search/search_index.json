{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\ude80 ENME480 \u2014 Introduction to Robotics","text":"**Fall 2025 \u2022 University of Maryland \u2022 3 credits**  *Hands-on robotics with UR3e arms, ROS 2, simulation, and a vision-enabled final project*  [![Course Banner](assets/images/favicon.png){ width=\"200\" }](assets/images/favicon.png)"},{"location":"#course-overview","title":"\ud83c\udfaf Course overview","text":"<p>ENME480 blends core theory with practical labs:</p> <ul> <li>\ud83e\udd16 Kinematics &amp; dynamics \u2014 rigid motions, forward/inverse kinematics, planning &amp; control  </li> <li>\ud83e\uddd1\u200d\ud83d\udcbb ROS 2 &amp; Python \u2014 modern robotics tooling and best practices  </li> <li>\ud83e\uddea Studios &amp; labs \u2014 translate math into code on UR3e industrial arms  </li> <li>\ud83d\udc41\ufe0f Vision pipeline \u2014 perception + pick &amp; place for the final project</li> </ul>"},{"location":"#key-facts","title":"\ud83d\udd11 Key facts","text":"<ul> <li>Instructor: Dr. Nikhil Chopra \u2014 Office Hours: Wed 10\u201311:30, 2149 Martin Hall (Zoom link in syllabus)  </li> <li>TAs: Alex Beyer, Kaustubh Joshi \u2014 TA Office Hours: TBD </li> <li>Course dates: Sep 2 \u2013 Dec 12, 2025 </li> <li>Lectures: MW 2:00\u20132:50pm (TWS1100)  </li> <li>Studios (sections): 0101 Thu 12\u20132, 0102 Fri 8\u201310, 0103 Tue 12\u20132 (KEB 2111 / EAF 3119)  </li> <li>Channels: Piazza, Canvas, GitHub</li> </ul> <p>Note on rooms: Syllabus mentions EAF 3119 in the section schedule and 3117 elsewhere. We list EAF 3119 here; confirm via Schedule/Piazza if updated.</p>   [\ud83d\udccb View Syllabus](syllabus.md){ .md-button .md-button--primary } [\ud83d\uddd3\ufe0f Schedule](schedule.md){ .md-button } [\ud83e\uddea Start Labs](labs/index.md){ .md-button } [\u2753 Help](help.md){ .md-button }"},{"location":"#quick-start-new-students","title":"\ud83d\ude80 Quick start (new students)","text":"<ol> <li>\ud83d\udccb Complete Safety Training (required before robot lab) </li> <li>\ud83d\udcbb Set up Ubuntu, Python, and ROS 2 \u2014 see Week 1 </li> <li>\ud83d\udc27 Practice Linux/Python basics \u2014 Week 2 </li> <li>\ud83e\udd16 Get started with ROS \u2014 Week 3</li> </ol>"},{"location":"#key-dates","title":"\ud83d\udcc5 Key dates","text":"<p>Final dates live on Canvas; midterm weeks appear on the Schedule page.</p> <ul> <li>Course runs: Sep 2 \u2192 Dec 12, 2025  </li> <li>Midterm 1: TBD (see Schedule) </li> <li>Midterm 2: TBD (see Schedule) </li> <li>Final project demos: TBD (last 1\u20132 weeks)</li> </ul>"},{"location":"#this-week","title":"\ud83d\uddd3\ufe0f This week","text":"<ul> <li>Safety training due by end of Week 1</li> <li>Environment setup (Ubuntu, Python, ROS 2)</li> <li>Account verification for lab access</li> </ul>"},{"location":"#whats-new","title":"\u26a1 What\u2019s new","text":"<ul> <li>Course website launched \ud83c\udf89</li> <li>Lab materials synced from GitHub</li> </ul>"},{"location":"#at-a-glance","title":"\ud83e\udded At a glance","text":"<ul> <li> <p> Meetings     ---     Lectures: MW 2:00\u20132:50 (TWS1100) Studios: 0101 Thu 12\u20132 \u2022 0102 Fri 8\u201310 \u2022 0103 Tue 12\u20132 (KEB 2111 / EAF 3119)      Schedule</p> </li> <li> <p> Grading     ---     Homework 20% \u00b7 Studios/Labs 20% \u00b7 Midterm 1 20% \u00b7 Midterm 2 20% \u00b7 Final Project 20% \u00b7 Extra credit up to 5%  Policies</p> </li> <li> <p> Text &amp; tools     ---     Spong/Hutchinson/Vidyasagar, Robot Modeling and Control (2e, 2020).     ROS 2 (Humble) + Python; laptop capable of running ROS 2.      Resources</p> </li> </ul>"},{"location":"#locations","title":"\ud83c\udfe2 Locations","text":"Activity Location Room \ud83d\udcbb Programming Studios Kim Engineering (KEB) KEB 2111 \ud83e\udd16 Robot Lab (RAL) Engineering Annex Facility (EAF) EAF 3119 (watch Piazza for any changes) \ud83d\udcda Office Hours (Instructor) Martin Hall 2149 (Wed 10\u201311:30)"},{"location":"#learning-path","title":"\ud83c\udf93 Learning path","text":"<pre><code>graph LR\n    A[Week 1\u20132: Setup] --&gt; B[Week 3: ROS Basics]\n    B --&gt; C[Week 4\u20135: Gazebo &amp; Demos]\n    C --&gt; D[Week 5\u20138: Kinematics]\n    D --&gt; E[Week 9\u201311: Dynamics &amp; Control]\n    E --&gt; F[Final Project]\n</code></pre>"},{"location":"help/","title":"\ud83c\udd98 Help &amp; Support","text":"**Need assistance? You're in the right place!**   *Everything you need to succeed in ENME480.*"},{"location":"help/#contact","title":"\ud83d\udcde Contact","text":"Who Details Best for \ud83c\udf93 Instructor \u2013 Dr. Nikhil Chopra Office Hours: Wed 10\u201311:30, 2149 Martin Hall \u2022 Email: nchopra@umd.edu \u2022 Zoom (syllabus link) Course content, grades, personal issues \ud83d\udc68\u200d\ud83d\udcbb TAs \u2013 Alex Beyer, Kaustubh Joshi Emails: abeyer@umd.edu, kjoshi@umd.edu \u2022 Office Hours: TBD Labs &amp; technical questions \ud83d\udcac Piazza piazza.com/umd/fall2025/enme480 Official Q&amp;A and announcements \ud83d\udce7 Canvas (ELMS) elms.umd.edu Materials, submissions, grades \ud83e\uddd1\u200d\ud83d\udcbb GitHub github.com/ENME480 Lab code &amp; updates"},{"location":"help/#emergency-safety","title":"\ud83d\udea8 Emergency &amp; Safety","text":"<ul> <li>Complete required safety training before entering RAL and using robots.  </li> <li>Never bypass safety systems; stay clear of the robot workspace; hit E-Stop when in doubt.  </li> <li>For medical or fire emergencies, call 911 / campus police; follow posted lab procedures.</li> </ul>"},{"location":"help/#lab-support","title":"\ud83e\uddea Lab Support","text":"<p>Before lab: finish pre-lab reading, set up ROS 2, review safety. During lab: ask TAs early; report equipment issues immediately. Attendance: Studios are mandatory; late/missed attendance may affect grades; coordinate via Piazza if conflicts arise. Homework cadence: posted Fridays 11:59pm, due a week later via Canvas.</p>"},{"location":"help/#quick-troubleshooting","title":"\ud83d\udcbb Quick Troubleshooting","text":""},{"location":"help/#ubuntu","title":"Ubuntu","text":"<pre><code>lsb_release -a\nsudo apt update &amp;&amp; sudo apt upgrade\ndf -h\n</code></pre>"},{"location":"help/#python","title":"Python","text":"<pre><code>python3 --version\npython3 -m pip install --upgrade pip\n</code></pre>"},{"location":"help/#ros-2","title":"ROS 2","text":"<pre><code>ros2 --help\nsource /opt/ros/humble/setup.bash\nros2 topic list\n</code></pre>"},{"location":"help/#learning-resources","title":"\ud83d\udcda Learning Resources","text":"<ul> <li>ROS 2 Docs (Humble)</li> <li>Python Docs \u2022 Ubuntu Help</li> <li>Gazebo Tutorials (or Ignition Gazebo)</li> <li>Stack Overflow \u2022 ROS Answers</li> </ul>"},{"location":"help/#asking-great-questions","title":"\ud83c\udfaf Asking Great Questions","text":"<ol> <li>Search Piazza/Canvas first \u2192 2) Try a fix \u2192 3) Share error + steps tried \u2192 4) Minimal code reproducer.    Example: \"<code>ros2 run my_pkg node</code> fails with <code>ImportError: \u2026</code>. I re-sourced <code>setup.bash</code>, verified <code>PYTHONPATH</code>, and rebuilt. Full stack trace: \u2026\"</li> </ol> <p>Last updated: Fall 2025 \u2022 Back to Home</p>"},{"location":"policies/","title":"Policies &amp; Campus Resources","text":"<p>This course follows University policies (integrity, conduct, accessibility, attendance, grades, IP). See campus policy pages and the syllabus for full details.</p>"},{"location":"policies/#academic-integrity-course-specific","title":"Academic Integrity (Course-specific)","text":"<ul> <li>Unauthorized collaboration or AI-generated solutions are not permitted unless explicitly allowed.</li> <li>Pledge on each assessment: \u201cI pledge on my honor that I have not given or received any unauthorized assistance on this exam/assignment.\u201d</li> <li>When in doubt about collaboration boundaries, ask the course staff.</li> </ul>"},{"location":"policies/#ai-usage-course-specific","title":"AI Usage (Course-specific)","text":"<ul> <li>You may use AI tools for brainstorming/review; your final submissions must be your own.</li> <li>Never run AI-generated code on physical robots.</li> </ul>"},{"location":"policies/#accessibility-accommodations","title":"Accessibility &amp; Accommodations","text":"<p>UMD ADS provides accommodations; contact the instructor promptly to arrange.</p>"},{"location":"policies/#title-ix-mandatory-reporting","title":"Title IX &amp; Mandatory Reporting","text":"<p>The instructor is a Responsible University Employee. Confidential resources include CARE to Stop Violence and the Counseling Center.</p>"},{"location":"policies/#participation-attendance","title":"Participation &amp; Attendance","text":"<p>Attendance and on-time arrival are essential, especially for group studios/labs. If you must miss your assigned lab time, message TAs via Piazza in advance and coordinate with your team.</p>"},{"location":"policies/#safety-guidelines","title":"Safety Guidelines","text":""},{"location":"policies/#robot-lab-safety","title":"Robot Lab Safety","text":"<ul> <li>Safety training is mandatory before entering the robot lab</li> <li>Never bypass safety systems or remove safety guards</li> <li>Keep clear of robot workspace during operation</li> <li>Use emergency stop buttons if needed</li> <li>Report safety concerns immediately to course staff</li> </ul>"},{"location":"policies/#general-lab-safety","title":"General Lab Safety","text":"<ul> <li>Follow all posted safety procedures</li> <li>Wear appropriate safety gear when required</li> <li>Keep work areas clean and organized</li> <li>Report equipment malfunctions immediately</li> <li>No food or drink in lab areas</li> </ul>"},{"location":"policies/#emergency-procedures","title":"Emergency Procedures","text":"<ul> <li>Medical emergency: Call 911 or campus police</li> <li>Fire/equipment emergency: Use emergency stops, evacuate if needed</li> <li>Robot malfunction: Stop all operations, contact TA immediately</li> </ul>"},{"location":"policies/#course-evaluation","title":"Course Evaluation","text":"<p>Please complete Student Feedback on Course Experiences at semester end.</p>"},{"location":"resources/","title":"Resources","text":"<ul> <li>Lab code (submodule): <code>labs/Lab-Code/</code> \u2192 upstream: https://github.com/ENME480/Lab-Code</li> <li>ROS 2 (Humble) tutorials &amp; docs: installation, nodes, topics, tf2, URDF, Gazebo, etc.</li> <li>Textbook: Spong, Hutchinson, Vidyasagar \u2014 Robot Modeling and Control (2e, 2020).</li> </ul> <p>TODO: Add department/proctoring links, UR3e datasheets, safety docs, camera calibration notes, lab-specific setup scripts.</p>"},{"location":"schedule/","title":"Schedule \u2014 Fall 2025","text":"<p>Note: Locations may change; monitor Piazza for updates. Studios meet in KEB 2111 (programming) and EAF 3119 (robot lab) unless noted.</p> Week Dates Mon (Lecture) Tue (Lab/Studio) Wed (Lecture) Thu (Lab/Studio) Fri (Lab/Studio) 1 9/1\u20139/5 No Lecture (Mon) Lab Intro Intro &amp; Linear Algebra Primer Lab Intro Lab Intro 2 9/8\u20139/12 Linear Algebra Primer RAL Intro, Setup Linear Algebra Primer RAL Intro, Setup RAL Intro, Setup 3 9/15\u20139/19 Rigid Motions Python Intro, ROS Intro, Studio 1 Rigid Motions Python Intro, ROS Intro, Studio 1 Python Intro, ROS Intro, Studio 1 4 9/22\u20139/26 Rigid Motions Gazebo Demo, Studio 2 Rigid Motions Gazebo Demo, Studio 2 Gazebo Demo, Studio 2 5 9/29\u201310/3 Forward Kinematics FK Lab 1.1 Forward Kinematics FK Lab 1.1 FK Lab 1.1 6 10/6\u201310/10 Velocity Kinematics FK Lab 1.2 Velocity Kinematics FK Lab 1.2 FK Lab 1.2 7 10/13\u201310/17 No Lecture (Mon/Tue) No Lecture Velocity Kinematics No Lab (Make-up/Office Hours) No Lab (Make-up/Office Hours) 8 10/20\u201310/24 Exam IK Studio Inverse Kinematics IK Studio IK Studio 9 10/27\u201310/31 Inverse Kinematics IK Lab Inverse Kinematics IK Lab IK Lab 10 11/3\u201311/7 Inverse Kinematics IK Lab Dynamics IK Lab IK Lab 11 11/10\u201311/14 Dynamics Intro to Cameras Dynamics Intro to Cameras Intro to Cameras 12 11/17\u201311/21 Path &amp; Trajectory Planning Camera Lab Exam 2 Camera Lab Camera Lab 13 11/24\u201311/29 Path &amp; Trajectory Planning No Lab (Make-up/Office Hours) No Lecture (Wed\u2013Fri) No Lecture No Lecture 14 12/1\u201312/5 Path &amp; Trajectory Planning Final Project Independent Joint Control Final Project Final Project 15 12/8\u201312/12 Independent Joint Control Final Project Independent Joint Control Final Project Final Project"},{"location":"syllabus/","title":"Syllabus \u2014 Fall 2025","text":"<p>Course: ENME480 \u2014 Intro to Robotics Credits: 3 Dates: Sep 2, 2025 \u2013 Dec 12, 2025 Professor: Dr. Nikhil Chopra \u2014 nchopra@umd.edu Office Hours: Wed 10\u201311:30, 2149 Martin Hall \u2014 Zoom link Teaching Assistants: Alex Beyer (abeyer@umd.edu), Kaustubh Joshi (kjoshi@umd.edu) TA Office Hours: TBD Canvas (ELMS): http://www.elms.umd.edu/ Piazza (official Q&amp;A): http://piazza.com/umd/fall2025/enme480 Lab GitHub org: https://github.com/ENME480</p>"},{"location":"syllabus/#course-description","title":"Course Description","text":"<p>This course introduces elementary concepts in robotics with integrated theory and lab components. Labs emphasize interdisciplinary teamwork, developing and testing code on UR3e robotic arms across programming studios and hands-on lab sections.</p>"},{"location":"syllabus/#learning-outcomes","title":"Learning Outcomes","text":"<ul> <li>Apply mathematics, science, and engineering to robotics problems  </li> <li>Analyze and interpret experimental data  </li> <li>Use robot geometry for kinematics analysis  </li> <li>Apply robot dynamics for planning and control</li> </ul>"},{"location":"syllabus/#required-resources","title":"Required Resources","text":"<ul> <li>Course website: ELMS-Canvas  </li> <li>Textbook: Robot Modeling and Control (2e), Spong, Hutchinson, Vidyasagar, 2020, ISBN 978-1119523994  </li> <li>Hardware/Software: Laptop capable of running ROS 2 (setup guided in labs)</li> </ul>"},{"location":"syllabus/#course-structure","title":"Course Structure","text":"<ul> <li>Lectures &amp; in-class assignments: Short comprehension questions (extra credit) may be assigned after lectures.  </li> <li>Studios &amp; Labs: Run by TAs in KEB 2111 (programming) and EAF 3119 (Robotics &amp; Autonomy Lab). Safety seminar + online training required before using robots.  </li> <li>Homework: Posted Fridays 11:59 pm; due one week later via Canvas. Extensions via Piazza only (solutions release soon after deadlines).  </li> <li>Exams: Two midterms (see Schedule). One page of notes (front/back) permitted.  </li> <li>Final Project: Vision-enabled pick-and-place with UR3e: locate blocks, grasp, and build a tower. Group project with write-up and video.</li> </ul>"},{"location":"syllabus/#major-assignments-weighting","title":"Major Assignments &amp; Weighting","text":"Component % Homework 20% Studio/Lab Assignments 20% Midterm 1 20% Midterm 2 20% Final Project 20% Extra Credit: In-class assignments Up to 5% <p>Final grade cutoffs: A+: 97, A: 94, A-: 90; B+: 87, B: 84, B-: 80; C+: 77, C: 74, C-: 70; D+: 67, D: 64, D-: 60; F: &lt; 60.</p>"},{"location":"syllabus/#communication-participation","title":"Communication &amp; Participation","text":"<ul> <li>Piazza is official for course questions; Canvas hosts materials/announcements.  </li> <li>Professional, inclusive discussion is expected in all channels and sessions.  </li> <li>Attendance and on-time arrival for studios/labs are essential; coordinate via Piazza if you must miss your assigned session.</li> </ul>"},{"location":"syllabus/#policies-summary","title":"Policies (Summary)","text":"<ul> <li>Academic Integrity: The University\u2019s Code applies; collaboration on graded work is prohibited unless stated. Unauthorized use of course-assistance sites or AI-generated solutions is not permitted. Pledge required on each assignment/exam.  </li> <li>AI Usage (Course-specific): Brainstorming/review OK; final work must be your own. Do not run AI-generated code on physical robots. </li> <li>Accessibility &amp; Accommodations: See ADS; contact instructor promptly for arrangements.  </li> <li>Campus resources: Emergency Preparedness, Basic Needs, Veteran Resources, Title IX, Course Evaluation\u2014see Policies page.</li> </ul>"},{"location":"_labcode/Final%20Project/Final_Project_Details/","title":"ENME480 Final Project - Pick and Place Task using UR3e","text":""},{"location":"_labcode/Final%20Project/Final_Project_Details/#objective","title":"Objective","text":"<p>The objective of this project is to control the UR3e to move (at least) three AR-tagged blocks to desired positions using camera image as inputs. We will use OpenCV for processing the image data. The program will also integrate the functions of previous lab assignments. The major objectives are the following - Use OpenCV functions to find the centroid of each block - Convert the pixel coordinates in an image to coordinates in the world frame using a perspective matrix - Move the blocks from the detected positions to predefined desired positions</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#task-description","title":"Task Description","text":"<p>The lab environment is shown below:</p> <p></p> <p>You will be given 3 blocks with different Aruco markers. Your task is to move them out of the workspace into predefined positions. To do so, you will need to find the centroid postion of the top side of each block with an image from the camera mounted above the table, facing down on the workspace. You will convert the detected pixel coordinates to the table frame using a persepctive transform. Then using your inverse kinematics solution, you will pick up the block using a suction gripper mounted at the end effector. Your task is to place each block at a specific location outside the workspace.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#overview-of-the-ros-package","title":"Overview of the ROS Package","text":"<p>The project package should be located on the local lab machines in RAL. You can also find the package with redacted scripts here: https://github.com/ENME480/enme480_project.</p> <p>The nodes have been added to the <code>setup.py</code> file, so you do not need to add that. You will find five scripts as listed in the table below:</p> Script Name Description <code>get_perspective_warping_with_aruco.py</code> Script to create the perspective matrix <code>aruco_detection_test.py</code> Script to test the perspective transform and get coordinates of the blocks in table frame <code>block_detection_aruco.py</code> ROS Node for detecting blocks, uses the same function and changes from <code>aruco_detection_test.py</code> <code>kinematic_functions.py</code> Script to insert all of your FK and IK functions from previous labs <code>main_pipeline.py</code> The main pipeline to strategize and sequence movement of the blocks <p>Please do not edit anything outside the given code snippets (it will lead to errors which will be difficult to identify)</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#procedure-for-setup-in-ral","title":"Procedure for Setup in RAL","text":"<p>Please follow the following steps before you start editing the scripts on RAL machines</p> <ol> <li> <p>UR3e Setup</p> <ul> <li>Power on the robot</li> <li>Release the brakes</li> </ul> </li> <li> <p>Restore the package to original form and pull the latest version</p> </li> </ol> <pre><code>cd rosPackages/ENME480_ws/src/enme480_project\ngit checkout .\ngit pull\n</code></pre> <ol> <li>Interfacing the Robot with PC</li> </ol> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS</li> </ul>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#script-descriptions","title":"Script Descriptions","text":"<p>You are recommended to complete each script in the order suggested in the table. </p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#get_perspective_warping_with_arucopy","title":"<code>get_perspective_warping_with_aruco.py</code>","text":"<p>This script will generate a perspective matrix for the camera to table frame. You need to edit one line to input the reference points on the table. Ensure that you are entering the values in <code>mm</code>. This script will generate a <code>perspective_matrix.npy</code> file in the folder.</p> <p>Before you run this script, ensure that you are in the correct directory. Assuming you have already entered the docker container, run</p> <pre><code>cd ENME480_ws/src/enme480_project/enme480_project/\npython3 get_perspective_warping_with_aruco.py\n</code></pre>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#troubleshooting","title":"Troubleshooting:","text":"<p>If you get a missing keyboard package error run the following command</p> <pre><code>pip install keyboard\n</code></pre> <p>Once run, you will see a window with the live camera feed. Click on the reference points in the same order that you have listed in your script. It will calulate the perspective transform and a new window will pop-up showing a blue dot at <code>(175,175)</code> on the table coordinate frame. If this is right, you can proceed to the next script.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#aruco_detection_testpy","title":"<code>aruco_detection_test.py</code>","text":"<p>This script will give you a live detection of the aruco markers and their location w.r.t the table frame in real-time. You need to modify the <code>image_frame_to_table_frame()</code> function in the script. Use the math from prespective transforms to do the same. You can find a file discussing perspective transforms in the main folder on this repository.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#block_detection_arucopy","title":"<code>block_detection_aruco.py</code>","text":"<p>This is the ROS node and a Python class for all the functions in the <code>aruco_detection_test.py</code> script. If your <code>aruco_detection_test.py</code> could detect the block coordinates correctly, please copy the same function to the snippet for <code>image_frame_to_table_frame()</code> function in this script as well.</p> <p>You can test this script by running the following commands:</p> <ul> <li>In a new terminal in the docker container, launch the camera node:</li> </ul> <pre><code>ros2 launch usb_cam camera.launch.py\n</code></pre>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#troubleshooting_1","title":"Troubleshooting:","text":"<p>If you get a Pydantic error run the following command</p> <pre><code>sudo pip install pydantic==1.10.9\n</code></pre> <p>Once the camera node is up and running, run the following command in a seperate terminal:</p> <pre><code>ros2 run enme480_project aruco_tracker\n</code></pre> <p>It will publish data under two topics <code>/aruco_detection/image</code> and <code>/aruco_detection/positions</code></p> <p>You can view the image using </p> <pre><code>ros2 run rqt_image_view rqt_image_view\n</code></pre> <p>and it should show the same image in the window as the one you saw with <code>aruco_detection_test.py</code>, once you select the topic.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#kinematic_functionspy","title":"<code>kinematic_functions.py</code>","text":"<p>This script will use your functions from previous labs and if you have the script working correctly for your FK and IK labs, you can copy the exact same functions here under the functions <code>calculate_dh_transform()</code> and <code>inverse_kinematics()</code> within the given snippets. We need to verify if your IK script is working correctly so please call the TAs over top show your final IK code working before you copy this.</p>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#main_pipelinepy","title":"<code>main_pipeline.py</code>","text":"<p>This script is where you will sequence and startegize the pick and place process. In this script, you have to edit the following functions:</p> <ol> <li> <p><code>move_arm()</code></p> <p>This function will take in the desired joint positions and publish them using the message data structure given in code comments</p> </li> <li> <p><code>gripper_control()</code></p> <p>This function will take in the desired state of the gripper and publish it using the message data structure given in code comments</p> </li> <li> <p><code>move_block()</code></p> <p>Here, you need to work on giving the sequence of positions you want the block to move to for moving a block from an initial position to a final position. Keep in mind that every block needs to be picked up, raised up and then moved. Do not give it a sequence to drag it accross the table.</p> </li> <li> <p><code>process_blocks()</code></p> <p>This function is where you will enter the startegy and sorting method to place the blocks in their desired positions given their IDs, pre-defined destinations.</p> </li> </ol> <p>Once everything is ready, call the TAs over before you execute the node</p> <pre><code>ros2 run enme480_project main_pipeline\n</code></pre>"},{"location":"_labcode/Final%20Project/Final_Project_Details/#submission-requirements","title":"Submission Requirements","text":"<p>One single PDF containing the following:</p> <ul> <li>Pseudo code for detecting and moving the block  (no specific format to be followed)</li> <li>Math for camera frame to table frame (your intuition behind the perspective warping, and transformation from camera frame to image frame)</li> <li>Video of pick and place task on UR3e (as a link (GDrive/YouTube) in the report)</li> <li>Extra Credit: Stacking (3.33 pts per block) - Max 10pts possible </li> </ul>"},{"location":"_labcode/Week%201%20Materials/","title":"Week 1 - Lab Introduction","text":""},{"location":"_labcode/Week%201%20Materials/#overview","title":"Overview","text":"<p>Course/lab onboarding, environments, safety overview, space orientation (KEB 2111 &amp; EAF 3119).</p>"},{"location":"_labcode/Week%201%20Materials/#materials","title":"Materials","text":"<ul> <li>ENME480 Lab 1.pptx - Complete lab presentation with course overview</li> </ul>"},{"location":"_labcode/Week%201%20Materials/#key-topics","title":"Key Topics","text":"<ul> <li>Environment Setup: Course and lab environment configuration</li> <li>Safety Training: Essential safety protocols and training requirements</li> <li>Space Orientation: Understanding lab spaces and equipment locations</li> <li>Course Structure: Overview of ENME480 robotics course</li> </ul>"},{"location":"_labcode/Week%201%20Materials/#deliverables","title":"Deliverables","text":"<ul> <li>Confirm environment setup and accounts</li> <li>Complete safety training checkpoint (details in Canvas/Piazza)</li> <li>Familiarize with lab spaces</li> </ul>"},{"location":"_labcode/Week%201%20Materials/#lab-locations","title":"Lab Locations","text":"<ul> <li>Programming Lab: KEB 2111</li> <li>Robot Lab: EAF 3119</li> </ul>"},{"location":"_labcode/Week%201%20Materials/#next-steps","title":"Next Steps","text":"<p>After completing this introduction, you'll be ready to begin hands-on robotics work in subsequent weeks.</p>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/","title":"Week 10 - UR3e Forward Kinematics","text":""},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#objectives","title":"Objectives","text":"<ul> <li>Use forward kinematics (FK) to compute the pose of a UR3e robot arm's end effector.</li> <li>Determine where a laser pointer on the end effector intersects with a workbench at an arbitrary height.</li> <li>Publish commands to control the UR3e robot in ROS2 and visualize results.</li> </ul>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#1-getting-started-with-the-ur3e","title":"1. Getting Started with the UR3e","text":"<ul> <li>Power on the robot</li> <li> <p>Release the brakes</p> </li> <li> <p>Interfacing the Robot with PC</p> </li> </ul> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS</li> </ul> <p>In one more terminal windows launch these commands:</p> <pre><code>ros2 launch ur3e_mrc ur3e_enme480.launch\n</code></pre>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#2-modify-the-fk-script-to-move-the-robot","title":"2. Modify the FK script to move the robot","text":"<p>Due to inaccuracies in some of the DH tables, resulting in safety risks, we are giving you a code structure that you need to enter your code in.</p> <p>It is located in <code>~/rosPackages/ENME480_ws/enme480_fk_labs/enme480_fk_labs/ur3e_fk.py</code></p> <p>If you are using your own code, remember to change the node name to <code>ur3e_fk_publisher</code></p> <p>To run it:</p> <pre><code>ros2 run enme480_lab_fk ur3e_fk joint1 joint2 joint3 joint4 joint5 joint6\n</code></pre>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#3-predicting-where-the-laser-point-will-land","title":"3. Predicting where the laser point will land","text":"<p>Since you know the position and orientation of the end effector (attached with a laser pointer), you have to predict where the laser point will land on the workbench. (Hint: Think in terms of vector and plane intersection)</p> <p>Assume the <code>z_table = 0</code>. </p> <p>We are providing you with the code in lab, but you need to show the math behind it in your lab report.</p> <p>Turning on the laser pointer:</p> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre>"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#4-test-points","title":"4. Test Points","text":"<p>Run the robot for the following test points:</p> Test Point Inputs (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) End Effector Position (Your Code) <code>(x y z)</code> Laser Position on Workbench (from Code) (<code>x,y</code>) Laser Position on Workbench(Measured) <code>(x, y)</code> [0, -45, 0, 45, -90, 60] [-30, -60, 80, -10, -90, -30] [30 -70 80 -10 -90 10] [-30, -60, 60, -10, -90, -30]"},{"location":"_labcode/Week%2010%20-%20Forward%20Kinematics%20Lab/FK_Lab/#submission","title":"Submission","text":"<p>Please create a neatly typed/written report for the lab including the following:</p> <ul> <li>Correct frame and axes assignments for the UR3e</li> <li>A correct DH table for the UR3e (with the updated dimensions)</li> <li>A detailed derivation of how the position of laser point is predicted on the workbench.</li> <li>Error Analysis (for at least 2 points)</li> <li>Your code snippets for the functions supposed to be changed (function for moving the robot and calulating DH transformation matrix)</li> </ul>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/","title":"Week 11 - UR3e Inverse Kinematics","text":""},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#objectives","title":"Objectives","text":"<ul> <li>Use inverse kinematics (IK) to compute the required joint angles of a UR3e robot arm for its end effector to reach a specific point.</li> <li>Determine if the laser pointer is close to the predicted cartesian coordinates.</li> <li>Publish commands to control the UR3e robot in ROS2 and visualize results.</li> </ul>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#1-getting-started-with-the-ur3e","title":"1. Getting Started with the UR3e","text":"<ul> <li>Power on the robot</li> <li>Release the brakes</li> </ul>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#interfacing-the-robot-with-pc","title":"Interfacing the Robot with PC","text":"<p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS.</li> </ul> <p>In one more terminal window launch this command:</p> <pre><code>ros2 launch ur3e_mrc ur3e_enme480.launch\n</code></pre>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#2-modify-the-ik-script-to-move-the-robot","title":"2. Modify the IK script to move the robot","text":"<p>Due to inaccuracies in some of your IK calculations, resulting in safety risks due to singulartities, we are giving you a code structure that you need to enter your code in.</p> <p>It is located in <code>~/rosPackages/ENME480_ws/src/enme480_fk_labs/enme480_fk_labs/ur3e_ik.py</code></p> <p>To refresh the folder to original state run the following commands:</p> <pre><code>cd ~/ENME480_ws/src/enme480_lab_fk\ngit checkout .\n</code></pre> <p>You need to modify the following functions within the given snippet (do not change anything else in the code):</p> <ul> <li><code>send_command()</code> - will be the same as last time (just remove conversion to radians since IK takes care of it)</li> <li><code>calculate_dh_transform()</code> - will be exactly same as last time (just make changes to DH parameters if wrong)</li> <li><code>inverse_kinematics()</code> - will be exactly similar as your simulation code</li> </ul> <p>Helpful Tip: Use tools like Pastebin or Google Docs to move your code from your laptop to the lab machine</p> <p>If you are using your own code, remember to change the node name to <code>ur3e_ik_publisher</code></p> <p>To run it:</p> <pre><code>ros2 run enme480_lab_fk ur3e_ik x y z yaw\n</code></pre> <p>If your IK code has high or slight error, you will receive a prompt on your terminal. Please follow the instructions. The robot will move regardless but those error mean that you need to check your calculations.</p>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#3-predicting-where-the-laser-point-will-land","title":"3. Predicting where the laser point will land","text":"<p>Since we are constraining IK to always face down, the laser point will exactly point at the same <code>(x,y)</code> as the end effector. You just need to measure z. Your prediction will depend on your DH transformation.</p> <p>Turning on the laser pointer:</p> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre> <p>If your DH transform is right, you should recieve a similar transformation matrix as the <code>Correct Transformation Matrix</code> on your terminal. Otherwise, work on it to get a matrix as similar as possible</p>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#4-test-points","title":"4. Test Points","text":"<p>Run the robot for the following test points and record the following data:</p> Test Point Inputs (x, y, z, Yaw) Joint Angles (Your Code)  <code>(\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4)</code> Correct Joint Angles <code>(\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4)</code> Laser Position on Workbench (Your Prediction) <code>(x, y)</code> Laser Position on Workbench (Correct Prediction) <code>(x, y)</code> Laser Position on Workbench (Measured Prediction) <code>(x, y)</code> End Effector Position (Your Prediction) <code>(x, y, z)</code> End Effector Position (Correct Prediction) <code>(x, y, z)</code> End Effector Position (Measured) <code>(x, y, z)</code> [0.2, 0.2, 0.2, 0] [0.2, 0.4, 0.2, 0] [0.3, 0.4, 0.1, 45] [0.3, 0.2, 0.25, 60] [0.25, 0.3, 0.3, -30]"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#5-before-you-leave-the-lab","title":"5. Before you leave the lab","text":"<p>Send yourself the backup/copy of your script and restore the package to its blank version.</p> <p>IMPORTANT: The below command will erase your script from the computer so take a backup of it before you run it</p> <pre><code>cd ~/rosPackages/ENME480_ws/src/enme480_lab_fk\ngit checkout .\n</code></pre>"},{"location":"_labcode/Week%2011%20-%20Inverse%20Kinematics%20Lab/IK_Lab/#submission","title":"Submission","text":"<p>Please create a neatly typed/written report for the lab including the following: 1. Your IK derivation - you can resue the one from Week 8 submission if that was right. If anything changed or you noticed errors in your previous derivation, make a note of it in the report including the reason behind the error. 2. Comparsion table for Step 4. 3. Write a paragraph on the reasons behind discrepancies in measurements and calculations. 4. What are the potential sources of singlularities and how will avoid them when you are implementing the code? If you found any singularities, be sure to list them and discuss possible causes. 5. Code snippet of <code>inverse_kinematics()</code> function that you used.</p>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/","title":"Week 2 - Ubuntu &amp; Python Introduction","text":""},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#overview","title":"Overview","text":"<p>Introduction to Ubuntu environment and Python programming basics for robotics applications.</p>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#materials","title":"Materials","text":"<ul> <li>ENME480 Lab Week 2.pptx - Complete lab presentation with Ubuntu and Python introduction</li> </ul>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#key-topics","title":"Key Topics","text":"<ul> <li>Ubuntu Environment: Linux-based development environment setup</li> <li>Python Basics: Programming fundamentals for robotics</li> <li>Development Tools: Essential software and libraries</li> <li>Environment Configuration: Setting up your development workspace</li> </ul>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#learning-objectives","title":"Learning Objectives","text":"<ul> <li>Understand the Ubuntu operating system</li> <li>Learn basic Python programming concepts</li> <li>Set up development environment for robotics work</li> <li>Familiarize with command-line interface</li> </ul>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic computer literacy</li> <li>No prior programming experience required</li> </ul>"},{"location":"_labcode/Week%202%20-%20Ubuntu%20%26%20Python%20Intro/#next-steps","title":"Next Steps","text":"<p>This foundation will prepare you for ROS (Robot Operating System) work in Week 3.</p>"},{"location":"_labcode/Week%203%20-%20ROS/","title":"Week 3 - Introduction to ROS (Robot Operating System)","text":""},{"location":"_labcode/Week%203%20-%20ROS/#overview","title":"Overview","text":"<p>Introduction to ROS (Robot Operating System), the fundamental framework for robotics development and simulation.</p>"},{"location":"_labcode/Week%203%20-%20ROS/#materials","title":"Materials","text":"<ul> <li>ENME480_IntroToROS.pdf - Comprehensive introduction to ROS concepts and usage</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#key-topics","title":"Key Topics","text":"<ul> <li>ROS Fundamentals: Understanding the Robot Operating System architecture</li> <li>Core Concepts: Nodes, topics, services, and actions</li> <li>Communication: How ROS components communicate with each other</li> <li>Development Workflow: Building and running ROS applications</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#learning-objectives","title":"Learning Objectives","text":"<ul> <li>Understand ROS architecture and philosophy</li> <li>Learn basic ROS concepts (nodes, topics, services)</li> <li>Set up ROS development environment</li> <li>Create simple ROS programs</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#prerequisites","title":"Prerequisites","text":"<ul> <li>Week 2: Ubuntu and Python basics</li> <li>Basic understanding of programming concepts</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#ros-concepts-covered","title":"ROS Concepts Covered","text":"<ul> <li>Nodes: Individual processes that perform computation</li> <li>Topics: Asynchronous communication mechanism</li> <li>Services: Synchronous request-response communication</li> <li>Messages: Data structures for communication</li> <li>Packages: Organizational units for ROS code</li> </ul>"},{"location":"_labcode/Week%203%20-%20ROS/#next-steps","title":"Next Steps","text":"<p>This ROS foundation will enable you to work with Gazebo simulation in Week 4.</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/","title":"Week 4 - Studio 4.1 - Gazebo Demo","text":"<p>The objective of this lab is to install the UR3e packages and have a working simulation of the robot in Gazebo.</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#package-installation","title":"Package Installation","text":"<p>There are two methods to do this:</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#1-source-installation","title":"1. Source Installation","text":"<p>Clone the following repositories in your workspace:</p> <pre><code>git clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Driver.git\ngit clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation.git\n</code></pre> <p>Build and source the workspace</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#2-pre-configured-docker-container","title":"2. Pre-configured Docker Container","text":"<p>Find the Dockerfile in <code>/Resources/Docker Container/humble_dockerfile.Dockerfile</code> and build and run the container. This is the preferred method but it can lead to issues with Gazebo (looking into a foolproof solution - will be updated this week)</p> <pre><code>sudo docker build -t humble_image -f humble_dockerfile.Dockerfile .\nsudo docker run -it humble_image\n</code></pre>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#troubleshooting-no-joint-trajcetory-controller-or-controller-interface","title":"Troubleshooting - no joint trajcetory controller or controller interface","text":"<p>If you run into an issue with building packages due to missing a joint controller run:</p> <pre><code>sudo apt install ros-humble-joint-trajectory-controller\n\nsudo apt install ros-humble-controller-interface\n\nsudo apt install ros-humble-ur-*\n\nsudo apt install ros-humble-control-*\n\nsudo apt install ros-humble-ros2-control-*\n</code></pre>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#troubleshooting-on-macs","title":"Troubleshooting on Macs","text":"<p>Gazebo doesn\u2019t directly support ARM64 architecture. As a result, we need to manually compile and install it.</p> <p>Install necessary dependencies:</p> <pre><code>sudo apt-add-repository ppa:dartsim\n\nsudo apt update\n\nsudo apt install libdart-dev libdart-utils-dev libdart-external-ikfast-dev libsdformat9-dev libfreeimage-dev libprotoc-dev libprotobuf-dev protobuf-compiler freeglut3-dev libcurl4-openssl-dev libtinyxml-dev libtinyxml2-dev libtar-dev libtbb-dev libogre-1.9-dev libxml2-dev pkg-config qtbase5-dev libqwt-qt5-dev libltdl-dev libgts-dev libboost-thread-dev libboost-system-dev libboost-filesystem-dev libboost-program-options-dev libboost-regex-dev libboost-iostreams-dev libsimbody-dev libignition-common3-dev libignition-fuel-tools4-dev libignition-transport8-dev libignition-math6-dev libignition-msgs5-dev\n</code></pre> <ol> <li> <p>Clone the Gazebo source code from GitHub: <pre><code>cd ~/Downloads/\n\ngit clone https://github.com/osrf/gazebo\n</code></pre></p> </li> <li> <p>Modify the line 647 of <code>SearchForStuff.cmake</code> in <code>Downloads/gazebo/cmake</code>. Change from 9.8 to 9.7 as the default libsdformat version of ubuntu22 is 9.7.</p> </li> <li> <p>Compile and install Gazebo:</p> </li> </ol> <pre><code>cd ~/Downloads/gazebo\nmkdir build &amp;&amp; cd build\ncmake ../\nmake -j3\nsudo make install\n</code></pre> <ol> <li>Add Gazebo to your environment path by modifying .bashrc*:</li> </ol> <pre><code>export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\nexport PATH=/usr/local/bin:$PATH\nexport PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH\n</code></pre> <ol> <li>In your workspace, add the <code>gazebo_ros</code> package:</li> </ol> <pre><code>cd ~/enme480_ws/src\ngit clone https://github.com/ros-simulation/gazebo_ros_pkgs\ncd gazebo_ros_pkgs\ngit checkout ros2\ncd ~/enme480_ws/src\ngit clone -b humble https://github.com/ros-controls/gazebo_ros2_control\n</code></pre> <ol> <li>Build and source your workspace</li> </ol>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#running-ur3-demo-on-gazebo","title":"Running UR3 Demo on Gazebo","text":"<p>Launch the UR3e in Gazebo</p> <pre><code>ros2 launch ur_simulation_gazebo ur_sim_control.launch.py\n</code></pre> <p>It should open up two windows with UR3e arm in Gazebo &amp; RViz. </p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#troubleshooting-gazebo-does-not-open-up-waiting-for-controller","title":"Troubleshooting - Gazebo does not open up; waiting for controller","text":"<p>Run the following command in a seperate terminal before launching the previous command (in order to use this method, start and source 3 consoles, run this command, then the one above it then the last command on this page).</p> <pre><code>gazebo -s libgazebo_ros_init.so -s libgazebo_ros_factory.so myworld.world\n</code></pre> <p>To test if the simulation works, run the following command</p> <p><pre><code>ros2 launch ur_robot_driver test_joint_trajectory_controller.launch.py\n</code></pre> This will keep moving the robot continously in multiple positions.</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_1-Gazebo/#assignment","title":"Assignment","text":"<p>Prepare a report answering the following questions and posting relevant screenshots 1. Screenshots of Gazebo &amp; RViz with the UR3 in 3 different positions 2. Show the topics </p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/","title":"Week 4 - Studio 4.2 - Rotation Matrices in Python","text":""},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#overview","title":"Overview","text":"<p>This assignment involves modifying a Python script named <code>studio_4_2.py</code> (located in the this folder) that performs matrix operations using rotation matrices. The task includes defining a function to generate a 3x3 rotation matrix, initializing a specific vector, and calculating the result of matrix multiplications involving two angles.</p>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#requirements","title":"Requirements","text":"<ul> <li>Python 3.x</li> <li>NumPy library</li> </ul>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#instructions","title":"Instructions","text":"<ol> <li>Define a function <code>R(phi)</code>:</li> <li> <p>This function should take an angle <code>\u03c6</code> (phi) as input and generate a 3x3 rotation matrix using the formula:</p> <p>\\(<code>R(\\phi) =   \\begin{bmatrix}  \\cos\\phi &amp; -\\sin\\phi &amp; 0 \\\\  \\sin\\phi &amp; \\cos\\phi &amp; 0 \\\\  0 &amp; 0 &amp; 1  \\end{bmatrix}</code>\\)</p> </li> <li> <p>Define a vector <code>v1</code>:</p> </li> <li> <p>Inside the <code>Test()</code> function, define a 3x1 NumPy array:</p> <p>\\(<code>v_1 =   \\begin{bmatrix}  1 \\\\  0.6 \\\\  0.8  \\end{bmatrix}</code>\\)</p> </li> <li> <p>Calculate the result <code>v2</code>:</p> </li> <li> <p>Use the angles <code>\u03c61 = 0.5</code> and <code>\u03c62 = 0.8</code> to compute the matrix multiplication:</p> <p>\\(<code>v_2 = R(\\phi_2) R(\\phi_1) v_1</code>\\)</p> </li> <li> <p>Run the script:</p> </li> <li> <p>Execute the script from the terminal using:</p> <pre><code>python studio_4_2.py\n</code></pre> </li> <li> <p>The output should display the calculated value of <code>v2</code>.</p> </li> </ol>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#submission","title":"Submission","text":"<ul> <li>Submit a PDF containing your <code>studio_4_2.py</code> script and a screenshot of the terminal output to ELMS.</li> </ul>"},{"location":"_labcode/Week%204%20-%20Gazebo%20%26%20Python/Studio-4_2-Python_RotMat/#notes","title":"Notes","text":"<ul> <li>Ensure that the script runs without errors and outputs the correct <code>v2</code> value.</li> <li>Refer to the rubric on ELMS for grading</li> <li>You will not be assessed if you do not follow the given script format</li> </ul>"},{"location":"_labcode/Week%205%20-%20UR3e%20Intro/UR3eOperation/","title":"Week 5 - UR3e Intro &amp; Operation","text":""},{"location":"_labcode/Week%205%20-%20UR3e%20Intro/UR3eOperation/#objectives","title":"Objectives","text":"<ul> <li>Learn how to use the Pendant</li> <li>Interface UR3e with ROS packages on RAL machines</li> <li>Visualize ROS Processes</li> <li>Use MoveIt to operate the robot</li> </ul>"},{"location":"_labcode/Week%205%20-%20UR3e%20Intro/UR3eOperation/#procedure","title":"Procedure","text":"<ol> <li> <p>You will be shown how to use the pendant</p> </li> <li> <p>Power on the robot</p> </li> <li>Release the brakes</li> <li>Try Freedrive</li> <li>Try Emergency Stop</li> <li>Try setting the joint anngles to moe the robot (Forward Kinematics)</li> <li>Try setting the final end effector position to move the robot (Inverse Kinematics)</li> <li></li> <li> <p>Interfacing the Robot with PC</p> </li> </ol> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li> <p>Follow instructions in the file</p> </li> <li> <p>Visualize ROS Processes</p> </li> <li> <p>Get the list of ROS topics</p> </li> <li>Open up RQT</li> <li>Visualize Node Graphs</li> <li> <p>You will be shown how to generate plots in RQT to analyze data</p> </li> <li> <p>Move the robot using MoveIt</p> </li> <li> <p>Open up the MoveIt node</p> </li> </ul> <pre><code>ros2 launch ur_moveit_config ur_moveit.launch.py ur_type:=ur3e\n</code></pre> <ul> <li>You will be shown how to move the robot using MoveIt</li> </ul>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/","title":"Week 6 - UR3e Forward Kinematics on Gazebo","text":""},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#objectives","title":"Objectives","text":"<ul> <li>Add elements to your Gazebo environment</li> <li>Calculate DH parameters of UR3e</li> <li>Create a publisher to move the robot to desired joint states</li> <li>Find the end effector pose</li> <li>Validate and compare the pose readings from DH-parameter calculation &amp; end effector</li> </ul>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#1-adding-physical-elements-in-gazebo","title":"1. Adding Physical Elements in Gazebo","text":"<p>Your aim is to add a base plate to your Gazebo environment and mount the robot on top of it, and link them.</p> <p>To do so, we modify the Unified Robot Description Format (URDF) file for the environment. This is an XML (Extensible Markup Language) specification. Another commonly known markup language is HTML. The major contrast between XML and HTML is that in addition to diplaying data, XML allows different applications to exchange and store data and its structure in a way that is universally understood. For more info, refer to this link: http://wiki.ros.org/urdf/XML/model</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#step-1-build-the-ur-description-package","title":"Step 1: Build the UR Description Package","text":"<p>This package contains the mesh files and all the description files to simulate the UR robots. Clone the repositiory in your src folder of your workspace</p> <pre><code>git clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Description.git\n</code></pre> <p>Build and source your workspace</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#step-2-modify-the-description-files-to-add-a-plate","title":"Step 2: Modify the Description Files to Add a Plate","text":"<p>Check the <code>urdf</code> folder in the directory. We will be modifying <code>ur.urdf.xacro</code> and creating a duplicate of <code>ur_macro.xacro</code> and rename the copy as <code>enme480_fk.xacro</code>. As to why we are modifying these files, will be explained in the studio session.</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#-changes-in-ururdfxacro","title":"- Changes in <code>ur.urdf.xacro</code> :","text":"<p>Here just change two things:</p> <ul> <li>Replace the main macro file being imported from <code>ur_macro.xacro</code> to <code>enme480_fk.xacro</code></li> <li>The default <code>ur_type</code> value should be <code>ur3e</code> (just to make life easy by making your command shorter)</li> </ul>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#-changes-in-enme480_fkxacro","title":"- Changes in <code>enme480_fk.xacro</code>","text":"<p>Add the following snippet to add the plate mesh to the environment. The code will be explained in class and you have to figure out where to add the snippets. Keep a base plate dimensions of <code>0.3 x 0.3 x 0.01</code></p> <p>Snippet 1: Defining the description of Base Plate</p> <pre><code>   &lt;!-- Define the base plate --&gt;\n   &lt;link name=\"${tf_prefix}base_plate\"&gt;\n     &lt;visual&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt;  &lt;!-- Modify Adjust origin as needed --&gt;\n       &lt;geometry&gt;\n         &lt;box size=\"0 0 0\"/&gt;  &lt;!-- Modify Size of the base plate (length x width x height) --&gt;\n       &lt;/geometry&gt;\n       &lt;material name=\"orange\"/&gt;\n     &lt;/visual&gt;\n     &lt;collision&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt; &lt;!-- Modify this --&gt;\n       &lt;geometry&gt;\n         &lt;box size=\"0 0 0\"/&gt; &lt;!-- Modify this --&gt;\n       &lt;/geometry&gt;\n     &lt;/collision&gt;\n     &lt;inertial&gt;\n       &lt;mass value=\"1.0\"/&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt; &lt;!-- Modify this --&gt;\n       &lt;inertia ixx=\"0.001\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.001\" iyz=\"0.0\" izz=\"0.001\"/&gt;\n     &lt;/inertial&gt;\n   &lt;/link&gt;\n</code></pre> <p>Snippet 2: Defining the relationship between base plate and the robot</p> <p>You will find a code block that defines how the base link connects to the environment. Replace that with the snippet below</p> <pre><code>   &lt;!-- base_joint fixes ..... to the environment  (Find this similar part in the code and replace it) --&gt;\n   &lt;joint name=\"${tf_prefix}base_joint\" type=\"fixed\"&gt;\n     &lt;xacro:insert_block name=\"origin\" /&gt;\n     &lt;parent link=\"${parent}\" /&gt;\n     &lt;child link=\"${tf_prefix}.................\" /&gt; &lt;!-- Modify this --&gt;\n   &lt;/joint&gt;\n\n   &lt;!-- Attach base plate to the robot's base link --&gt;\n   &lt;joint name=\"${tf_prefix}base_to_base_plate\" type=\"fixed\"&gt;\n     &lt;parent link=\"${tf_prefix}............\" /&gt; &lt;!-- Modify this based on the child and parent --&gt;\n     &lt;child link=\"${tf_prefix}.............\" /&gt; &lt;!-- Modify this based on child and parent Hint Check the subsequent code to know the childparent --&gt;\n     &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\"/&gt;  &lt;!-- Adjust origin to place the base plate correctly --&gt;\n   &lt;/joint&gt;\n</code></pre> <p>Try launching the robot simulation to check if the pate is visible and the robot is standing on the plate:</p> <pre><code>ros2 launch ur_simulation_gazebo ur_sim_control.launch.py ur_type:=ur3e\n</code></pre> <p>You can modify the launch file to have <code>ur3e</code> as the default argument so that you don't need to specify it everytime</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#2-dh-parameters-of-ur3e","title":"2. DH Parameters of UR3e","text":"<p>Link for UR3e specifications: https://www.universal-robots.com/media/1807464/ur3e-rgb-fact-sheet-landscape-a4.pdf</p> <p>The PDF for UR3 dimensions is included in the folder for <code>Week 6</code> and the zero configuration (all joint angles are 0) for the robot looks like given in this image</p> <p>You need to create a DH-table for the robot and annotate the given PDF to show the frames and axes used. The unknowns here will be the joint angles. Include the base plate in your calculations as well.</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#3-creating-a-publisher-script-to-move-the-robot","title":"3. Creating a Publisher script to move the robot","text":"<p>(NEW) Bridge packages for custom topics between ur_driver and ENME480 labs</p> <ul> <li>Clone the following repositories into your workspace</li> </ul> <p><pre><code>git clone https://github.com/MarylandRoboticsCenter/ur3e_mrc.git\ngit clone https://github.com/ENME480/ur3e_enme480.git\n</code></pre> - Build and source your workspace.</p> <p>We have a predefined custom message for obtaining position and sending commands:</p> <p>CommandUR3e.msg  <pre><code>float64[] destination\nfloat64 v\nfloat64 a\nbool io_0\n</code></pre> (destination is the set of joint angles <code>[theta1 theta2 theta3 theta4 theta5 theta6]</code>)</p> <p>PositionUR3e.msg <pre><code>float64[] position\nbool is_ready\n</code></pre></p> <p>(position is the set of 6DoF pose of the end effector <code>[x y z roll pitch yaw]</code>)</p> <p>Now run the following command: <pre><code>ros2 launch ur3e_enme480 ur3e_sim_enme480.launch.py\n</code></pre></p> <p>You should be able to see the topics <code>/ur3/position</code> and <code>/ur3/command</code>. Refer to this link for details of the package and its usage.</p> <p>~~Using the topic <code>/joint_trajectory_controller/joint_trajectory</code> and the message type <code>JointTrajectory</code> and <code>JointTrajectoryPoint</code> from <code>trajectory_msgs</code>, create a publisher to move the robot to desired joint angles. Keep in mind that the angles given to th robot sould be in radians but we want to give the input in degrees so ensure that you have converted that.~~</p> <p>Using the topic <code>/ur3/command</code> and the message type <code>CommandUR3e</code> from <code>ur3e_mrc.msg</code>, create a publisher to move the robot to desired joint angles. Keep in mind that the angles given to the robot should be in radians but we want to give the input in degrees so ensure that you have converted that. You can set the velocity and acceleration as <code>1.0</code></p> <p>The second step is to create a function (or multiple functions) in the same Python class to calculate the end effector pose using forward kinematics via DH-parameters, and print that out as the final transformation matrix.</p> <p>Your code will have a structure like this (it can be different but just a baseline)</p> <pre><code>import ....\n\nclass ForwardKinematicsUR3e(...)\n\n  def __init__(self): \n    ...\n    ...\n\n  def move_robot(...):\n    ...\n    ...\n\n  def calculate_fk_from_dh(...):\n    ...\n    ...\n\n\ndef main(...):\n\n  ...\n  ...\n\nif __name__ == '__main__':\n  main()\n</code></pre> <p>Hint: Use the structure from your <code>pubsub</code> codes which you have done previously. ~~You can get the message info for <code>JointTrajectory</code> and <code>JointTrajectoryPoint</code> here: http://docs.ros.org/en/noetic/api/trajectory_msgs/html/msg/JointTrajectory.html &amp; http://docs.ros.org/en/noetic/api/trajectory_msgs/html/msg/JointTrajectoryPoint.html~~</p> <p>Your command should look something like this:</p> <p><pre><code>ros2 run &lt;package_name&gt; ur3e_fk 0 0 0 0 0 0\n</code></pre> where the numbers represent the six joint angles in degrees. Hint: Look into how you can send arguments to a Python script</p> <p>Don't forget to add the node to your <code>setup.py</code> in your package.</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#4-get-the-end-effector-pose-from-ur3position","title":"4. Get the end effector pose from <code>/ur3/position</code>","text":"<p>~~Here you will be using the <code>/tf</code> topic which denotes the transformations in your workspace. The topic publishes the relative transform between all the joints. Your goal is to find the relative transform between the <code>base_plate</code> and the last link on the robot (figure out which is the last link). You will be shown what <code>tf</code> is in class.~~</p> <p>~~Get the relative transform and print the position and orientation. (Hint: There is a tf2 library that will help you to trnasform between frames without needing to do calcuulations.)~~</p> <p>TF (TransForm) calculations are being done on the backend now. You will get the position of the end effector from <code>/ur3/position</code>. </p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#5-compare-the-readings","title":"5. Compare the readings","text":"<p>You need to compare the readings from the DH-parameters method with the actual robot position through <code>/tf</code>. Put that in a table for the following 5 test cases:</p> <p>Set 1: <code>[0 0 0 0 0 0]</code> (robot should be horizontal)</p> <p>Set 2: <code>[0 0 -90 90 0 0]</code></p> <p>Set 3: <code>[0 -45 45 -90 30 90]</code></p> <p>Set 4: <code>[90 -60 30 20 10 50]</code></p> <p>Set 5: <code>[0 -90 0 0 0 0]</code> (robot should be upright)</p>"},{"location":"_labcode/Week%206%20-%20Forward%20Kinematics/Studio-6_1-FK-Gazebo/#submission","title":"Submission","text":"<ol> <li> <p>Show a screenshot of the base plate with the robot </p> </li> <li> <p>Show the DH Table for the robot</p> </li> <li> <p>Show a figure with frames and axes marked</p> </li> <li> <p>For each test case, show:</p> </li> <li> <p>The set of joint angle values (\u03b81, \u03b82, \u03b83, \u03b84, \u03b85, \u03b86)</p> </li> <li>The final transformation matrix (from Python script). You can add it as a readable image of the output window as well.</li> <li>The calculated pose from DH table in simulation vs the pose from <code>/ur3/position</code></li> <li> <p>The scalar error</p> </li> <li> <p>Discuss the sources of error</p> </li> <li> <p>An appendix to show your scripts</p> </li> <li> <p><code>enme480_fk.xacro</code></p> </li> <li>FK publisher (including the Python script for DH transformation)</li> <li>~~<code>tf</code> subscriber~~ Screenshot of messages received from <code>/ur3/position</code></li> </ol> <p>Add everything in one single PDF file and upload it.</p>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/","title":"Week 8 - UR3e Inverse Kinematics on Gazebo","text":""},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#objectives","title":"Objectives","text":"<p>The objective of this lab is to derive and implement a solution to the inverse kinematics problem for the UR3 robot. In this lab we will:</p> <ul> <li>Derive elbow-up inverse kinematic equations for the UR3</li> <li>Write a publisher that moves the UR3 to a point in space specified by the user</li> </ul>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#task-description","title":"Task Description","text":"<p>The joints and links of the UR3 robot are annotated in Figure 1. The goal is to find the rotation angles of the 6 joints <code>(\u03b81, ... , \u03b86)</code>, so that the end-effector (end of Link 10) can reach to a given position <code>(x_grip, y_grip, z_grip)</code> and orientation <code>{\u03b8_yaw, \u03b8_pitch, \u03b8_roll}</code> input by the user. There are many possible solutions to the inverse kinematics problem. To make the derivation manageable, we will only implement one of the elbow-up solution in this lab. <code>\u03b8_pitch</code> and <code>\u03b8_roll</code> of the end-effector are fixed by letting the vacuum gripper aluminum plate (Link 9) always be parallel to the x-y plane of world frame coordinates (i.e., desk plane), and \u03b85 is always equal to \u221290\u00b0. Thus, the user will input the desired position and yaw angle of the end-effector in world frame coordinates <code>(xWgrip, yWgrip, zWgrip, yawWgrip)</code>, and the output of the program should be the joint angles <code>\u03b81 to \u03b86</code>.</p> <p></p>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#solution-steps","title":"Solution Steps","text":"<p>In this section, a suggested solution approach is described.</p> <ol> <li>Establish the world coordinate frame (frame w) centered at the corner of the UR3\u2019s base shown in Figure 2. We will solve the inverse kinematics problem in the base frame (frame 0), so we will convert the coordinates (\ud835\udc65\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d) entered by the user to base frame coordinates (\ud835\udc65\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d). The origin of the base frame is at (-0.15, 0.15, 0.01) in the world frame. Set \ud835\udf035 = \u221290\u00b0 in unit of radian.\"</li> </ol> <p></p> <ol> <li>We will define a \u201cwrist center\u201d as \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b which equals the same desired \ud835\udc67 value of the vacuum gripper, and \ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b are the coordinates of <code>\ud835\udf036</code>\u2019s \ud835\udc67 axis (see Figure 1). Link 9 (gripper plate) has a length of 0.0535 meters from the center line of the gripper to the center line of Joint 6. Given the desired position of the gripper <code>(\ud835\udc65\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d)</code> in the base frame and the yaw angle, find wrist\u2019s center point (\ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b).</li> <li>Given the wrist\u2019s center point (\ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b), find the waist angle \ud835\udf031. Figure 3 shows the top-down view of the robot, which is helpful for formulating the relations.</li> <li>Solve for the value of <code>\ud835\udf036</code>, given \ud835\udf031 and the desired yaw angle (should be converted to radian from the input degree value). \ud835\udf036 = 0 when Link 9 is parallel to Link 4 and Link 6.</li> <li>We will define another virtual point. A projected end point (\ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51) is a point off the UR3 but lies along the Link 6 axis, as shown in Figure 1 and Figure 3. For example, if \ud835\udf031 = 0 then \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51 = 0. If \ud835\udf031 = 90\u00b0 then \ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51 = 0. Use the top-down view (Figure 3) to find \ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51 and \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51 from \ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b. Figure 4 is a side view that is a projection of the robot onto a plane perpendicular to the x-y plane of world frame and rotated by \ud835\udf031 about the base frame. From this figure we can see that \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51 is \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b offset by a constant. The end of the gripper is 0.052m from the center of the gripper plate in the z-axis direction.</li> </ol> <p></p> <p></p> <ol> <li>Find \ud835\udf032, \ud835\udf033 and \ud835\udf034 from the end point (\ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51). In Figure 4, a parallel to the base construction line through Joint 2 and a parallel to the base construction line through Joint 4 are helpful in finding the needed partial angles. \ud835\udf032 and \ud835\udf033 can be found from the geometry, while \ud835\udf034 is determined due to the requirement that Link 7 and Link 9 must be parallel to the x-y plane of the world frame.</li> </ol> <p>Now that your code solves for all the joint variables <code>(\ud835\udf031 to \ud835\udf036)</code>, send these six values to the publisher you created in FK lab to move the robot to those angles so that it gets to the desired position.</p>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#implementation-in-ros2-gazebo","title":"Implementation in ROS2 &amp; Gazebo","text":"<ol> <li>Pull the latest commit for ur3e_enme480 package</li> </ol> <pre><code>cd ~/&lt;your_workspace&gt;/src/ur3e_enme480\ngit pull\n</code></pre> <ol> <li>Download the URDF <code>enme480_ik.xacro</code> (from <code>Code Resources</code> in Week 7 on this page) in your <code>urdf</code> folder. Replace <code>ur.urdf.xacro</code> as well.</li> </ol> <p>Add the <code>UR3SuctionCupMount.stl</code> from <code>Code Resources</code> to your <code>Universal_Robots_ROS2_Description//meshes/ur3/visual/</code> folder.</p> <ol> <li>Create a publisher <code>ur3e_ik_sim.py</code> with node name <code>ur3e_sim_ik_publisher</code>. It will have a structure somewhat like this:</li> </ol> <pre><code>import ....\n\nclass InverseKinematicsUR3e(...)\n\n  def __init__(self): \n    ...\n    ...\n    self.publisher_ = self.create_publisher(CommandUR3e, '/ur3/command', 10)\n    ...\n    ...\n\n  def move_robot(...):\n    ...\n    ...\n\n  def calculate_fk_from_dh(...):\n    ...\n    ...\n\n  def inverse_kinematics(self, xWgrip, yWgrip, zWgrip, yawWgrip):\n\n    # TODO: Function that calculates an elbow up \n    # inverse kinematics solution for the UR3\n\n    # Step 1: find gripper position relative to the base of UR3,\n    # and set theta_5 equal to -pi/2\n\n\n    # Step 2: find x_cen, y_cen, z_cen\n\n\n    # Step 3: find theta_1\n\n\n    # Step 4: find theta_6 \n\n\n    # Step 5: find x3_end, y3_end, z3_end\n\n\n    # Step 6: find theta_2, theta_3, theta_4\n\n    # Return the set of joint angles to move the robot\n\n\ndef main(...):\n\n  ...\n  ...\n\nif __name__ == '__main__':\n  main()\n</code></pre> <p>You command should look like this:</p> <pre><code>ros2 run &lt;package_name&gt; ur3e_sim_ik_publisher &lt;x&gt; &lt;y&gt; &lt;z&gt; &lt;Yaw&gt;\n</code></pre>"},{"location":"_labcode/Week%208%20-%20Inverse%20Kinematics/Studio-8-IK_Gazebo/#test-cases","title":"Test Cases","text":"Test Point Inputs (x, y, z, yaw) IK solution (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) Output from <code>/ur3/position</code> (0.2, 0.3, 0.3, 45) (0.1, 0.4, 0.1, 90) (0.2, 0.2, 0.2, 0) (0.2, -0.2, 0.1, 0) (0.2, 0.3, 0.4, 30) ## Submission <ol> <li>A pdf of your code complete with comments describing the steps you've taken</li> <li>A pdf containing a (neatly) written/typed solution for IK showing how you derived your equations from the geometry</li> <li>Screenshots of UR3e in Gazebo for all test cases</li> <li>A comparison of error between your IK script and the output of the <code>ur3/position</code> topic for the test cases with a discussion of possible error sources.</li> <li>A brief discussion of any possible singularities in the math and what could be done to avoid them (you don't need to implement this, we just want you thinking about strategies!)</li> </ol>"},{"location":"blog/","title":"Announcements","text":"<p>Course updates will appear here (and on Canvas/Piazza). Create new posts by adding dated Markdown files to <code>docs/blog/</code>.</p>"},{"location":"blog/2025-09-01-welcome/","title":"Welcome to ENME480 (FA 2025)","text":"<p>Check the Schedule for weekly topics and labs. The Labs section links to the code submodule. Good luck &amp; have fun!</p>"},{"location":"labs/","title":"\ud83e\uddea Labs Overview","text":"**Your hands-on journey into robotics starts here!**  *Weekly labs combine programming, simulation, and real robot programming*"},{"location":"labs/#lab-structure","title":"\ud83c\udfaf Lab Structure","text":""},{"location":"labs/#two-types-of-sessions","title":"Two Types of Sessions","text":"<ul> <li>\ud83e\uddea Programming Studios (KEB 2111) - Software, simulation, theory</li> <li>\ud83e\udd16 Robot Labs (EAF 3119) - Real robot programming and testing</li> </ul>"},{"location":"labs/#weekly-schedule","title":"Weekly Schedule","text":"<ul> <li>Alternating format - Programming one week, robot work the next</li> <li>Group-based - Work with classmates to solve problems</li> <li>Progressive difficulty - Skills build week by week</li> </ul>"},{"location":"labs/#lab-progression","title":"\ud83d\udcc5 Lab Progression","text":"Week Focus Type Location Key Skills Week 1 Course Intro &amp; Setup Setup KEB 2111 Environment, safety Week 2 Ubuntu &amp; Python Programming KEB 2111 Linux, Python basics Week 3 ROS Introduction Programming KEB 2111 ROS fundamentals Week 4 Gazebo &amp; Python Programming KEB 2111 Simulation, matrices Week 5 UR3e Robot Intro Robot EAF 3119 Robot operation Week 6 Forward Kinematics Programming KEB 2111 DH parameters, FK Week 7 No Lab - - Catch up week Week 8 Inverse Kinematics Programming KEB 2111 IK algorithms Week 9 No Lab - - Catch up week Week 10 FK Lab Robot EAF 3119 Real robot FK Week 11 IK Lab Robot EAF 3119 Real robot IK Week 12-15 Final Project Both Both Vision-enabled pick &amp; place"},{"location":"labs/#getting-started-with-labs","title":"\ud83d\ude80 Getting Started with Labs","text":""},{"location":"labs/#before-your-first-lab","title":"Before Your First Lab","text":"<ol> <li>\u2705 Complete safety training (required for robot access)</li> <li>\ud83d\udcbb Set up Ubuntu environment on your laptop</li> <li>\ud83d\udc0d Install Python and basic packages</li> <li>\ud83d\udcda Read pre-lab materials for the week</li> <li>\ud83d\udd27 Bring laptop with required software</li> </ol>"},{"location":"labs/#what-to-expect-each-week","title":"What to Expect Each Week","text":"<ul> <li>Pre-lab reading - understand concepts before arriving</li> <li>In-lab exercises - hands-on problem solving</li> <li>Group collaboration - work with classmates</li> <li>TA support - help available during lab time</li> <li>Post-lab work - complete any unfinished exercises</li> </ul>"},{"location":"labs/#lab-locations","title":"\ud83c\udfe2 Lab Locations","text":""},{"location":"labs/#keb-2111-programming-studio","title":"KEB 2111 - Programming Studio","text":"<ul> <li>Building: KEB (Kim Engineering Building)</li> <li>Room: 2111</li> <li>Equipment: Computers, software, simulation tools</li> <li>Activities: Programming, theory, simulation</li> </ul>"},{"location":"labs/#eaf-3119-robot-lab","title":"EAF 3119 - Robot Lab","text":"<ul> <li>Building: EAF (Engineering Annex F)</li> <li>Room: 3119</li> <li>Equipment: UR3e robots, safety equipment, tools</li> <li>Activities: Real robot programming, testing</li> </ul>"},{"location":"labs/#lab-requirements","title":"\ud83d\udccb Lab Requirements","text":""},{"location":"labs/#equipment-needed","title":"Equipment Needed","text":"<ul> <li>Laptop with Ubuntu installed</li> <li>USB drive for Ubuntu boot (if needed)</li> <li>Safety gear (provided in robot lab)</li> <li>Notebook for taking notes</li> </ul>"},{"location":"labs/#software-requirements","title":"Software Requirements","text":"<ul> <li>Ubuntu 20.04 or later</li> <li>Python 3.8+ with key packages</li> <li>ROS Noetic (Robot Operating System)</li> <li>Gazebo simulation environment</li> <li>Git for version control</li> </ul>"},{"location":"labs/#lab-learning-objectives","title":"\ud83c\udf93 Lab Learning Objectives","text":""},{"location":"labs/#technical-skills","title":"Technical Skills","text":"<ul> <li>Programming: Python, ROS, simulation</li> <li>Robotics: Kinematics, control, planning</li> <li>Simulation: Gazebo, virtual testing</li> <li>Hardware: Robot operation, safety</li> </ul>"},{"location":"labs/#professional-skills","title":"Professional Skills","text":"<ul> <li>Problem solving - tackle complex robotics challenges</li> <li>Collaboration - work effectively in teams</li> <li>Documentation - record your work and findings</li> <li>Time management - complete labs efficiently</li> </ul>"},{"location":"labs/#lab-materials","title":"\ud83d\udcda Lab Materials","text":""},{"location":"labs/#where-to-find-materials","title":"Where to Find Materials","text":"<ul> <li>This website - weekly lab pages with instructions</li> <li>Lab-Code repository - all code, files, and resources</li> <li>Canvas - assignments, due dates, submissions</li> <li>Piazza - discussions, questions, clarifications</li> </ul>"},{"location":"labs/#lab-code-organization","title":"Lab Code Organization","text":"<pre><code>labs/Lab-Code/\n\u251c\u2500\u2500 Week 1 Materials/          # Course intro\n\u251c\u2500\u2500 Week 2 - Ubuntu &amp; Python/  # Environment setup\n\u251c\u2500\u2500 Week 3 - ROS/              # ROS introduction\n\u251c\u2500\u2500 Week 4 - Gazebo &amp; Python/  # Simulation basics\n\u251c\u2500\u2500 Week 5 - UR3e Intro/       # Robot operation\n\u251c\u2500\u2500 Week 6 - Forward Kinematics/ # FK concepts\n\u251c\u2500\u2500 Week 8 - Inverse Kinematics/ # IK algorithms\n\u251c\u2500\u2500 Week 10 - Forward Kinematics Lab/ # Real robot FK\n\u251c\u2500\u2500 Week 11 - Inverse Kinematics Lab/ # Real robot IK\n\u2514\u2500\u2500 Final Project/              # End-of-semester project\n</code></pre>"},{"location":"labs/#lab-support","title":"\ud83c\udd98 Lab Support","text":""},{"location":"labs/#during-lab","title":"During Lab","text":"<ul> <li>Teaching Assistant - available for technical help</li> <li>Instructor - available for concept questions</li> <li>Peers - collaborate with classmates</li> <li>Documentation - use provided resources</li> </ul>"},{"location":"labs/#outside-lab-hours","title":"Outside Lab Hours","text":"<ul> <li>Office hours - get help from TA or instructor</li> <li>Piazza - ask questions and help others</li> <li>Course website - review materials and instructions</li> <li>Lab-Code repository - access all materials anytime</li> </ul>"},{"location":"labs/#lab-success-tips","title":"\ud83c\udfc6 Lab Success Tips","text":""},{"location":"labs/#before-lab","title":"Before Lab","text":"<ul> <li>Read materials thoroughly</li> <li>Set up environment at home first</li> <li>Prepare questions you want to ask</li> <li>Arrive early to get settled</li> </ul>"},{"location":"labs/#during-lab_1","title":"During Lab","text":"<ul> <li>Start early - don't wait for others</li> <li>Ask questions when you're stuck</li> <li>Help classmates - teaching reinforces learning</li> <li>Document everything - notes help with post-lab work</li> </ul>"},{"location":"labs/#after-lab","title":"After Lab","text":"<ul> <li>Complete exercises you didn't finish</li> <li>Review concepts that were unclear</li> <li>Prepare for next week - stay ahead</li> <li>Submit deliverables on time</li> </ul>"},{"location":"labs/#quick-navigation","title":"\ud83d\udd17 Quick Navigation","text":"**Ready to start building robots? Choose your week below! \ud83d\ude80**  [\ud83d\udccb Week 1 - Intro](week-01.md){ .md-button .md-button--primary } [\ud83d\udc27 Week 2 - Setup](week-02.md){ .md-button } [\ud83d\udd27 Week 3 - ROS](week-03.md){ .md-button } [\ud83c\udfae Week 4 - Gazebo](week-04.md){ .md-button } [\ud83e\udd16 Week 5 - Robot](week-05.md){ .md-button }   <p>Last updated: Fall 2025 \u2022 Back to Home</p>"},{"location":"labs/#current-week","title":"Current Week","text":"<ul> <li>Week 1 - Course Introduction</li> <li>Week 2 - Ubuntu &amp; Python</li> <li>Week 3 - ROS Basics</li> </ul>"},{"location":"labs/#key-resources","title":"Key Resources","text":"<ul> <li>Safety Guidelines</li> <li>Lab Policies</li> <li>Help &amp; Support</li> <li>Course Schedule</li> </ul>"},{"location":"labs/final-project/","title":"Final Project \u2014 Vision-Enabled Pick &amp; Place","text":"<p>Build a pipeline to detect blocks on a table, move UR3e to them, grasp, and stack into a tower. Team-based; submit write-up + demo video.</p> <ul> <li>\ud83d\udcc1 Repo folder: <code>labs/Lab-Code/Final Project/</code></li> </ul>"},{"location":"labs/final-project/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/final-project/#enme480-final-project-pick-and-place-task-using-ur3e","title":"ENME480 Final Project - Pick and Place Task using UR3e","text":""},{"location":"labs/final-project/#objective","title":"Objective","text":"<p>The objective of this project is to control the UR3e to move (at least) three AR-tagged blocks to desired positions using camera image as inputs. We will use OpenCV for processing the image data. The program will also integrate the functions of previous lab assignments. The major objectives are the following - Use OpenCV functions to find the centroid of each block - Convert the pixel coordinates in an image to coordinates in the world frame using a perspective matrix - Move the blocks from the detected positions to predefined desired positions</p>"},{"location":"labs/final-project/#task-description","title":"Task Description","text":"<p>The lab environment is shown below:</p> <p></p> <p>You will be given 3 blocks with different Aruco markers. Your task is to move them out of the workspace into predefined positions. To do so, you will need to find the centroid postion of the top side of each block with an image from the camera mounted above the table, facing down on the workspace. You will convert the detected pixel coordinates to the table frame using a persepctive transform. Then using your inverse kinematics solution, you will pick up the block using a suction gripper mounted at the end effector. Your task is to place each block at a specific location outside the workspace.</p>"},{"location":"labs/final-project/#overview-of-the-ros-package","title":"Overview of the ROS Package","text":"<p>The project package should be located on the local lab machines in RAL. You can also find the package with redacted scripts here: https://github.com/ENME480/enme480_project.</p> <p>The nodes have been added to the <code>setup.py</code> file, so you do not need to add that. You will find five scripts as listed in the table below:</p> Script Name Description <code>get_perspective_warping_with_aruco.py</code> Script to create the perspective matrix <code>aruco_detection_test.py</code> Script to test the perspective transform and get coordinates of the blocks in table frame <code>block_detection_aruco.py</code> ROS Node for detecting blocks, uses the same function and changes from <code>aruco_detection_test.py</code> <code>kinematic_functions.py</code> Script to insert all of your FK and IK functions from previous labs <code>main_pipeline.py</code> The main pipeline to strategize and sequence movement of the blocks <p>Please do not edit anything outside the given code snippets (it will lead to errors which will be difficult to identify)</p>"},{"location":"labs/final-project/#procedure-for-setup-in-ral","title":"Procedure for Setup in RAL","text":"<p>Please follow the following steps before you start editing the scripts on RAL machines</p> <ol> <li> <p>UR3e Setup</p> <ul> <li>Power on the robot</li> <li>Release the brakes</li> </ul> </li> <li> <p>Restore the package to original form and pull the latest version</p> </li> </ol> <pre><code>cd rosPackages/ENME480_ws/src/enme480_project\ngit checkout .\ngit pull\n</code></pre> <ol> <li>Interfacing the Robot with PC</li> </ol> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS</li> </ul>"},{"location":"labs/final-project/#script-descriptions","title":"Script Descriptions","text":"<p>You are recommended to complete each script in the order suggested in the table. </p>"},{"location":"labs/final-project/#get_perspective_warping_with_arucopy","title":"<code>get_perspective_warping_with_aruco.py</code>","text":"<p>This script will generate a perspective matrix for the camera to table frame. You need to edit one line to input the reference points on the table. Ensure that you are entering the values in <code>mm</code>. This script will generate a <code>perspective_matrix.npy</code> file in the folder.</p> <p>Before you run this script, ensure that you are in the correct directory. Assuming you have already entered the docker container, run</p> <pre><code>cd ENME480_ws/src/enme480_project/enme480_project/\npython3 get_perspective_warping_with_aruco.py\n</code></pre>"},{"location":"labs/final-project/#troubleshooting","title":"Troubleshooting:","text":"<p>If you get a missing keyboard package error run the following command</p> <pre><code>pip install keyboard\n</code></pre> <p>Once run, you will see a window with the live camera feed. Click on the reference points in the same order that you have listed in your script. It will calulate the perspective transform and a new window will pop-up showing a blue dot at <code>(175,175)</code> on the table coordinate frame. If this is right, you can proceed to the next script.</p>"},{"location":"labs/final-project/#aruco_detection_testpy","title":"<code>aruco_detection_test.py</code>","text":"<p>This script will give you a live detection of the aruco markers and their location w.r.t the table frame in real-time. You need to modify the <code>image_frame_to_table_frame()</code> function in the script. Use the math from prespective transforms to do the same. You can find a file discussing perspective transforms in the main folder on this repository.</p>"},{"location":"labs/final-project/#block_detection_arucopy","title":"<code>block_detection_aruco.py</code>","text":"<p>This is the ROS node and a Python class for all the functions in the <code>aruco_detection_test.py</code> script. If your <code>aruco_detection_test.py</code> could detect the block coordinates correctly, please copy the same function to the snippet for <code>image_frame_to_table_frame()</code> function in this script as well.</p> <p>You can test this script by running the following commands:</p> <ul> <li>In a new terminal in the docker container, launch the camera node:</li> </ul> <pre><code>ros2 launch usb_cam camera.launch.py\n</code></pre>"},{"location":"labs/final-project/#troubleshooting_1","title":"Troubleshooting:","text":"<p>If you get a Pydantic error run the following command</p> <pre><code>sudo pip install pydantic==1.10.9\n</code></pre> <p>Once the camera node is up and running, run the following command in a seperate terminal:</p> <pre><code>ros2 run enme480_project aruco_tracker\n</code></pre> <p>It will publish data under two topics <code>/aruco_detection/image</code> and <code>/aruco_detection/positions</code></p> <p>You can view the image using </p> <pre><code>ros2 run rqt_image_view rqt_image_view\n</code></pre> <p>and it should show the same image in the window as the one you saw with <code>aruco_detection_test.py</code>, once you select the topic.</p>"},{"location":"labs/final-project/#kinematic_functionspy","title":"<code>kinematic_functions.py</code>","text":"<p>This script will use your functions from previous labs and if you have the script working correctly for your FK and IK labs, you can copy the exact same functions here under the functions <code>calculate_dh_transform()</code> and <code>inverse_kinematics()</code> within the given snippets. We need to verify if your IK script is working correctly so please call the TAs over top show your final IK code working before you copy this.</p>"},{"location":"labs/final-project/#main_pipelinepy","title":"<code>main_pipeline.py</code>","text":"<p>This script is where you will sequence and startegize the pick and place process. In this script, you have to edit the following functions:</p> <ol> <li> <p><code>move_arm()</code></p> <p>This function will take in the desired joint positions and publish them using the message data structure given in code comments</p> </li> <li> <p><code>gripper_control()</code></p> <p>This function will take in the desired state of the gripper and publish it using the message data structure given in code comments</p> </li> <li> <p><code>move_block()</code></p> <p>Here, you need to work on giving the sequence of positions you want the block to move to for moving a block from an initial position to a final position. Keep in mind that every block needs to be picked up, raised up and then moved. Do not give it a sequence to drag it accross the table.</p> </li> <li> <p><code>process_blocks()</code></p> <p>This function is where you will enter the startegy and sorting method to place the blocks in their desired positions given their IDs, pre-defined destinations.</p> </li> </ol> <p>Once everything is ready, call the TAs over before you execute the node</p> <pre><code>ros2 run enme480_project main_pipeline\n</code></pre>"},{"location":"labs/final-project/#submission-requirements","title":"Submission Requirements","text":"<p>One single PDF containing the following:</p> <ul> <li>Pseudo code for detecting and moving the block  (no specific format to be followed)</li> <li>Math for camera frame to table frame (your intuition behind the perspective warping, and transformation from camera frame to image frame)</li> <li>Video of pick and place task on UR3e (as a link (GDrive/YouTube) in the report)</li> <li>Extra Credit: Stacking (3.33 pts per block) - Max 10pts possible </li> </ul>"},{"location":"labs/week-01/","title":"Week 01 \u2014 Lab Intro","text":"<p>Focus: course/lab onboarding, environments, safety overview, space orientation (KEB 2111 &amp; EAF 3119).</p> <ul> <li>\ud83d\udcc1 Lab materials (if present): <code>labs/Lab-Code/Week 1 Materials/</code></li> <li>\u2705 Deliverables:</li> <li>confirm environment + accounts</li> <li>complete safety training checkpoint (details in Canvas/Piazza)</li> <li>lab survey: go.umd.edu/ENME480-25-Survey</li> <li>\ud83e\udded Rooms: programming in KEB 2111; robot lab in EAF 3119.</li> </ul>"},{"location":"labs/week-01/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-01/#week-1-lab-introduction","title":"Week 1 - Lab Introduction","text":""},{"location":"labs/week-01/#overview","title":"Overview","text":"<p>Course/lab onboarding, environments, safety overview, space orientation (KEB 2111 &amp; EAF 3119).</p>"},{"location":"labs/week-01/#materials","title":"Materials","text":"<ul> <li>ENME480 Lab 1.pptx - Complete lab presentation with course overview</li> </ul>"},{"location":"labs/week-01/#key-topics","title":"Key Topics","text":"<ul> <li>Environment Setup: Course and lab environment configuration</li> <li>Safety Training: Essential safety protocols and training requirements</li> <li>Space Orientation: Understanding lab spaces and equipment locations</li> <li>Course Structure: Overview of ENME480 robotics course</li> </ul>"},{"location":"labs/week-01/#deliverables","title":"Deliverables","text":"<ul> <li>Confirm environment setup and accounts</li> <li>Complete safety training checkpoint (details in Canvas/Piazza)</li> <li>Familiarize with lab spaces</li> </ul>"},{"location":"labs/week-01/#lab-locations","title":"Lab Locations","text":"<ul> <li>Programming Lab: KEB 2111</li> <li>Robot Lab: EAF 3119</li> </ul>"},{"location":"labs/week-01/#next-steps","title":"Next Steps","text":"<p>After completing this introduction, you'll be ready to begin hands-on robotics work in subsequent weeks.</p>"},{"location":"labs/week-02/","title":"Week 02 \u2014 RAL Intro &amp; Setup / Ubuntu + Python Intro","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 2 - Ubuntu &amp; Python Intro/</code></li> </ul>"},{"location":"labs/week-02/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-02/#week-2-ubuntu-python-introduction","title":"Week 2 - Ubuntu &amp; Python Introduction","text":""},{"location":"labs/week-02/#overview","title":"Overview","text":"<p>Introduction to Ubuntu environment and Python programming basics for robotics applications.</p>"},{"location":"labs/week-02/#materials","title":"Materials","text":"<ul> <li>ENME480 Lab Week 2.pptx - Complete lab presentation with Ubuntu and Python introduction</li> </ul>"},{"location":"labs/week-02/#key-topics","title":"Key Topics","text":"<ul> <li>Ubuntu Environment: Linux-based development environment setup</li> <li>Python Basics: Programming fundamentals for robotics</li> <li>Development Tools: Essential software and libraries</li> <li>Environment Configuration: Setting up your development workspace</li> </ul>"},{"location":"labs/week-02/#learning-objectives","title":"Learning Objectives","text":"<ul> <li>Understand the Ubuntu operating system</li> <li>Learn basic Python programming concepts</li> <li>Set up development environment for robotics work</li> <li>Familiarize with command-line interface</li> </ul>"},{"location":"labs/week-02/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic computer literacy</li> <li>No prior programming experience required</li> </ul>"},{"location":"labs/week-02/#next-steps","title":"Next Steps","text":"<p>This foundation will prepare you for ROS (Robot Operating System) work in Week 3.</p>"},{"location":"labs/week-03/","title":"Week 03 \u2014 Python + ROS Intro (Studio 1)","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 3 - ROS/</code></li> </ul>"},{"location":"labs/week-03/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-03/#week-3-introduction-to-ros-robot-operating-system","title":"Week 3 - Introduction to ROS (Robot Operating System)","text":""},{"location":"labs/week-03/#overview","title":"Overview","text":"<p>Introduction to ROS (Robot Operating System), the fundamental framework for robotics development and simulation.</p>"},{"location":"labs/week-03/#materials","title":"Materials","text":"<ul> <li>ENME480_IntroToROS.pdf - Comprehensive introduction to ROS concepts and usage</li> </ul>"},{"location":"labs/week-03/#key-topics","title":"Key Topics","text":"<ul> <li>ROS Fundamentals: Understanding the Robot Operating System architecture</li> <li>Core Concepts: Nodes, topics, services, and actions</li> <li>Communication: How ROS components communicate with each other</li> <li>Development Workflow: Building and running ROS applications</li> </ul>"},{"location":"labs/week-03/#learning-objectives","title":"Learning Objectives","text":"<ul> <li>Understand ROS architecture and philosophy</li> <li>Learn basic ROS concepts (nodes, topics, services)</li> <li>Set up ROS development environment</li> <li>Create simple ROS programs</li> </ul>"},{"location":"labs/week-03/#prerequisites","title":"Prerequisites","text":"<ul> <li>Week 2: Ubuntu and Python basics</li> <li>Basic understanding of programming concepts</li> </ul>"},{"location":"labs/week-03/#ros-concepts-covered","title":"ROS Concepts Covered","text":"<ul> <li>Nodes: Individual processes that perform computation</li> <li>Topics: Asynchronous communication mechanism</li> <li>Services: Synchronous request-response communication</li> <li>Messages: Data structures for communication</li> <li>Packages: Organizational units for ROS code</li> </ul>"},{"location":"labs/week-03/#next-steps","title":"Next Steps","text":"<p>This ROS foundation will enable you to work with Gazebo simulation in Week 4.</p>"},{"location":"labs/week-04/","title":"Week 04 \u2014 Gazebo Demo (Studio 2)","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 4 - Gazebo &amp; Python/</code></li> </ul>"},{"location":"labs/week-04/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-04/#week-4-studio-41-gazebo-demo","title":"Week 4 - Studio 4.1 - Gazebo Demo","text":"<p>The objective of this lab is to install the UR3e packages and have a working simulation of the robot in Gazebo.</p>"},{"location":"labs/week-04/#package-installation","title":"Package Installation","text":"<p>There are two methods to do this:</p>"},{"location":"labs/week-04/#1-source-installation","title":"1. Source Installation","text":"<p>Clone the following repositories in your workspace:</p> <pre><code>git clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Driver.git\ngit clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation.git\n</code></pre> <p>Build and source the workspace</p>"},{"location":"labs/week-04/#2-pre-configured-docker-container","title":"2. Pre-configured Docker Container","text":"<p>Find the Dockerfile in <code>/Resources/Docker Container/humble_dockerfile.Dockerfile</code> and build and run the container. This is the preferred method but it can lead to issues with Gazebo (looking into a foolproof solution - will be updated this week)</p> <pre><code>sudo docker build -t humble_image -f humble_dockerfile.Dockerfile .\nsudo docker run -it humble_image\n</code></pre>"},{"location":"labs/week-04/#troubleshooting-no-joint-trajcetory-controller-or-controller-interface","title":"Troubleshooting - no joint trajcetory controller or controller interface","text":"<p>If you run into an issue with building packages due to missing a joint controller run:</p> <pre><code>sudo apt install ros-humble-joint-trajectory-controller\n\nsudo apt install ros-humble-controller-interface\n\nsudo apt install ros-humble-ur-*\n\nsudo apt install ros-humble-control-*\n\nsudo apt install ros-humble-ros2-control-*\n</code></pre>"},{"location":"labs/week-04/#troubleshooting-on-macs","title":"Troubleshooting on Macs","text":"<p>Gazebo doesn\u2019t directly support ARM64 architecture. As a result, we need to manually compile and install it.</p> <p>Install necessary dependencies:</p> <pre><code>sudo apt-add-repository ppa:dartsim\n\nsudo apt update\n\nsudo apt install libdart-dev libdart-utils-dev libdart-external-ikfast-dev libsdformat9-dev libfreeimage-dev libprotoc-dev libprotobuf-dev protobuf-compiler freeglut3-dev libcurl4-openssl-dev libtinyxml-dev libtinyxml2-dev libtar-dev libtbb-dev libogre-1.9-dev libxml2-dev pkg-config qtbase5-dev libqwt-qt5-dev libltdl-dev libgts-dev libboost-thread-dev libboost-system-dev libboost-filesystem-dev libboost-program-options-dev libboost-regex-dev libboost-iostreams-dev libsimbody-dev libignition-common3-dev libignition-fuel-tools4-dev libignition-transport8-dev libignition-math6-dev libignition-msgs5-dev\n</code></pre> <ol> <li> <p>Clone the Gazebo source code from GitHub: <pre><code>cd ~/Downloads/\n\ngit clone https://github.com/osrf/gazebo\n</code></pre></p> </li> <li> <p>Modify the line 647 of <code>SearchForStuff.cmake</code> in <code>Downloads/gazebo/cmake</code>. Change from 9.8 to 9.7 as the default libsdformat version of ubuntu22 is 9.7.</p> </li> <li> <p>Compile and install Gazebo:</p> </li> </ol> <pre><code>cd ~/Downloads/gazebo\nmkdir build &amp;&amp; cd build\ncmake ../\nmake -j3\nsudo make install\n</code></pre> <ol> <li>Add Gazebo to your environment path by modifying .bashrc*:</li> </ol> <pre><code>export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\nexport PATH=/usr/local/bin:$PATH\nexport PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH\n</code></pre> <ol> <li>In your workspace, add the <code>gazebo_ros</code> package:</li> </ol> <pre><code>cd ~/enme480_ws/src\ngit clone https://github.com/ros-simulation/gazebo_ros_pkgs\ncd gazebo_ros_pkgs\ngit checkout ros2\ncd ~/enme480_ws/src\ngit clone -b humble https://github.com/ros-controls/gazebo_ros2_control\n</code></pre> <ol> <li>Build and source your workspace</li> </ol>"},{"location":"labs/week-04/#running-ur3-demo-on-gazebo","title":"Running UR3 Demo on Gazebo","text":"<p>Launch the UR3e in Gazebo</p> <pre><code>ros2 launch ur_simulation_gazebo ur_sim_control.launch.py\n</code></pre> <p>It should open up two windows with UR3e arm in Gazebo &amp; RViz. </p>"},{"location":"labs/week-04/#troubleshooting-gazebo-does-not-open-up-waiting-for-controller","title":"Troubleshooting - Gazebo does not open up; waiting for controller","text":"<p>Run the following command in a seperate terminal before launching the previous command (in order to use this method, start and source 3 consoles, run this command, then the one above it then the last command on this page).</p> <pre><code>gazebo -s libgazebo_ros_init.so -s libgazebo_ros_factory.so myworld.world\n</code></pre> <p>To test if the simulation works, run the following command</p> <p><pre><code>ros2 launch ur_robot_driver test_joint_trajectory_controller.launch.py\n</code></pre> This will keep moving the robot continously in multiple positions.</p>"},{"location":"labs/week-04/#assignment","title":"Assignment","text":"<p>Prepare a report answering the following questions and posting relevant screenshots 1. Screenshots of Gazebo &amp; RViz with the UR3 in 3 different positions 2. Show the topics </p>"},{"location":"labs/week-05/","title":"Week 05 \u2014 Forward Kinematics Lab 1.1","text":"<ul> <li>\ud83d\udcc1 Possibly relevant: <code>labs/Lab-Code/Week 5 - UR3e Intro/</code> and <code>labs/Lab-Code/Week 6 - Forward Kinematics/</code></li> </ul>"},{"location":"labs/week-05/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-05/#week-5-ur3e-intro-operation","title":"Week 5 - UR3e Intro &amp; Operation","text":""},{"location":"labs/week-05/#objectives","title":"Objectives","text":"<ul> <li>Learn how to use the Pendant</li> <li>Interface UR3e with ROS packages on RAL machines</li> <li>Visualize ROS Processes</li> <li>Use MoveIt to operate the robot</li> </ul>"},{"location":"labs/week-05/#procedure","title":"Procedure","text":"<ol> <li> <p>You will be shown how to use the pendant</p> </li> <li> <p>Power on the robot</p> </li> <li>Release the brakes</li> <li>Try Freedrive</li> <li>Try Emergency Stop</li> <li>Try setting the joint anngles to moe the robot (Forward Kinematics)</li> <li>Try setting the final end effector position to move the robot (Inverse Kinematics)</li> <li></li> <li> <p>Interfacing the Robot with PC</p> </li> </ol> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li> <p>Follow instructions in the file</p> </li> <li> <p>Visualize ROS Processes</p> </li> <li> <p>Get the list of ROS topics</p> </li> <li>Open up RQT</li> <li>Visualize Node Graphs</li> <li> <p>You will be shown how to generate plots in RQT to analyze data</p> </li> <li> <p>Move the robot using MoveIt</p> </li> <li> <p>Open up the MoveIt node</p> </li> </ul> <pre><code>ros2 launch ur_moveit_config ur_moveit.launch.py ur_type:=ur3e\n</code></pre> <ul> <li>You will be shown how to move the robot using MoveIt</li> </ul>"},{"location":"labs/week-06/","title":"Week 06 \u2014 Forward Kinematics Lab 1.2","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 6 - Forward Kinematics/</code></li> </ul>"},{"location":"labs/week-06/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-06/#week-6-ur3e-forward-kinematics-on-gazebo","title":"Week 6 - UR3e Forward Kinematics on Gazebo","text":""},{"location":"labs/week-06/#objectives","title":"Objectives","text":"<ul> <li>Add elements to your Gazebo environment</li> <li>Calculate DH parameters of UR3e</li> <li>Create a publisher to move the robot to desired joint states</li> <li>Find the end effector pose</li> <li>Validate and compare the pose readings from DH-parameter calculation &amp; end effector</li> </ul>"},{"location":"labs/week-06/#1-adding-physical-elements-in-gazebo","title":"1. Adding Physical Elements in Gazebo","text":"<p>Your aim is to add a base plate to your Gazebo environment and mount the robot on top of it, and link them.</p> <p>To do so, we modify the Unified Robot Description Format (URDF) file for the environment. This is an XML (Extensible Markup Language) specification. Another commonly known markup language is HTML. The major contrast between XML and HTML is that in addition to diplaying data, XML allows different applications to exchange and store data and its structure in a way that is universally understood. For more info, refer to this link: http://wiki.ros.org/urdf/XML/model</p>"},{"location":"labs/week-06/#step-1-build-the-ur-description-package","title":"Step 1: Build the UR Description Package","text":"<p>This package contains the mesh files and all the description files to simulate the UR robots. Clone the repositiory in your src folder of your workspace</p> <pre><code>git clone -b humble https://github.com/UniversalRobots/Universal_Robots_ROS2_Description.git\n</code></pre> <p>Build and source your workspace</p>"},{"location":"labs/week-06/#step-2-modify-the-description-files-to-add-a-plate","title":"Step 2: Modify the Description Files to Add a Plate","text":"<p>Check the <code>urdf</code> folder in the directory. We will be modifying <code>ur.urdf.xacro</code> and creating a duplicate of <code>ur_macro.xacro</code> and rename the copy as <code>enme480_fk.xacro</code>. As to why we are modifying these files, will be explained in the studio session.</p>"},{"location":"labs/week-06/#-changes-in-ururdfxacro","title":"- Changes in <code>ur.urdf.xacro</code> :","text":"<p>Here just change two things:</p> <ul> <li>Replace the main macro file being imported from <code>ur_macro.xacro</code> to <code>enme480_fk.xacro</code></li> <li>The default <code>ur_type</code> value should be <code>ur3e</code> (just to make life easy by making your command shorter)</li> </ul>"},{"location":"labs/week-06/#-changes-in-enme480_fkxacro","title":"- Changes in <code>enme480_fk.xacro</code>","text":"<p>Add the following snippet to add the plate mesh to the environment. The code will be explained in class and you have to figure out where to add the snippets. Keep a base plate dimensions of <code>0.3 x 0.3 x 0.01</code></p> <p>Snippet 1: Defining the description of Base Plate</p> <pre><code>   &lt;!-- Define the base plate --&gt;\n   &lt;link name=\"${tf_prefix}base_plate\"&gt;\n     &lt;visual&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt;  &lt;!-- Modify Adjust origin as needed --&gt;\n       &lt;geometry&gt;\n         &lt;box size=\"0 0 0\"/&gt;  &lt;!-- Modify Size of the base plate (length x width x height) --&gt;\n       &lt;/geometry&gt;\n       &lt;material name=\"orange\"/&gt;\n     &lt;/visual&gt;\n     &lt;collision&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt; &lt;!-- Modify this --&gt;\n       &lt;geometry&gt;\n         &lt;box size=\"0 0 0\"/&gt; &lt;!-- Modify this --&gt;\n       &lt;/geometry&gt;\n     &lt;/collision&gt;\n     &lt;inertial&gt;\n       &lt;mass value=\"1.0\"/&gt;\n       &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\" /&gt; &lt;!-- Modify this --&gt;\n       &lt;inertia ixx=\"0.001\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.001\" iyz=\"0.0\" izz=\"0.001\"/&gt;\n     &lt;/inertial&gt;\n   &lt;/link&gt;\n</code></pre> <p>Snippet 2: Defining the relationship between base plate and the robot</p> <p>You will find a code block that defines how the base link connects to the environment. Replace that with the snippet below</p> <pre><code>   &lt;!-- base_joint fixes ..... to the environment  (Find this similar part in the code and replace it) --&gt;\n   &lt;joint name=\"${tf_prefix}base_joint\" type=\"fixed\"&gt;\n     &lt;xacro:insert_block name=\"origin\" /&gt;\n     &lt;parent link=\"${parent}\" /&gt;\n     &lt;child link=\"${tf_prefix}.................\" /&gt; &lt;!-- Modify this --&gt;\n   &lt;/joint&gt;\n\n   &lt;!-- Attach base plate to the robot's base link --&gt;\n   &lt;joint name=\"${tf_prefix}base_to_base_plate\" type=\"fixed\"&gt;\n     &lt;parent link=\"${tf_prefix}............\" /&gt; &lt;!-- Modify this based on the child and parent --&gt;\n     &lt;child link=\"${tf_prefix}.............\" /&gt; &lt;!-- Modify this based on child and parent Hint Check the subsequent code to know the childparent --&gt;\n     &lt;origin xyz=\"0 0 0\" rpy=\"0 0 0\"/&gt;  &lt;!-- Adjust origin to place the base plate correctly --&gt;\n   &lt;/joint&gt;\n</code></pre> <p>Try launching the robot simulation to check if the pate is visible and the robot is standing on the plate:</p> <pre><code>ros2 launch ur_simulation_gazebo ur_sim_control.launch.py ur_type:=ur3e\n</code></pre> <p>You can modify the launch file to have <code>ur3e</code> as the default argument so that you don't need to specify it everytime</p>"},{"location":"labs/week-06/#2-dh-parameters-of-ur3e","title":"2. DH Parameters of UR3e","text":"<p>Link for UR3e specifications: https://www.universal-robots.com/media/1807464/ur3e-rgb-fact-sheet-landscape-a4.pdf</p> <p>The PDF for UR3 dimensions is included in the folder for <code>Week 6</code> and the zero configuration (all joint angles are 0) for the robot looks like given in this image</p> <p>You need to create a DH-table for the robot and annotate the given PDF to show the frames and axes used. The unknowns here will be the joint angles. Include the base plate in your calculations as well.</p>"},{"location":"labs/week-06/#3-creating-a-publisher-script-to-move-the-robot","title":"3. Creating a Publisher script to move the robot","text":"<p>(NEW) Bridge packages for custom topics between ur_driver and ENME480 labs</p> <ul> <li>Clone the following repositories into your workspace</li> </ul> <p><pre><code>git clone https://github.com/MarylandRoboticsCenter/ur3e_mrc.git\ngit clone https://github.com/ENME480/ur3e_enme480.git\n</code></pre> - Build and source your workspace.</p> <p>We have a predefined custom message for obtaining position and sending commands:</p> <p>CommandUR3e.msg  <pre><code>float64[] destination\nfloat64 v\nfloat64 a\nbool io_0\n</code></pre> (destination is the set of joint angles <code>[theta1 theta2 theta3 theta4 theta5 theta6]</code>)</p> <p>PositionUR3e.msg <pre><code>float64[] position\nbool is_ready\n</code></pre></p> <p>(position is the set of 6DoF pose of the end effector <code>[x y z roll pitch yaw]</code>)</p> <p>Now run the following command: <pre><code>ros2 launch ur3e_enme480 ur3e_sim_enme480.launch.py\n</code></pre></p> <p>You should be able to see the topics <code>/ur3/position</code> and <code>/ur3/command</code>. Refer to this link for details of the package and its usage.</p> <p>~~Using the topic <code>/joint_trajectory_controller/joint_trajectory</code> and the message type <code>JointTrajectory</code> and <code>JointTrajectoryPoint</code> from <code>trajectory_msgs</code>, create a publisher to move the robot to desired joint angles. Keep in mind that the angles given to th robot sould be in radians but we want to give the input in degrees so ensure that you have converted that.~~</p> <p>Using the topic <code>/ur3/command</code> and the message type <code>CommandUR3e</code> from <code>ur3e_mrc.msg</code>, create a publisher to move the robot to desired joint angles. Keep in mind that the angles given to the robot should be in radians but we want to give the input in degrees so ensure that you have converted that. You can set the velocity and acceleration as <code>1.0</code></p> <p>The second step is to create a function (or multiple functions) in the same Python class to calculate the end effector pose using forward kinematics via DH-parameters, and print that out as the final transformation matrix.</p> <p>Your code will have a structure like this (it can be different but just a baseline)</p> <pre><code>import ....\n\nclass ForwardKinematicsUR3e(...)\n\n  def __init__(self): \n    ...\n    ...\n\n  def move_robot(...):\n    ...\n    ...\n\n  def calculate_fk_from_dh(...):\n    ...\n    ...\n\n\ndef main(...):\n\n  ...\n  ...\n\nif __name__ == '__main__':\n  main()\n</code></pre> <p>Hint: Use the structure from your <code>pubsub</code> codes which you have done previously. ~~You can get the message info for <code>JointTrajectory</code> and <code>JointTrajectoryPoint</code> here: http://docs.ros.org/en/noetic/api/trajectory_msgs/html/msg/JointTrajectory.html &amp; http://docs.ros.org/en/noetic/api/trajectory_msgs/html/msg/JointTrajectoryPoint.html~~</p> <p>Your command should look something like this:</p> <p><pre><code>ros2 run &lt;package_name&gt; ur3e_fk 0 0 0 0 0 0\n</code></pre> where the numbers represent the six joint angles in degrees. Hint: Look into how you can send arguments to a Python script</p> <p>Don't forget to add the node to your <code>setup.py</code> in your package.</p>"},{"location":"labs/week-06/#4-get-the-end-effector-pose-from-ur3position","title":"4. Get the end effector pose from <code>/ur3/position</code>","text":"<p>~~Here you will be using the <code>/tf</code> topic which denotes the transformations in your workspace. The topic publishes the relative transform between all the joints. Your goal is to find the relative transform between the <code>base_plate</code> and the last link on the robot (figure out which is the last link). You will be shown what <code>tf</code> is in class.~~</p> <p>~~Get the relative transform and print the position and orientation. (Hint: There is a tf2 library that will help you to trnasform between frames without needing to do calcuulations.)~~</p> <p>TF (TransForm) calculations are being done on the backend now. You will get the position of the end effector from <code>/ur3/position</code>. </p>"},{"location":"labs/week-06/#5-compare-the-readings","title":"5. Compare the readings","text":"<p>You need to compare the readings from the DH-parameters method with the actual robot position through <code>/tf</code>. Put that in a table for the following 5 test cases:</p> <p>Set 1: <code>[0 0 0 0 0 0]</code> (robot should be horizontal)</p> <p>Set 2: <code>[0 0 -90 90 0 0]</code></p> <p>Set 3: <code>[0 -45 45 -90 30 90]</code></p> <p>Set 4: <code>[90 -60 30 20 10 50]</code></p> <p>Set 5: <code>[0 -90 0 0 0 0]</code> (robot should be upright)</p>"},{"location":"labs/week-06/#submission","title":"Submission","text":"<ol> <li> <p>Show a screenshot of the base plate with the robot </p> </li> <li> <p>Show the DH Table for the robot</p> </li> <li> <p>Show a figure with frames and axes marked</p> </li> <li> <p>For each test case, show:</p> </li> <li> <p>The set of joint angle values (\u03b81, \u03b82, \u03b83, \u03b84, \u03b85, \u03b86)</p> </li> <li>The final transformation matrix (from Python script). You can add it as a readable image of the output window as well.</li> <li>The calculated pose from DH table in simulation vs the pose from <code>/ur3/position</code></li> <li> <p>The scalar error</p> </li> <li> <p>Discuss the sources of error</p> </li> <li> <p>An appendix to show your scripts</p> </li> <li> <p><code>enme480_fk.xacro</code></p> </li> <li>FK publisher (including the Python script for DH transformation)</li> <li>~~<code>tf</code> subscriber~~ Screenshot of messages received from <code>/ur3/position</code></li> </ol> <p>Add everything in one single PDF file and upload it.</p>"},{"location":"labs/week-07/","title":"Week 07 \u2014 Make-up / Office Hours","text":"<p>No scheduled lab; use time for catch-up and TA help.</p>"},{"location":"labs/week-08/","title":"Week 08 \u2014 IK Studio","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 8 - Inverse Kinematics/</code></li> </ul>"},{"location":"labs/week-08/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-08/#week-8-ur3e-inverse-kinematics-on-gazebo","title":"Week 8 - UR3e Inverse Kinematics on Gazebo","text":""},{"location":"labs/week-08/#objectives","title":"Objectives","text":"<p>The objective of this lab is to derive and implement a solution to the inverse kinematics problem for the UR3 robot. In this lab we will:</p> <ul> <li>Derive elbow-up inverse kinematic equations for the UR3</li> <li>Write a publisher that moves the UR3 to a point in space specified by the user</li> </ul>"},{"location":"labs/week-08/#task-description","title":"Task Description","text":"<p>The joints and links of the UR3 robot are annotated in Figure 1. The goal is to find the rotation angles of the 6 joints <code>(\u03b81, ... , \u03b86)</code>, so that the end-effector (end of Link 10) can reach to a given position <code>(x_grip, y_grip, z_grip)</code> and orientation <code>{\u03b8_yaw, \u03b8_pitch, \u03b8_roll}</code> input by the user. There are many possible solutions to the inverse kinematics problem. To make the derivation manageable, we will only implement one of the elbow-up solution in this lab. <code>\u03b8_pitch</code> and <code>\u03b8_roll</code> of the end-effector are fixed by letting the vacuum gripper aluminum plate (Link 9) always be parallel to the x-y plane of world frame coordinates (i.e., desk plane), and \u03b85 is always equal to \u221290\u00b0. Thus, the user will input the desired position and yaw angle of the end-effector in world frame coordinates <code>(xWgrip, yWgrip, zWgrip, yawWgrip)</code>, and the output of the program should be the joint angles <code>\u03b81 to \u03b86</code>.</p> <p></p>"},{"location":"labs/week-08/#solution-steps","title":"Solution Steps","text":"<p>In this section, a suggested solution approach is described.</p> <ol> <li>Establish the world coordinate frame (frame w) centered at the corner of the UR3\u2019s base shown in Figure 2. We will solve the inverse kinematics problem in the base frame (frame 0), so we will convert the coordinates (\ud835\udc65\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc64\u2212\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d) entered by the user to base frame coordinates (\ud835\udc65\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d). The origin of the base frame is at (-0.15, 0.15, 0.01) in the world frame. Set \ud835\udf035 = \u221290\u00b0 in unit of radian.\"</li> </ol> <p></p> <ol> <li>We will define a \u201cwrist center\u201d as \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b which equals the same desired \ud835\udc67 value of the vacuum gripper, and \ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b are the coordinates of <code>\ud835\udf036</code>\u2019s \ud835\udc67 axis (see Figure 1). Link 9 (gripper plate) has a length of 0.0535 meters from the center line of the gripper to the center line of Joint 6. Given the desired position of the gripper <code>(\ud835\udc65\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc66\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d, \ud835\udc67\ud835\udc54\ud835\udc5f\ud835\udc56\ud835\udc5d)</code> in the base frame and the yaw angle, find wrist\u2019s center point (\ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b).</li> <li>Given the wrist\u2019s center point (\ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b), find the waist angle \ud835\udf031. Figure 3 shows the top-down view of the robot, which is helpful for formulating the relations.</li> <li>Solve for the value of <code>\ud835\udf036</code>, given \ud835\udf031 and the desired yaw angle (should be converted to radian from the input degree value). \ud835\udf036 = 0 when Link 9 is parallel to Link 4 and Link 6.</li> <li>We will define another virtual point. A projected end point (\ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51) is a point off the UR3 but lies along the Link 6 axis, as shown in Figure 1 and Figure 3. For example, if \ud835\udf031 = 0 then \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51 = 0. If \ud835\udf031 = 90\u00b0 then \ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51 = 0. Use the top-down view (Figure 3) to find \ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51 and \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51 from \ud835\udc65\ud835\udc50\ud835\udc52\ud835\udc5b, \ud835\udc66\ud835\udc50\ud835\udc52\ud835\udc5b. Figure 4 is a side view that is a projection of the robot onto a plane perpendicular to the x-y plane of world frame and rotated by \ud835\udf031 about the base frame. From this figure we can see that \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51 is \ud835\udc67\ud835\udc50\ud835\udc52\ud835\udc5b offset by a constant. The end of the gripper is 0.052m from the center of the gripper plate in the z-axis direction.</li> </ol> <p></p> <p></p> <ol> <li>Find \ud835\udf032, \ud835\udf033 and \ud835\udf034 from the end point (\ud835\udc653\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc663\ud835\udc52\ud835\udc5b\ud835\udc51, \ud835\udc673\ud835\udc52\ud835\udc5b\ud835\udc51). In Figure 4, a parallel to the base construction line through Joint 2 and a parallel to the base construction line through Joint 4 are helpful in finding the needed partial angles. \ud835\udf032 and \ud835\udf033 can be found from the geometry, while \ud835\udf034 is determined due to the requirement that Link 7 and Link 9 must be parallel to the x-y plane of the world frame.</li> </ol> <p>Now that your code solves for all the joint variables <code>(\ud835\udf031 to \ud835\udf036)</code>, send these six values to the publisher you created in FK lab to move the robot to those angles so that it gets to the desired position.</p>"},{"location":"labs/week-08/#implementation-in-ros2-gazebo","title":"Implementation in ROS2 &amp; Gazebo","text":"<ol> <li>Pull the latest commit for ur3e_enme480 package</li> </ol> <pre><code>cd ~/&lt;your_workspace&gt;/src/ur3e_enme480\ngit pull\n</code></pre> <ol> <li>Download the URDF <code>enme480_ik.xacro</code> (from <code>Code Resources</code> in Week 7 on this page) in your <code>urdf</code> folder. Replace <code>ur.urdf.xacro</code> as well.</li> </ol> <p>Add the <code>UR3SuctionCupMount.stl</code> from <code>Code Resources</code> to your <code>Universal_Robots_ROS2_Description//meshes/ur3/visual/</code> folder.</p> <ol> <li>Create a publisher <code>ur3e_ik_sim.py</code> with node name <code>ur3e_sim_ik_publisher</code>. It will have a structure somewhat like this:</li> </ol> <pre><code>import ....\n\nclass InverseKinematicsUR3e(...)\n\n  def __init__(self): \n    ...\n    ...\n    self.publisher_ = self.create_publisher(CommandUR3e, '/ur3/command', 10)\n    ...\n    ...\n\n  def move_robot(...):\n    ...\n    ...\n\n  def calculate_fk_from_dh(...):\n    ...\n    ...\n\n  def inverse_kinematics(self, xWgrip, yWgrip, zWgrip, yawWgrip):\n\n    # TODO: Function that calculates an elbow up \n    # inverse kinematics solution for the UR3\n\n    # Step 1: find gripper position relative to the base of UR3,\n    # and set theta_5 equal to -pi/2\n\n\n    # Step 2: find x_cen, y_cen, z_cen\n\n\n    # Step 3: find theta_1\n\n\n    # Step 4: find theta_6 \n\n\n    # Step 5: find x3_end, y3_end, z3_end\n\n\n    # Step 6: find theta_2, theta_3, theta_4\n\n    # Return the set of joint angles to move the robot\n\n\ndef main(...):\n\n  ...\n  ...\n\nif __name__ == '__main__':\n  main()\n</code></pre> <p>You command should look like this:</p> <pre><code>ros2 run &lt;package_name&gt; ur3e_sim_ik_publisher &lt;x&gt; &lt;y&gt; &lt;z&gt; &lt;Yaw&gt;\n</code></pre>"},{"location":"labs/week-08/#test-cases","title":"Test Cases","text":"Test Point Inputs (x, y, z, yaw) IK solution (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) Output from <code>/ur3/position</code> (0.2, 0.3, 0.3, 45) (0.1, 0.4, 0.1, 90) (0.2, 0.2, 0.2, 0) (0.2, -0.2, 0.1, 0) (0.2, 0.3, 0.4, 30) ### Submission <ol> <li>A pdf of your code complete with comments describing the steps you've taken</li> <li>A pdf containing a (neatly) written/typed solution for IK showing how you derived your equations from the geometry</li> <li>Screenshots of UR3e in Gazebo for all test cases</li> <li>A comparison of error between your IK script and the output of the <code>ur3/position</code> topic for the test cases with a discussion of possible error sources.</li> <li>A brief discussion of any possible singularities in the math and what could be done to avoid them (you don't need to implement this, we just want you thinking about strategies!)</li> </ol>"},{"location":"labs/week-09/","title":"Week 09 \u2014 Inverse Kinematics Lab","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 11 - Inverse Kinematics Lab/</code></li> <li>Note: An <code>IK Lab Solution.pdf</code> exists in repo root for staff reference.</li> </ul>"},{"location":"labs/week-10/","title":"Week 10 \u2014 IK Lab / Dynamics intro","text":"<ul> <li>\ud83d\udcc1 <code>labs/Lab-Code/Week 10 - Forward Kinematics Lab/</code></li> </ul>"},{"location":"labs/week-10/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-10/#week-10-ur3e-forward-kinematics","title":"Week 10 - UR3e Forward Kinematics","text":""},{"location":"labs/week-10/#objectives","title":"Objectives","text":"<ul> <li>Use forward kinematics (FK) to compute the pose of a UR3e robot arm's end effector.</li> <li>Determine where a laser pointer on the end effector intersects with a workbench at an arbitrary height.</li> <li>Publish commands to control the UR3e robot in ROS2 and visualize results.</li> </ul>"},{"location":"labs/week-10/#1-getting-started-with-the-ur3e","title":"1. Getting Started with the UR3e","text":"<ul> <li>Power on the robot</li> <li> <p>Release the brakes</p> </li> <li> <p>Interfacing the Robot with PC</p> </li> </ul> <p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS</li> </ul> <p>In one more terminal windows launch these commands:</p> <pre><code>ros2 launch ur3e_mrc ur3e_enme480.launch\n</code></pre>"},{"location":"labs/week-10/#2-modify-the-fk-script-to-move-the-robot","title":"2. Modify the FK script to move the robot","text":"<p>Due to inaccuracies in some of the DH tables, resulting in safety risks, we are giving you a code structure that you need to enter your code in.</p> <p>It is located in <code>~/rosPackages/ENME480_ws/enme480_fk_labs/enme480_fk_labs/ur3e_fk.py</code></p> <p>If you are using your own code, remember to change the node name to <code>ur3e_fk_publisher</code></p> <p>To run it:</p> <pre><code>ros2 run enme480_lab_fk ur3e_fk joint1 joint2 joint3 joint4 joint5 joint6\n</code></pre>"},{"location":"labs/week-10/#3-predicting-where-the-laser-point-will-land","title":"3. Predicting where the laser point will land","text":"<p>Since you know the position and orientation of the end effector (attached with a laser pointer), you have to predict where the laser point will land on the workbench. (Hint: Think in terms of vector and plane intersection)</p> <p>Assume the <code>z_table = 0</code>. </p> <p>We are providing you with the code in lab, but you need to show the math behind it in your lab report.</p> <p>Turning on the laser pointer:</p> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre>"},{"location":"labs/week-10/#4-test-points","title":"4. Test Points","text":"<p>Run the robot for the following test points:</p> Test Point Inputs (\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4) End Effector Position (Your Code) <code>(x y z)</code> Laser Position on Workbench (from Code) (<code>x,y</code>) Laser Position on Workbench(Measured) <code>(x, y)</code> [0, -45, 0, 45, -90, 60] [-30, -60, 80, -10, -90, -30] [30 -70 80 -10 -90 10] [-30, -60, 60, -10, -90, -30]"},{"location":"labs/week-10/#submission","title":"Submission","text":"<p>Please create a neatly typed/written report for the lab including the following:</p> <ul> <li>Correct frame and axes assignments for the UR3e</li> <li>A correct DH table for the UR3e (with the updated dimensions)</li> <li>A detailed derivation of how the position of laser point is predicted on the workbench.</li> <li>Error Analysis (for at least 2 points)</li> <li>Your code snippets for the functions supposed to be changed (function for moving the robot and calulating DH transformation matrix)</li> </ul>"},{"location":"labs/week-11/","title":"Week 11 \u2014 Dynamics + Intro to Cameras","text":"<ul> <li>\ud83d\udcc4 Camera perspective PDF in repo: <code>labs/Lab-Code/PerspectiveTransformEstimation (1).pdf</code></li> </ul>"},{"location":"labs/week-11/#lab-handout-from-lab-code","title":"Lab handout (from Lab-Code)","text":"<p>View this lab folder on GitHub</p>"},{"location":"labs/week-11/#week-11-ur3e-inverse-kinematics","title":"Week 11 - UR3e Inverse Kinematics","text":""},{"location":"labs/week-11/#objectives","title":"Objectives","text":"<ul> <li>Use inverse kinematics (IK) to compute the required joint angles of a UR3e robot arm for its end effector to reach a specific point.</li> <li>Determine if the laser pointer is close to the predicted cartesian coordinates.</li> <li>Publish commands to control the UR3e robot in ROS2 and visualize results.</li> </ul>"},{"location":"labs/week-11/#1-getting-started-with-the-ur3e","title":"1. Getting Started with the UR3e","text":"<ul> <li>Power on the robot</li> <li>Release the brakes</li> </ul>"},{"location":"labs/week-11/#interfacing-the-robot-with-pc","title":"Interfacing the Robot with PC","text":"<p>The robot connections and configuration has been setup. You have to interface the robot with ROS to receive and send comands.</p> <ul> <li>Find the <code>commands2run.txt</code> file on the Desktop</li> <li>Follow instructions in the file to get the robot interfaced with ROS.</li> </ul> <p>In one more terminal window launch this command:</p> <pre><code>ros2 launch ur3e_mrc ur3e_enme480.launch\n</code></pre>"},{"location":"labs/week-11/#2-modify-the-ik-script-to-move-the-robot","title":"2. Modify the IK script to move the robot","text":"<p>Due to inaccuracies in some of your IK calculations, resulting in safety risks due to singulartities, we are giving you a code structure that you need to enter your code in.</p> <p>It is located in <code>~/rosPackages/ENME480_ws/src/enme480_fk_labs/enme480_fk_labs/ur3e_ik.py</code></p> <p>To refresh the folder to original state run the following commands:</p> <pre><code>cd ~/ENME480_ws/src/enme480_lab_fk\ngit checkout .\n</code></pre> <p>You need to modify the following functions within the given snippet (do not change anything else in the code):</p> <ul> <li><code>send_command()</code> - will be the same as last time (just remove conversion to radians since IK takes care of it)</li> <li><code>calculate_dh_transform()</code> - will be exactly same as last time (just make changes to DH parameters if wrong)</li> <li><code>inverse_kinematics()</code> - will be exactly similar as your simulation code</li> </ul> <p>Helpful Tip: Use tools like Pastebin or Google Docs to move your code from your laptop to the lab machine</p> <p>If you are using your own code, remember to change the node name to <code>ur3e_ik_publisher</code></p> <p>To run it:</p> <pre><code>ros2 run enme480_lab_fk ur3e_ik x y z yaw\n</code></pre> <p>If your IK code has high or slight error, you will receive a prompt on your terminal. Please follow the instructions. The robot will move regardless but those error mean that you need to check your calculations.</p>"},{"location":"labs/week-11/#3-predicting-where-the-laser-point-will-land","title":"3. Predicting where the laser point will land","text":"<p>Since we are constraining IK to always face down, the laser point will exactly point at the same <code>(x,y)</code> as the end effector. You just need to measure z. Your prediction will depend on your DH transformation.</p> <p>Turning on the laser pointer:</p> <pre><code>ros2 topic pub --once /ur3/laser_point std_msgs/msg/Bool \"data: true\"\n</code></pre> <p>If your DH transform is right, you should recieve a similar transformation matrix as the <code>Correct Transformation Matrix</code> on your terminal. Otherwise, work on it to get a matrix as similar as possible</p>"},{"location":"labs/week-11/#4-test-points","title":"4. Test Points","text":"<p>Run the robot for the following test points and record the following data:</p> Test Point Inputs (x, y, z, Yaw) Joint Angles (Your Code)  <code>(\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4)</code> Correct Joint Angles <code>(\ud835\udf3d\ud835\udfcf, \u2026 \ud835\udf3d\ud835\udfd4)</code> Laser Position on Workbench (Your Prediction) <code>(x, y)</code> Laser Position on Workbench (Correct Prediction) <code>(x, y)</code> Laser Position on Workbench (Measured Prediction) <code>(x, y)</code> End Effector Position (Your Prediction) <code>(x, y, z)</code> End Effector Position (Correct Prediction) <code>(x, y, z)</code> End Effector Position (Measured) <code>(x, y, z)</code> [0.2, 0.2, 0.2, 0] [0.2, 0.4, 0.2, 0] [0.3, 0.4, 0.1, 45] [0.3, 0.2, 0.25, 60] [0.25, 0.3, 0.3, -30]"},{"location":"labs/week-11/#5-before-you-leave-the-lab","title":"5. Before you leave the lab","text":"<p>Send yourself the backup/copy of your script and restore the package to its blank version.</p> <p>IMPORTANT: The below command will erase your script from the computer so take a backup of it before you run it</p> <pre><code>cd ~/rosPackages/ENME480_ws/src/enme480_lab_fk\ngit checkout .\n</code></pre>"},{"location":"labs/week-11/#submission","title":"Submission","text":"<p>Please create a neatly typed/written report for the lab including the following: 1. Your IK derivation - you can resue the one from Week 8 submission if that was right. If anything changed or you noticed errors in your previous derivation, make a note of it in the report including the reason behind the error. 2. Comparsion table for Step 4. 3. Write a paragraph on the reasons behind discrepancies in measurements and calculations. 4. What are the potential sources of singlularities and how will avoid them when you are implementing the code? If you found any singularities, be sure to list them and discuss possible causes. 5. Code snippet of <code>inverse_kinematics()</code> function that you used.</p>"},{"location":"labs/week-12/","title":"Week 12 \u2014 Camera Lab (+ Exam 2 week)","text":"<ul> <li>\ud83d\udcc1 Camera Lab materials: use camera PDF above and any posted updates.</li> </ul>"},{"location":"labs/week-13/","title":"Week 13 \u2014 Make-up / Office Hours","text":"<p>No lab meetings (holiday week). Use time for project prep.</p>"},{"location":"labs/week-14/","title":"Week 14 \u2014 Final Project (starts)","text":"<ul> <li>\ud83d\udcc1 Final Project folder: <code>labs/Lab-Code/Final Project/</code></li> </ul>"},{"location":"labs/week-15/","title":"Week 15 \u2014 Final Project (wrap-up)","text":"<ul> <li>\ud83d\udcc1 Continue work in <code>labs/Lab-Code/Final Project/</code></li> <li>Deliverables: write-up + video demo (see syllabus).</li> </ul>"}]}